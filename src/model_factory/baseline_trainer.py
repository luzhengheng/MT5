#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
XGBoost Baseline Trainer

è®­ç»ƒå’Œè¯„ä¼° XGBoost åˆ†ç±»å™¨ç”¨äºä»·æ ¼æ–¹å‘é¢„æµ‹ã€‚

åè®®: v2.2 (æœ¬åœ°å­˜å‚¨ï¼Œæ–‡æ¡£ä¼˜å…ˆ)
"""

import logging
import sys
from pathlib import Path
from typing import List, Tuple, Optional
from datetime import datetime
import json

import pandas as pd
import numpy as np
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler
from sklearn.metrics import (
    classification_report, confusion_matrix, roc_auc_score,
    roc_curve, auc, precision_recall_curve
)
from xgboost import XGBClassifier
import json as json_lib

# Add project root to path
PROJECT_ROOT = Path(__file__).parent.parent.parent
sys.path.insert(0, str(PROJECT_ROOT))

from src.model_factory.data_loader import APIDataLoader

# Configure logging
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s'
)
logger = logging.getLogger(__name__)

# Color codes
GREEN = "\033[92m"
RED = "\033[91m"
YELLOW = "\033[93m"
CYAN = "\033[96m"
BLUE = "\033[94m"
RESET = "\033[0m"


class BaselineTrainer:
    """XGBoost åŸºçº¿æ¨¡å‹è®­ç»ƒå™¨"""

    def __init__(
        self,
        symbols: Optional[List[str]] = None,
        api_url: str = "http://localhost:8000"
    ):
        """åˆå§‹åŒ–è®­ç»ƒå™¨"""
        self.symbols = symbols or ["EURUSD", "GBPUSD", "XAUUSD"]
        self.api_url = api_url
        self.data_loader = APIDataLoader(api_url=api_url)

        self.df = None
        self.X_train = None
        self.X_test = None
        self.y_train = None
        self.y_test = None
        self.model = None
        self.scaler = StandardScaler()
        self.results = None

        self.feature_cols = [
            'sma_20', 'sma_50', 'sma_200',
            'rsi_14',
            'macd_line', 'macd_signal', 'macd_histogram',
            'atr_14',
            'bb_upper', 'bb_middle', 'bb_lower'
        ]

        logger.info(f"{GREEN}âœ… BaselineTrainer å·²åˆå§‹åŒ–{RESET}")
        logger.info(f"  ç¬¦å·: {self.symbols}")
        logger.info(f"  API: {api_url}")

    def load_data(
        self,
        start_date: str = "2010-01-01",
        end_date: str = "2025-12-31"
    ) -> pd.DataFrame:
        """åŠ è½½ç‰¹å¾å’Œ OHLCV æ•°æ®"""
        logger.info(f"{CYAN}ğŸ“¥ åŠ è½½æ•°æ®...{RESET}")

        try:
            # ä» API è·å–ç‰¹å¾
            features_df = self.data_loader.fetch_features(
                symbols=self.symbols,
                start_date=start_date,
                end_date=end_date,
                features=self.feature_cols
            )

            # ä»æ•°æ®åº“è·å– OHLCV
            ohlcv_data = []
            for symbol in self.symbols:
                try:
                    ohlcv = self.data_loader.fetch_ohlcv(
                        symbol=symbol,
                        start_date=start_date,
                        end_date=end_date
                    )
                    if not ohlcv.empty:
                        ohlcv_data.append(ohlcv)
                except Exception as e:
                    logger.warning(f"{YELLOW}âš ï¸  æ— æ³•è·å– {symbol} çš„ OHLCV: {e}{RESET}")

            if not ohlcv_data:
                raise ValueError("æ— æ³•è·å–ä»»ä½• OHLCV æ•°æ®")

            ohlcv_df = pd.concat(ohlcv_data, ignore_index=True)

            # åˆå¹¶æ•°æ®
            self.df = self.data_loader.merge_features_ohlcv(features_df, ohlcv_df)

            logger.info(f"{GREEN}âœ… æ•°æ®åŠ è½½å®Œæˆ{RESET}")
            logger.info(f"  æ ·æœ¬æ•°: {len(self.df)}")
            logger.info(f"  åˆ—æ•°: {len(self.df.columns)}")
            logger.info(f"  æ—¶é—´èŒƒå›´: {self.df['date'].min()} è‡³ {self.df['date'].max()}")

            return self.df

        except Exception as e:
            logger.error(f"{RED}âŒ æ•°ï¿½ï¿½ï¿½åŠ è½½å¤±è´¥: {e}{RESET}")
            raise

    def prepare_features(self) -> pd.DataFrame:
        """å‡†å¤‡ç‰¹å¾æ•°æ®ï¼ˆå·¥ç¨‹ç‰¹å¾ + æ ‡å‡†åŒ–ï¼‰"""
        logger.info(f"{CYAN}âš™ï¸  å‡†å¤‡ç‰¹å¾...{RESET}")

        if self.df is None:
            raise ValueError("å¿…é¡»å…ˆåŠ è½½æ•°æ®")

        df = self.df.copy()

        # å·¥ç¨‹ç‰¹å¾
        logger.info("  è®¡ç®—å·¥ç¨‹ç‰¹å¾...")

        # 1. Bollinger Band ä»·æ ¼ä½ç½®
        df['bb_position'] = (df['close'] - df['bb_lower']) / (df['bb_upper'] - df['bb_lower'] + 1e-8)
        df['bb_position'] = df['bb_position'].clip(0, 1)

        # 2. RSI åŠ¨é‡
        df['rsi_momentum'] = df['rsi_14'] - 50

        # 3. MACD å¼ºåº¦
        df['macd_strength'] = df['macd_histogram'].abs()

        # 4. SMA è¶‹åŠ¿
        df['sma_trend'] = (df['sma_20'] - df['sma_50']) / (df['sma_50'] + 1e-8)

        # 5. ç›¸å¯¹æ³¢åŠ¨ç‡
        df['volatility_ratio'] = df['atr_14'] / (df['close'] + 1e-8)

        # 6. 1 æ—¥æ”¶ç›Šç‡
        df['returns_1d'] = df['close'].pct_change()

        # 7. 5 æ—¥æ”¶ç›Šç‡
        df['returns_5d'] = df['close'].pct_change(5)

        # åˆ é™¤åŒ…å« NaN çš„è¡Œ
        initial_rows = len(df)
        df = df.dropna()
        dropped = initial_rows - len(df)

        logger.info(f"{GREEN}âœ… ç‰¹å¾å‡†å¤‡å®Œæˆ{RESET}")
        logger.info(f"  åŸå§‹ç‰¹å¾: {len(self.feature_cols)}")
        logger.info(f"  å·¥ç¨‹ç‰¹å¾: 7")
        logger.info(f"  æ€»ç‰¹å¾æ•°: {len(self.feature_cols) + 7}")
        logger.info(f"  åˆ é™¤ NaN è¡Œ: {dropped}")

        self.df = df
        return self.df

    def create_labels(self) -> Tuple[pd.DataFrame, pd.Series]:
        """åˆ›å»ºç›®æ ‡æ ‡ç­¾ (ä¸‹ä¸€æ—¥æ”¶ç›˜ä»·æ˜¯å¦ä¸Šå‡)"""
        logger.info(f"{CYAN}ğŸ¯ åˆ›å»ºæ ‡ç­¾...{RESET}")

        if self.df is None:
            raise ValueError("å¿…é¡»å…ˆå‡†å¤‡ç‰¹å¾")

        df = self.df.copy()

        # æŒ‰ symbol å’Œ date æ’åº
        df = df.sort_values(['symbol', 'date']).reset_index(drop=True)

        # åˆ›å»º shift åˆ—
        df['next_close'] = df.groupby('symbol')['close'].shift(-1)

        # åˆ é™¤æœ€åä¸€è¡Œ (æ— ä¸‹ä¸€æ—¥æ”¶ç›˜ä»·)
        df = df.dropna(subset=['next_close'])

        # åˆ›å»ºæ ‡ç­¾: 1 if up, 0 if down
        y = (df['next_close'] > df['close']).astype(int)

        logger.info(f"{GREEN}âœ… æ ‡ç­¾åˆ›å»ºå®Œæˆ{RESET}")
        logger.info(f"  æ€»æ ·æœ¬: {len(y)}")
        logger.info(f"  ä¸Šå‡: {(y == 1).sum()} ({100 * (y == 1).mean():.1f}%)")
        logger.info(f"  ä¸‹é™: {(y == 0).sum()} ({100 * (y == 0).mean():.1f}%)")

        self.df = df
        self.y = y

        return self.df, y

    def split_data(self, test_size: float = 0.33) -> Tuple[pd.DataFrame, pd.DataFrame]:
        """æ—¶é—´åºåˆ—åˆ’åˆ† (ä¸ shuffle)"""
        logger.info(f"{CYAN}ğŸ“Š åˆ’åˆ†æ•°æ®...{RESET}")

        if self.df is None or self.y is None:
            raise ValueError("å¿…é¡»å…ˆåˆ›å»ºæ ‡ç­¾")

        df = self.df.copy()
        y = self.y.copy()

        # ç‰¹å¾åˆ—
        feature_cols = self.feature_cols + ['bb_position', 'rsi_momentum', 'macd_strength',
                                             'sma_trend', 'volatility_ratio', 'returns_1d', 'returns_5d']

        X = df[feature_cols].copy()

        # æ—¶é—´åºåˆ—åˆ’åˆ†ï¼ˆä¸ shuffleï¼‰
        n = len(X)
        split_idx = int(n * (1 - test_size))

        self.X_train = X.iloc[:split_idx].reset_index(drop=True)
        self.X_test = X.iloc[split_idx:].reset_index(drop=True)
        self.y_train = y.iloc[:split_idx].reset_index(drop=True)
        self.y_test = y.iloc[split_idx:].reset_index(drop=True)

        # æ ‡å‡†åŒ–ç‰¹å¾
        self.X_train_scaled = self.scaler.fit_transform(self.X_train)
        self.X_test_scaled = self.scaler.transform(self.X_test)

        logger.info(f"{GREEN}âœ… æ•°æ®åˆ’åˆ†å®Œæˆ{RESET}")
        logger.info(f"  è®­ç»ƒé›†: {len(self.X_train)} æ ·æœ¬ (2010-2023)")
        logger.info(f"  æµ‹è¯•é›†: {len(self.X_test)} æ ·æœ¬ (2024-2025)")
        logger.info(f"  è®­ç»ƒé›†ç±»åˆ†å¸ƒ: {(self.y_train == 1).sum()}/{len(self.y_train)} ä¸Šå‡")
        logger.info(f"  æµ‹è¯•é›†ç±»åˆ†å¸ƒ: {(self.y_test == 1).sum()}/{len(self.y_test)} ä¸Šå‡")

    def train(self) -> XGBClassifier:
        """è®­ç»ƒ XGBoost æ¨¡å‹"""
        logger.info(f"{CYAN}ğŸš€ è®­ç»ƒ XGBoost æ¨¡å‹...{RESET}")

        if self.X_train_scaled is None:
            raise ValueError("å¿…é¡»å…ˆåˆ’åˆ†æ•°æ®")

        # XGBoost è¶…å‚æ•°
        self.model = XGBClassifier(
            n_estimators=200,
            max_depth=6,
            learning_rate=0.1,
            subsample=0.8,
            colsample_bytree=0.8,
            reg_alpha=1.0,
            reg_lambda=1.0,
            objective='binary:logistic',
            eval_metric='logloss',
            random_state=42,
            n_jobs=-1,
            verbosity=0
        )

        # è®­ç»ƒ
        self.model.fit(
            self.X_train_scaled,
            self.y_train,
            eval_set=[(self.X_test_scaled, self.y_test)],
            verbose=False,
            early_stopping_rounds=20
        )

        logger.info(f"{GREEN}âœ… æ¨¡å‹è®­ç»ƒå®Œæˆ{RESET}")

        return self.model

    def evaluate(self) -> dict:
        """è¯„ä¼°æ¨¡å‹æ€§èƒ½"""
        logger.info(f"{CYAN}ğŸ“ˆ è¯„ä¼°æ¨¡å‹...{RESET}")

        if self.model is None:
            raise ValueError("å¿…é¡»å…ˆè®­ç»ƒæ¨¡å‹")

        # é¢„æµ‹
        y_pred = self.model.predict(self.X_test_scaled)
        y_pred_proba = self.model.predict_proba(self.X_test_scaled)[:, 1]

        # è®¡ç®—æŒ‡æ ‡
        from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score

        accuracy = accuracy_score(self.y_test, y_pred)
        precision = precision_score(self.y_test, y_pred)
        recall = recall_score(self.y_test, y_pred)
        f1 = f1_score(self.y_test, y_pred)
        auc_score = roc_auc_score(self.y_test, y_pred_proba)

        # Confusion Matrix
        cm = confusion_matrix(self.y_test, y_pred)
        tn, fp, fn, tp = cm.ravel()

        results = {
            'accuracy': float(accuracy),
            'precision': float(precision),
            'recall': float(recall),
            'f1_score': float(f1),
            'auc_roc': float(auc_score),
            'confusion_matrix': {
                'true_negative': int(tn),
                'false_positive': int(fp),
                'false_negative': int(fn),
                'true_positive': int(tp)
            },
            'test_samples': int(len(self.y_test)),
            'train_samples': int(len(self.y_train))
        }

        logger.info(f"{GREEN}âœ… è¯„ä¼°å®Œæˆ{RESET}")
        logger.info(f"")
        logger.info(f"  Accuracy:  {accuracy:.4f}")
        logger.info(f"  Precision: {precision:.4f}")
        logger.info(f"  Recall:    {recall:.4f}")
        logger.info(f"  F1-Score:  {f1:.4f}")
        logger.info(f"  AUC-ROC:   {auc_score:.4f}")
        logger.info(f"")
        logger.info(f"  Confusion Matrix:")
        logger.info(f"    TN={tn}, FP={fp}")
        logger.info(f"    FN={fn}, TP={tp}")

        self.results = results

        return results

    def save_model(self, path: str = "models/baseline_v1.json") -> str:
        """ä¿å­˜æ¨¡å‹"""
        logger.info(f"{CYAN}ğŸ’¾ ä¿å­˜æ¨¡å‹...{RESET}")

        if self.model is None:
            raise ValueError("å¿…é¡»å…ˆè®­ç»ƒæ¨¡å‹")

        model_path = PROJECT_ROOT / path
        model_path.parent.mkdir(parents=True, exist_ok=True)

        self.model.save_model(str(model_path))

        logger.info(f"{GREEN}âœ… æ¨¡å‹å·²ä¿å­˜{RESET}")
        logger.info(f"  è·¯å¾„: {model_path}")
        logger.info(f"  å¤§å°: {model_path.stat().st_size / 1024 / 1024:.2f} MB")

        return str(model_path)

    def save_results(self, path: str = "models/baseline_v1_results.json") -> str:
        """ä¿å­˜è¯„ä¼°ç»“æœ"""
        logger.info(f"{CYAN}ğŸ’¾ ä¿å­˜è¯„ä¼°ç»“æœ...{RESET}")

        if self.results is None:
            raise ValueError("å¿…é¡»å…ˆè¯„ä¼°æ¨¡å‹")

        results_path = PROJECT_ROOT / path
        results_path.parent.mkdir(parents=True, exist_ok=True)

        with open(results_path, 'w') as f:
            json_lib.dump(self.results, f, indent=2)

        logger.info(f"{GREEN}âœ… è¯„ä¼°ç»“æœå·²ä¿å­˜{RESET}")
        logger.info(f"  è·¯å¾„: {results_path}")

        return str(results_path)

    def run_pipeline(
        self,
        start_date: str = "2010-01-01",
        end_date: str = "2025-12-31"
    ):
        """å®Œæ•´çš„è®­ç»ƒç®¡é“"""
        logger.info(f"{BLUE}{'=' * 80}{RESET}")
        logger.info(f"{BLUE}ğŸ§  XGBoost Baseline Model Training{RESET}")
        logger.info(f"{BLUE}{'=' * 80}{RESET}")
        logger.info(f"")

        try:
            # åŠ è½½æ•°æ®
            self.load_data(start_date=start_date, end_date=end_date)

            # å‡†å¤‡ç‰¹å¾
            self.prepare_features()

            # åˆ›å»ºæ ‡ç­¾
            self.create_labels()

            # åˆ’åˆ†æ•°æ®
            self.split_data()

            # è®­ç»ƒæ¨¡å‹
            self.train()

            # è¯„ä¼°æ¨¡å‹
            self.evaluate()

            # ä¿å­˜æ¨¡å‹å’Œç»“æœ
            self.save_model()
            self.save_results()

            logger.info(f"")
            logger.info(f"{GREEN}{'=' * 80}{RESET}")
            logger.info(f"{GREEN}âœ… è®­ç»ƒç®¡é“å®Œæˆ{RESET}")
            logger.info(f"{GREEN}{'=' * 80}{RESET}")

            return self.results

        except Exception as e:
            logger.error(f"{RED}âŒ è®­ç»ƒç®¡é“å¤±è´¥: {e}{RESET}")
            import traceback
            traceback.print_exc()
            raise

"""ç«¯åˆ°ç«¯æµ‹è¯•è„šæœ¬

æµ‹è¯•å®Œæ•´çš„æ–°é—»åˆ°ä¿¡å·ç”Ÿæˆæµç¨‹
"""
import sys
import os
import time
import logging
from datetime import datetime, timedelta

# æ·»åŠ è·¯å¾„
sys.path.insert(0, os.path.join(os.path.dirname(__file__)))

import redis
from event_bus.config import redis_config
from event_bus.base_producer import BaseEventProducer

# é…ç½®æ—¥å¿—
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s'
)

logger = logging.getLogger(__name__)


def test_redis_connection():
    """æµ‹è¯• Redis è¿æ¥"""
    logger.info("=== æµ‹è¯•1ï¼šRedis è¿æ¥ ===")

    try:
        client = redis.Redis(
            host=redis_config.host,
            port=redis_config.port,
            db=redis_config.db,
            decode_responses=True
        )

        client.ping()
        logger.info("âœ“ Redis è¿æ¥æˆåŠŸ")
        return True
    except Exception as e:
        logger.error(f"âœ— Redis è¿æ¥å¤±è´¥: {e}")
        return False


def publish_test_news():
    """å‘å¸ƒæµ‹è¯•æ–°é—»åˆ° news_raw stream"""
    logger.info("\n=== æµ‹è¯•2ï¼šå‘å¸ƒæµ‹è¯•æ–°é—» ===")

    producer = BaseEventProducer(stream_key=redis_config.STREAM_NEWS_RAW)

    # æµ‹è¯•æ–°é—»æ•°æ®
    test_news = [
        {
            "news_id": "test-001",
            "title": "Apple reports record-breaking Q4 earnings, stock surges 10%",
            "content": "Apple Inc. announced impressive fourth-quarter results today, with revenue beating analyst expectations. The iPhone maker's stock jumped 10% in after-hours trading.",
            "link": "https://example.com/news/apple-earnings",
            "published_at": datetime.utcnow().isoformat() + "Z",
            "source": "TEST",
            "tickers": ["AAPL"],
            "fetched_at": datetime.utcnow().isoformat() + "Z",
        },
        {
            "news_id": "test-002",
            "title": "Tesla faces production delays, shares fall 8%",
            "content": "Tesla is experiencing significant production delays at its new factory, causing shares to drop 8% today. Analysts express concerns about delivery targets.",
            "link": "https://example.com/news/tesla-delays",
            "published_at": datetime.utcnow().isoformat() + "Z",
            "source": "TEST",
            "tickers": ["TSLA"],
            "fetched_at": datetime.utcnow().isoformat() + "Z",
        },
        {
            "news_id": "test-003",
            "title": "Mixed earnings from tech giants: Google up, Amazon down",
            "content": "Tech earnings season continues with mixed results. Google parent Alphabet beat estimates and rose 5%, while Amazon missed expectations and fell 3%.",
            "link": "https://example.com/news/tech-earnings",
            "published_at": datetime.utcnow().isoformat() + "Z",
            "source": "TEST",
            "tickers": ["GOOGL", "AMZN"],
            "fetched_at": datetime.utcnow().isoformat() + "Z",
        },
    ]

    published_ids = []
    for news in test_news:
        msg_id = producer.produce(news, event_type='news_raw')
        if msg_id:
            published_ids.append(msg_id)
            logger.info(f"âœ“ å‘å¸ƒæ–°é—»: {news['title'][:60]}... â†’ {msg_id}")
        else:
            logger.error(f"âœ— å‘å¸ƒå¤±è´¥: {news['title'][:60]}...")

    producer.close()

    logger.info(f"\nå…±å‘å¸ƒ {len(published_ids)}/{len(test_news)} æ¡æµ‹è¯•æ–°é—»")
    return len(published_ids) == len(test_news)


def check_stream_data(stream_key, expected_min=0):
    """æ£€æŸ¥ stream ä¸­çš„æ•°æ®"""
    try:
        client = redis.Redis(
            host=redis_config.host,
            port=redis_config.port,
            db=redis_config.db,
            decode_responses=True
        )

        # è·å– stream é•¿åº¦
        info = client.xinfo_stream(stream_key)
        length = info['length']

        logger.info(f"  Stream '{stream_key}': {length} æ¡æ¶ˆæ¯")

        if length >= expected_min:
            # è¯»å–æœ€æ–°çš„å‡ æ¡æ¶ˆæ¯
            messages = client.xrevrange(stream_key, count=3)

            logger.info(f"  æœ€æ–°æ¶ˆæ¯é¢„è§ˆ:")
            for msg_id, msg_data in messages:
                # è§£æç¬¬ä¸€ä¸ªå­—æ®µä½œä¸ºé¢„è§ˆ
                preview = list(msg_data.keys())[0] if msg_data else "ç©º"
                logger.info(f"    {msg_id}: {preview}...")

            return True
        else:
            logger.warning(f"  âš ï¸ æ¶ˆæ¯æ•°é‡ä¸è¶³: {length} < {expected_min}")
            return False

    except Exception as e:
        logger.error(f"  âœ— æ£€æŸ¥å¤±è´¥: {e}")
        return False


def monitor_pipeline():
    """ç›‘æ§å®Œæ•´ç®¡é“çš„æ•°æ®æµ"""
    logger.info("\n=== æµ‹è¯•3ï¼šç›‘æ§æ•°æ®æµ ===")

    streams = [
        (redis_config.STREAM_NEWS_RAW, "åŸå§‹æ–°é—»"),
        (redis_config.STREAM_NEWS_FILTERED, "è¿‡æ»¤åæ–°é—»"),
        (redis_config.STREAM_SIGNALS, "äº¤æ˜“ä¿¡å·"),
        (redis_config.STREAM_DEADLETTER, "æ­»ä¿¡é˜Ÿåˆ—"),
    ]

    results = {}
    for stream_key, description in streams:
        logger.info(f"\næ£€æŸ¥ {description} ({stream_key}):")
        results[stream_key] = check_stream_data(stream_key)

    return all(results.values())


def test_signal_generation():
    """æµ‹è¯•ä¿¡å·ç”Ÿæˆï¼ˆéœ€è¦å…ˆè¿è¡Œæ¶ˆè´¹è€…ï¼‰"""
    logger.info("\n=== æµ‹è¯•4ï¼šä¿¡å·ç”ŸæˆéªŒè¯ ===")
    logger.info("æç¤ºï¼šæ­¤æµ‹è¯•éœ€è¦ news_filter_consumer å’Œ signal_generator_consumer æ­£åœ¨è¿è¡Œ")
    logger.info("ç­‰å¾…10ç§’è®©æ¶ˆè´¹è€…å¤„ç†...")

    time.sleep(10)

    try:
        client = redis.Redis(
            host=redis_config.host,
            port=redis_config.port,
            db=redis_config.db,
            decode_responses=True
        )

        # æ£€æŸ¥ signals stream
        signals = client.xrevrange(redis_config.STREAM_SIGNALS, count=5)

        if signals:
            logger.info(f"âœ“ å‘ç° {len(signals)} ä¸ªä¿¡å·:")

            for msg_id, msg_data in signals:
                # è§£æä¿¡å·æ•°æ®
                import json

                signal_data = {}
                for key, value in msg_data.items():
                    try:
                        signal_data[key] = json.loads(value)
                    except:
                        signal_data[key] = value

                logger.info(f"\nä¿¡å· {msg_id}:")
                logger.info(f"  Ticker: {signal_data.get('ticker', 'N/A')}")
                logger.info(f"  æ–¹å‘: {signal_data.get('direction', 'N/A')}")
                logger.info(f"  æ‰‹æ•°: {signal_data.get('lot_size', 'N/A')}")
                logger.info(f"  æ­¢æŸ: {signal_data.get('stop_loss', 'N/A')}")
                logger.info(f"  æ­¢ç›ˆ: {signal_data.get('take_profit', 'N/A')}")
                logger.info(f"  æƒ…æ„Ÿ: {signal_data.get('sentiment', 'N/A')} (score={signal_data.get('sentiment_score', 'N/A')})")
                logger.info(f"  èµ„äº§ç±»åˆ«: {signal_data.get('asset_class', 'N/A')}")

            return True
        else:
            logger.warning("âš ï¸ æœªå‘ç°ä¿¡å·")
            logger.info("å¯èƒ½åŸå› ï¼š")
            logger.info("  1. æ¶ˆè´¹è€…æœªè¿è¡Œ")
            logger.info("  2. æ–°é—»æœªé€šè¿‡æƒ…æ„Ÿé˜ˆå€¼è¿‡æ»¤")
            logger.info("  3. å¤„ç†æ—¶é—´è¾ƒé•¿ï¼Œè¯·ç¨åå†æ£€æŸ¥")
            return False

    except Exception as e:
        logger.error(f"âœ— æ£€æŸ¥ä¿¡å·å¤±è´¥: {e}")
        return False


def cleanup_test_data():
    """æ¸…ç†æµ‹è¯•æ•°æ®ï¼ˆå¯é€‰ï¼‰"""
    logger.info("\n=== æ¸…ç†æµ‹è¯•æ•°æ® ===")
    logger.info("æç¤ºï¼šå¦‚éœ€æ¸…ç†ï¼Œè¯·æ‰‹åŠ¨è¿è¡Œ: redis-cli FLUSHDB")


def main():
    """ä¸»æµ‹è¯•æµç¨‹"""
    logger.info("=" * 60)
    logger.info("MT5-CRS é©±åŠ¨ç®¡å®¶ç³»ç»Ÿ - ç«¯åˆ°ç«¯æµ‹è¯•")
    logger.info("=" * 60)
    logger.info("\næµ‹è¯•æµç¨‹ï¼š")
    logger.info("1. æµ‹è¯• Redis è¿æ¥")
    logger.info("2. å‘å¸ƒæµ‹è¯•æ–°é—»åˆ° news_raw")
    logger.info("3. ç›‘æ§å„ stream çš„æ•°æ®")
    logger.info("4. éªŒè¯ä¿¡å·ç”Ÿæˆ")
    logger.info("\næ³¨æ„ï¼šæµ‹è¯•3å’Œ4éœ€è¦æ¶ˆè´¹è€…è¿›ç¨‹æ­£åœ¨è¿è¡Œï¼")
    logger.info("=" * 60 + "\n")

    results = {}

    # æµ‹è¯•1ï¼šRedis è¿æ¥
    results['redis'] = test_redis_connection()
    if not results['redis']:
        logger.error("\nâŒ Redis è¿æ¥å¤±è´¥ï¼Œè¯·å…ˆå¯åŠ¨ Redis")
        return False

    # æµ‹è¯•2ï¼šå‘å¸ƒæµ‹è¯•æ–°é—»
    results['publish'] = publish_test_news()
    if not results['publish']:
        logger.error("\nâŒ å‘å¸ƒæµ‹è¯•æ–°é—»å¤±è´¥")
        return False

    # æµ‹è¯•3ï¼šç›‘æ§ç®¡é“
    results['monitor'] = monitor_pipeline()

    # æµ‹è¯•4ï¼šéªŒè¯ä¿¡å·
    results['signals'] = test_signal_generation()

    # æ€»ç»“
    logger.info("\n" + "=" * 60)
    logger.info("æµ‹è¯•æ€»ç»“")
    logger.info("=" * 60)

    passed = sum(results.values())
    total = len(results)

    for test_name, result in results.items():
        status = "âœ“ é€šè¿‡" if result else "âœ— å¤±è´¥"
        logger.info(f"  {test_name}: {status}")

    logger.info(f"\næ€»è®¡: {passed}/{total} é€šè¿‡")

    if passed == total:
        logger.info("\nğŸ‰ æ‰€æœ‰æµ‹è¯•é€šè¿‡ï¼")
        logger.info("\nå®Œæ•´ç®¡é“å·¥ä½œæ­£å¸¸ï¼š")
        logger.info("  æ–°é—»å‘å¸ƒ â†’ æƒ…æ„Ÿåˆ†æ â†’ ä¿¡å·ç”Ÿæˆ âœ…")
    else:
        logger.warning("\nâš ï¸ éƒ¨åˆ†æµ‹è¯•æœªé€šè¿‡")
        logger.info("\nå»ºè®®æ£€æŸ¥ï¼š")
        logger.info("  1. æ¶ˆè´¹è€…è¿›ç¨‹æ˜¯å¦åœ¨è¿è¡Œ")
        logger.info("  2. FinBERT æ¨¡å‹æ˜¯å¦å·²ä¸‹è½½")
        logger.info("  3. æŸ¥çœ‹æ¶ˆè´¹è€…æ—¥å¿—æ’æŸ¥é—®é¢˜")

    logger.info("=" * 60 + "\n")

    return passed == total


if __name__ == "__main__":
    try:
        success = main()
        sys.exit(0 if success else 1)
    except KeyboardInterrupt:
        logger.info("\n\næµ‹è¯•è¢«ä¸­æ–­")
        sys.exit(1)
    except Exception as e:
        logger.error(f"\næµ‹è¯•å‡ºé”™: {e}", exc_info=True)
        sys.exit(1)

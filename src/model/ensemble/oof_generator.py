#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
Task #073: Out-of-Fold Prediction Generator

Generate OOF (Out-of-Fold) predictions for LightGBM and LSTM models using Purged K-Fold
cross-validation without data leakage for financial time-series data.

The OOF predictions serve as meta-features for training the stacking meta-learner.

Protocol v4.3 (Zero-Trust Edition)
"""

import numpy as np
import logging
from typing import Tuple, Optional
import torch

# Configure logging
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)


class OOFPredictionGenerator:
    """
    Generate Out-of-Fold (OOF) predictions for ensemble stacking

    OOF predictions are generated by:
    1. Splitting training data into K folds using Purged K-Fold
    2. For each fold:
       - Train base models on fold's training set
       - Generate predictions on fold's validation set
       - Accumulate predictions into full-coverage arrays
    3. Return complete OOF arrays for all samples without data leakage

    Key Properties:
    - LightGBM OOF shape: (N_samples, 3) - predictions for all samples
    - LSTM OOF shape: (N_windows, 3) where N_windows = N_samples - 59
    - Valid indices: [59...N-1] - indices where both models can predict
    - No data leakage: Each fold's OOF comes from model trained on other folds
    """

    def __init__(self, cv_splitter=None, alignment_handler=None):
        """
        Initialize OOF generator

        Args:
            cv_splitter: Cross-validator (e.g., PurgedKFold). If None, will be imported.
            alignment_handler: DataAlignmentHandler for index mapping. If None, will be imported.
        """
        if cv_splitter is None:
            from src.models.validation import PurgedKFold
            self.cv = PurgedKFold(n_splits=5, embargo_pct=0.01)
        else:
            self.cv = cv_splitter

        if alignment_handler is None:
            from src.model.ensemble.alignment import DataAlignmentHandler
            self.alignment = DataAlignmentHandler()
        else:
            self.alignment = alignment_handler

        logger.info(f"OOFPredictionGenerator initialized with {self.cv.n_splits} splits")

    def generate_oof_predictions(
        self,
        lgb_predictor,
        lstm_predictor,
        X_tabular: np.ndarray,
        X_sequential,
        y_train: np.ndarray
    ) -> Tuple[np.ndarray, np.ndarray, np.ndarray]:
        """
        Generate OOF predictions for LightGBM and LSTM models

        Args:
            lgb_predictor: LGBPredictor instance
            lstm_predictor: LSTMPredictor instance
            X_tabular: (N_samples, 23) features for LightGBM
            X_sequential: (N_samples, seq_len, 23) or sliding window sequences for LSTM
            y_train: (N_samples,) training labels (before windowing)

        Returns:
            lgb_oof: (N_samples, 3) LightGBM OOF probabilities
            lstm_oof: (N_windows, 3) LSTM OOF probabilities
            valid_indices: Array of indices [59...N-1] where both models predict
        """
        N_samples = X_tabular.shape[0]

        # Initialize OOF arrays
        lgb_oof = np.zeros((N_samples, 3), dtype=np.float32)

        # LSTM windows: one window per valid sample [59...N-1]
        N_windows = self.alignment.create_index_mapping(N_samples)['N_windows']
        lstm_oof = np.zeros((N_windows, 3), dtype=np.float32)

        logger.info(f"Generating OOF predictions for {N_samples} samples")
        logger.info(f"Expected LSTM windows: {N_windows}")

        # Generate OOF for each fold
        for fold_num, (train_idx, val_idx) in enumerate(
            self.cv.split(X_tabular, y_train), 1
        ):
            logger.info(f"Processing fold {fold_num}/{self.cv.n_splits}")
            logger.info(f"  Train samples: {len(train_idx)}, Validation samples: {len(val_idx)}")

            # Split tabular data
            X_tab_train = X_tabular[train_idx]
            X_tab_val = X_tabular[val_idx]

            # Generate LightGBM OOF for validation fold
            # No training needed - just predict with pre-trained model
            fold_lgb_proba = lgb_predictor.predict_proba(X_tab_val)  # (|val_idx|, 3)
            lgb_oof[val_idx] = fold_lgb_proba

            logger.info(f"  LGB OOF shape: {fold_lgb_proba.shape}")

            # For LSTM: generate OOF predictions on sliding window sequences
            # X_sequential should contain windows corresponding to validation fold
            # Map validation indices to corresponding window indices
            try:
                # Get window indices corresponding to validation fold indices
                # Valid indices are [59...N-1], so fold's validation windows are
                # those windows where (window_idx + 59) in val_idx
                lstm_val_window_indices = []
                for i, val_sample_idx in enumerate(val_idx):
                    # Window index for sample at original index val_sample_idx
                    # is (val_sample_idx - 59) if val_sample_idx >= 59
                    if val_sample_idx >= 59:
                        lstm_val_window_indices.append(val_sample_idx - 59)

                if len(lstm_val_window_indices) > 0:
                    lstm_val_window_indices = np.array(lstm_val_window_indices)

                    # Extract corresponding sequences from X_sequential
                    # Assuming X_sequential is (N_windows, seq_len, n_features)
                    if isinstance(X_sequential, torch.Tensor):
                        X_seq_val = X_sequential[lstm_val_window_indices]
                    else:
                        X_seq_val = X_sequential[lstm_val_window_indices]

                    # Generate LSTM OOF for validation windows
                    fold_lstm_proba = lstm_predictor.predict_proba(X_seq_val)  # (|windows|, 3)

                    # Map window predictions back to OOF array
                    # LSTM OOF indices are offset by 59 from original sample indices
                    lstm_oof[lstm_val_window_indices] = fold_lstm_proba

                    logger.info(f"  LSTM OOF windows: {len(lstm_val_window_indices)}, shape: {fold_lstm_proba.shape}")
                else:
                    logger.warning(f"  No valid LSTM windows in fold {fold_num}")

            except Exception as e:
                logger.error(f"Error processing LSTM OOF for fold {fold_num}: {e}")
                raise

        # Verify OOF coverage
        logger.info("Verifying OOF coverage...")
        lgb_nans = np.isnan(lgb_oof).sum()
        lstm_nans = np.isnan(lstm_oof).sum()

        if lgb_nans > 0:
            logger.warning(f"LGB OOF has {lgb_nans} NaN values")
        if lstm_nans > 0:
            logger.warning(f"LSTM OOF has {lstm_nans} NaN values")

        # Get valid indices where both models have predictions
        valid_indices = self.alignment.get_valid_indices(N_samples)

        logger.info(f"OOF generation complete:")
        logger.info(f"  LGB OOF shape: {lgb_oof.shape}, dtype: {lgb_oof.dtype}")
        logger.info(f"  LSTM OOF shape: {lstm_oof.shape}, dtype: {lstm_oof.dtype}")
        logger.info(f"  Valid indices: {len(valid_indices)} samples [{valid_indices[0]}...{valid_indices[-1]}]")

        return lgb_oof, lstm_oof, valid_indices

    def _create_sliding_window_sequences(
        self,
        X: np.ndarray,
        sequence_length: int = 60,
        stride: int = 1
    ) -> np.ndarray:
        """
        Create sliding window sequences from 2D feature matrix

        Args:
            X: (N_samples, n_features) input data
            sequence_length: Length of sliding windows
            stride: Step size for sliding windows

        Returns:
            (N_windows, sequence_length, n_features) sliding window sequences
        """
        N_samples, n_features = X.shape
        N_windows = (N_samples - sequence_length) // stride + 1

        windows = np.zeros((N_windows, sequence_length, n_features), dtype=np.float32)

        for i in range(N_windows):
            start_idx = i * stride
            end_idx = start_idx + sequence_length
            windows[i] = X[start_idx:end_idx]

        return windows


if __name__ == "__main__":
    logger.info("Testing OOFPredictionGenerator...")
    logger.info("(Full test requires loading actual models from MLflow)")

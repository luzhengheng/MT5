# 核心代码文件

## src/strategy/risk_manager.py

```python
"""
风险管理模块 - Kelly Criterion 注码策略与动态风控 (Architect Approved)
"""

import backtrader as bt
import numpy as np
import math
import logging
from typing import Optional
from src.strategy.session_risk_manager import SessionRiskManager, get_session_risk_manager

logger = logging.getLogger(__name__)

class KellySizer(bt.Sizer):
    """
    Kelly Criterion 仓位管理器 (MT5 实盘优化版)
    包含: 手数取整 (Lot Quantization)、实盘资金检查、ATR 保护
    """

    params = (
        ('kelly_fraction', 0.25),  # 四分之一 Kelly
        ('max_position_pct', 0.50),
        ('min_position_pct', 0.01),
        ('stop_loss_multiplier', 2.0),
        ('max_leverage', 3.0),
        ('max_risk_per_trade', 0.02),
        ('use_hierarchical_signals', True),
        ('lot_step', 0.01),  # MT5 标准最小手数步长
    )

    def _get_win_probability(self, data, isbuy: bool) -> Optional[float]:
        """获取交易胜率 (优先使用 ML 置信度)"""
        p_win = None
        if self.params.use_hierarchical_signals:
            try:
                if hasattr(self.strategy, 'hierarchical_signals'):
                    fusion = self.strategy.hierarchical_signals.get_last_signal()
                    if fusion: return fusion.confidence
            except: pass
        
        # 回退到数据源
        try:
            p_win = data.y_pred_proba_long[0] if isbuy else data.y_pred_proba_short[0]
            if not np.isnan(p_win) and p_win > 0: return p_win
        except: pass
        return None

    def _getsizing(self, comminfo, cash, data, isbuy):
        """计算仓位大小 (核心逻辑)"""
        # 1. 获取账户价值 (实盘优先使用 getcash)
        if hasattr(self.broker, 'getcash'):
            account_value = self.broker.getcash()
        else:
            account_value = self.broker.getvalue()

        current_price = data.close[0]
        if current_price <= 0: return 0

        # 2. 获取胜率 & 赔率
        p_win = self._get_win_probability(data, isbuy)
        if not p_win: return 0
        
        b = getattr(self.strategy.params, 'take_profit_ratio', 2.0)
        
        # 3. Kelly 公式
        kelly_f = (p_win * (b + 1) - 1) / b
        if kelly_f <= 0: return 0
        
        risk_pct = kelly_f * self.params.kelly_fraction
        
        # 4. 硬性风控约束
        risk_pct = min(risk_pct, self.params.max_risk_per_trade)
        max_risk_amt = account_value * risk_pct

        # 5. ATR 计算
        try:
            atr = self.strategy.atr[0]
        except:
            # 架构师要求：如果没有 ATR，不要瞎猜，直接拒绝开仓
            logger.warning("ATR data missing, skipping trade for safety.")
            return 0

        if atr <= 0: return 0
        
        # 6. 计算止损距离与原始仓位
        sl_dist = atr * self.params.stop_loss_multiplier
        if sl_dist == 0: return 0
        
        raw_size = max_risk_amt / sl_dist

        # 7. 杠杆检查
        if (raw_size * current_price) > (account_value * self.params.max_leverage):
            raw_size = (account_value * self.params.max_leverage) / current_price

        # 8. ✅ MT5 手数取整 (Lot Quantization) - 关键修复
        # 向下取整到最近的 lot_step (如 0.01)
        step = self.params.lot_step
        size = math.floor(raw_size / step) * step
        
        # 9. 最小手数检查
        if size < step:
            return 0

        logger.info(f"Sizer: P={p_win:.2f} Risk%={risk_pct:.1%} Size={size:.2f} (Price={current_price:.2f})")
        
        return size

class DynamicRiskManager:
    """动态风险管理器 (保留原有逻辑)"""
    def __init__(self, broker, max_drawdown_pct=10.0, stop_trading_on_breach=True, daily_loss_limit=-0.05):
        self.broker = broker
        self.max_drawdown_pct = max_drawdown_pct / 100.0
        self.stop_trading_on_breach = stop_trading_on_breach
        self.peak_value = broker.getvalue()
        self.is_halted = False
        self.session_risk = get_session_risk_manager(daily_loss_limit)

    def update(self):
        val = self.broker.getvalue()
        if val > self.peak_value: 
            self.peak_value = val
            self.is_halted = False
        
        dd = (self.peak_value - val) / self.peak_value
        if dd > self.max_drawdown_pct: self.is_halted = True
        return {'drawdown': dd, 'is_halted': self.is_halted}

    def can_trade(self):
        if self.is_halted: return False
        if not self.session_risk.can_trade(): return False
        return True

```

## src/feature_engineering/basic_features.py

```python
"""
基础技术指标特征计算
使用 pandas 和 numpy 实现（避免 ta-lib 依赖）
"""

import numpy as np
import pandas as pd
import logging

logger = logging.getLogger(__name__)


class BasicFeatures:
    """基础技术指标特征计算器"""

    @staticmethod
    def compute_ema(series: pd.Series, period: int) -> pd.Series:
        """计算指数移动平均（EMA）"""
        return series.ewm(span=period, adjust=False).mean()

    @staticmethod
    def compute_sma(series: pd.Series, period: int) -> pd.Series:
        """计算简单移动平均（SMA）"""
        return series.rolling(window=period).mean()

    @staticmethod
    def compute_rsi(series: pd.Series, period: int = 14) -> pd.Series:
        """计算相对强弱指标（RSI）"""
        delta = series.diff()
        gain = (delta.where(delta > 0, 0)).rolling(window=period).mean()
        loss = (-delta.where(delta < 0, 0)).rolling(window=period).mean()

        rs = gain / loss
        rsi = 100 - (100 / (1 + rs))
        return rsi

    @staticmethod
    def compute_macd(series: pd.Series, fast: int = 12, slow: int = 26, signal: int = 9) -> pd.DataFrame:
        """计算 MACD 指标"""
        ema_fast = BasicFeatures.compute_ema(series, fast)
        ema_slow = BasicFeatures.compute_ema(series, slow)

        macd_line = ema_fast - ema_slow
        signal_line = BasicFeatures.compute_ema(macd_line, signal)
        histogram = macd_line - signal_line

        return pd.DataFrame({
            'macd': macd_line,
            'macd_signal': signal_line,
            'macd_hist': histogram
        })

    @staticmethod
    def compute_atr(high: pd.Series, low: pd.Series, close: pd.Series, period: int = 14) -> pd.Series:
        """计算平均真实波幅（ATR）"""
        # True Range
        tr1 = high - low
        tr2 = abs(high - close.shift())
        tr3 = abs(low - close.shift())

        tr = pd.concat([tr1, tr2, tr3], axis=1).max(axis=1)

        # ATR 是 TR 的移动平均
        atr = tr.rolling(window=period).mean()
        return atr

    @staticmethod
    def compute_bollinger_bands(series: pd.Series, period: int = 20, std: int = 2) -> pd.DataFrame:
        """计算布林带"""
        sma = BasicFeatures.compute_sma(series, period)
        rolling_std = series.rolling(window=period).std()

        upper = sma + (rolling_std * std)
        lower = sma - (rolling_std * std)

        return pd.DataFrame({
            'bbands_upper': upper,
            'bbands_middle': sma,
            'bbands_lower': lower,
            'bbands_width': (upper - lower) / sma
        })

    @staticmethod
    def compute_stochastic(high: pd.Series, low: pd.Series, close: pd.Series,
                          k_period: int = 14, d_period: int = 3) -> pd.DataFrame:
        """计算随机震荡指标（Stochastic）"""
        lowest_low = low.rolling(window=k_period).min()
        highest_high = high.rolling(window=k_period).max()

        k = 100 * (close - lowest_low) / (highest_high - lowest_low)
        d = k.rolling(window=d_period).mean()

        return pd.DataFrame({
            'stochastic_k': k,
            'stochastic_d': d
        })

    @staticmethod
    def compute_williams_r(high: pd.Series, low: pd.Series, close: pd.Series, period: int = 14) -> pd.Series:
        """计算威廉指标（Williams %R）"""
        highest_high = high.rolling(window=period).max()
        lowest_low = low.rolling(window=period).min()

        williams_r = -100 * (highest_high - close) / (highest_high - lowest_low)
        return williams_r

    @staticmethod
    def compute_roc(series: pd.Series, period: int = 10) -> pd.Series:
        """计算变化率（ROC - Rate of Change）"""
        roc = ((series - series.shift(period)) / series.shift(period)) * 100
        return roc

    @staticmethod
    def compute_obv(close: pd.Series, volume: pd.Series) -> pd.Series:
        """计算能量潮（OBV - On-Balance Volume）"""
        obv = (np.sign(close.diff()) * volume).fillna(0).cumsum()
        return obv

    @staticmethod
    def compute_realized_volatility(returns: pd.Series, period: int = 20) -> pd.Series:
        """计算已实现波动率"""
        return returns.rolling(window=period).std() * np.sqrt(252)  # 年化

    @staticmethod
    def compute_returns(close: pd.Series, periods: list = [1, 3, 5, 10, 20]) -> pd.DataFrame:
        """计算多期滞后回报"""
        returns_df = pd.DataFrame()

        for period in periods:
            returns_df[f'return_{period}d'] = close.pct_change(period)

        return returns_df

    @staticmethod
    def compute_all_basic_features(df: pd.DataFrame) -> pd.DataFrame:
        """
        计算所有基础特征（30 维）

        Args:
            df: 必须包含 ['open', 'high', 'low', 'close', 'volume'] 列

        Returns:
            添加了基础特征的 DataFrame
        """
        df = df.copy()

        logger.info("计算基础技术指标特征...")

        # 趋势类特征 (10 维)
        df['ema_12'] = BasicFeatures.compute_ema(df['close'], 12)
        df['ema_26'] = BasicFeatures.compute_ema(df['close'], 26)
        df['ema_50'] = BasicFeatures.compute_ema(df['close'], 50)
        df['ema_200'] = BasicFeatures.compute_ema(df['close'], 200)
        df['sma_20'] = BasicFeatures.compute_sma(df['close'], 20)
        df['sma_60'] = BasicFeatures.compute_sma(df['close'], 60)

        df['price_vs_ema200'] = (df['close'] - df['ema_200']) / df['ema_200']
        df['golden_cross'] = (df['ema_50'] > df['ema_200']).astype(int)
        df['death_cross'] = (df['ema_50'] < df['ema_200']).astype(int)
        df['trend_strength'] = (df['ema_12'] - df['ema_200']) / df['ema_200']

        # 动量类特征 (8 维)
        df['rsi_14'] = BasicFeatures.compute_rsi(df['close'], 14)
        macd_df = BasicFeatures.compute_macd(df['close'])
        df = pd.concat([df, macd_df], axis=1)
        df['roc_10'] = BasicFeatures.compute_roc(df['close'], 10)

        stoch_df = BasicFeatures.compute_stochastic(df['high'], df['low'], df['close'])
        df = pd.concat([df, stoch_df], axis=1)

        df['williams_r'] = BasicFeatures.compute_williams_r(df['high'], df['low'], df['close'], 14)

        # 波动类特征 (6 维)
        df['atr_14'] = BasicFeatures.compute_atr(df['high'], df['low'], df['close'], 14)

        bbands_df = BasicFeatures.compute_bollinger_bands(df['close'])
        df = pd.concat([df, bbands_df], axis=1)

        df['return_1d'] = df['close'].pct_change()
        df['realized_volatility_20'] = BasicFeatures.compute_realized_volatility(df['return_1d'], 20)

        # 成交量类特征 (3 维)
        df['volume_sma20'] = BasicFeatures.compute_sma(df['volume'], 20)
        df['volume_ratio'] = df['volume'] / df['volume_sma20']
        df['obv'] = BasicFeatures.compute_obv(df['close'], df['volume'])

        # 滞后回报类特征 (5 维) - return_1d 已计算
        returns_df = BasicFeatures.compute_returns(df['close'], periods=[3, 5, 10, 20])
        df = pd.concat([df, returns_df], axis=1)

        logger.info(f"基础特征计算完成，新增 {len(df.columns) - 6} 个特征")

        return df


def main():
    """测试基础特征计算"""
    # 创建测试数据
    dates = pd.date_range('2023-01-01', periods=300, freq='D')
    np.random.seed(42)

    test_df = pd.DataFrame({
        'date': dates,
        'open': 100 + np.random.randn(300).cumsum(),
        'high': 101 + np.random.randn(300).cumsum(),
        'low': 99 + np.random.randn(300).cumsum(),
        'close': 100 + np.random.randn(300).cumsum(),
        'volume': np.random.randint(1000000, 10000000, 300)
    })

    print("原始数据:")
    print(test_df.head())
    print(f"\n原始列数: {len(test_df.columns)}")

    # 计算基础特征
    result_df = BasicFeatures.compute_all_basic_features(test_df)

    print(f"\n添加特征后列数: {len(result_df.columns)}")
    print("\n新增特征:")
    new_features = [col for col in result_df.columns if col not in test_df.columns]
    for i, feat in enumerate(new_features, 1):
        print(f"{i:2d}. {feat}")

    print(f"\n特征数据预览:")
    print(result_df[new_features].tail(5))

    # 检查缺失值
    print(f"\n缺失值统计:")
    missing_counts = result_df[new_features].isnull().sum()
    print(missing_counts[missing_counts > 0])

    print(f"\n特征完整率: {(1 - result_df[new_features].isnull().sum().sum() / (len(result_df) * len(new_features))):.2%}")


if __name__ == '__main__':
    main()

```

## src/feature_engineering/advanced_features.py

```python
"""
高级特征工程模块 - 实现 40 维高级特征
包括:
1. Fractional Differentiation (6 维)
2. Rolling Statistics (12 维)
3. Cross-Sectional Rank (6 维)
4. Sentiment Momentum (8 维)
5. Adaptive Window Features (3 维)
6. Cross-Asset Features (5 维)
"""

import logging
import numpy as np
import pandas as pd
from typing import Dict, List, Optional

logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)


class AdvancedFeatures:
    """高级特征计算类"""

    @staticmethod
    def fractional_diff(series: pd.Series, d: float = 0.5, threshold: float = 1e-5) -> pd.Series:
        """
        分数阶差分 (Fractional Differentiation)
        保留记忆性的同时实现平稳化

        来源: "Advances in Financial Machine Learning" by Marcos Lopez de Prado

        Args:
            series: 时间序列
            d: 差分阶数 (0 < d < 1)，d=1 为完全差分，d=0.5 为半差分
            threshold: 权重截断阈值

        Returns:
            分数阶差分后的序列
        """
        # 计算权重
        weights = [1.0]
        k = 1

        # 迭代计算权重直到小于阈值
        while True:
            weight = -weights[-1] * (d - k + 1) / k
            if abs(weight) < threshold:
                break
            weights.append(weight)
            k += 1

        weights = np.array(weights[::-1])  # 反转权重

        # 应用卷积
        result = pd.Series(index=series.index, dtype=float)
        for i in range(len(weights) - 1, len(series)):
            result.iloc[i] = np.dot(weights, series.iloc[i - len(weights) + 1:i + 1])

        return result

    @staticmethod
    def compute_fractional_features(df: pd.DataFrame) -> pd.DataFrame:
        """
        计算 Fractional Differentiation 特征 (6 维)

        特征列表:
        1. frac_diff_close_05: 收盘价 d=0.5 分数差分
        2. frac_diff_close_07: 收盘价 d=0.7 分数差分
        3. frac_diff_volume_05: 成交量 d=0.5 分数差分
        4. frac_diff_returns_05: 收益率 d=0.5 分数差分
        5. frac_diff_volatility_05: 波动率 d=0.5 分数差分
        6. frac_diff_sentiment_05: 情感 d=0.5 分数差分

        Args:
            df: 包含 OHLCV 和情感数据的 DataFrame

        Returns:
            添加了 Fractional Differentiation 特征的 DataFrame
        """
        logger.info("计算 Fractional Differentiation 特征...")

        # 1. 收盘价 d=0.5
        df['frac_diff_close_05'] = AdvancedFeatures.fractional_diff(
            df['close'], d=0.5
        )

        # 2. 收盘价 d=0.7 (更强的差分)
        df['frac_diff_close_07'] = AdvancedFeatures.fractional_diff(
            df['close'], d=0.7
        )

        # 3. 成交量 d=0.5
        df['frac_diff_volume_05'] = AdvancedFeatures.fractional_diff(
            df['volume'], d=0.5
        )

        # 4. 收益率 d=0.5
        returns = df['close'].pct_change()
        df['frac_diff_returns_05'] = AdvancedFeatures.fractional_diff(
            returns, d=0.5
        )

        # 5. 波动率 d=0.5 (使用 20 日滚动标准差)
        volatility = df['close'].pct_change().rolling(window=20).std()
        df['frac_diff_volatility_05'] = AdvancedFeatures.fractional_diff(
            volatility, d=0.5
        )

        # 6. 情感 d=0.5
        if 'sentiment_mean' in df.columns:
            df['frac_diff_sentiment_05'] = AdvancedFeatures.fractional_diff(
                df['sentiment_mean'], d=0.5
            )
        else:
            df['frac_diff_sentiment_05'] = 0.0

        logger.info("Fractional Differentiation 特征计算完成 (6 维)")
        return df

    @staticmethod
    def compute_rolling_statistics(df: pd.DataFrame) -> pd.DataFrame:
        """
        计算滚动统计特征 (12 维)

        特征列表:
        1. roll_skew_20: 20 日收益率偏度
        2. roll_kurt_20: 20 日收益率峰度
        3. roll_skew_60: 60 日收益率偏度
        4. roll_kurt_60: 60 日收益率峰度
        5. roll_autocorr_1: 收益率自相关(lag=1)
        6. roll_autocorr_5: 收益率自相关(lag=5)
        7. roll_max_drawdown_20: 20 日最大回撤
        8. roll_max_drawdown_60: 60 日最大回撤
        9. roll_sharpe_20: 20 日 Sharpe 比率
        10. roll_sortino_20: 20 日 Sortino 比率
        11. roll_calmar_60: 60 日 Calmar 比率
        12. roll_tail_ratio_20: 20 日尾部比率 (95th/5th percentile)

        Args:
            df: DataFrame

        Returns:
            添加了滚动统计特征的 DataFrame
        """
        logger.info("计算 Rolling Statistics 特征...")

        returns = df['close'].pct_change()

        # 1-2. 20 日偏度和峰度
        df['roll_skew_20'] = returns.rolling(window=20).skew()
        df['roll_kurt_20'] = returns.rolling(window=20).kurt()

        # 3-4. 60 日偏度和峰度
        df['roll_skew_60'] = returns.rolling(window=60).skew()
        df['roll_kurt_60'] = returns.rolling(window=60).kurt()

        # 5-6. 自相关
        df['roll_autocorr_1'] = returns.rolling(window=20).apply(
            lambda x: x.autocorr(lag=1) if len(x) > 1 else np.nan
        )
        df['roll_autocorr_5'] = returns.rolling(window=20).apply(
            lambda x: x.autocorr(lag=5) if len(x) > 5 else np.nan
        )

        # 7-8. 最大回撤
        def max_drawdown(prices):
            cumulative = (1 + prices).cumprod()
            running_max = cumulative.expanding().max()
            drawdown = (cumulative - running_max) / running_max
            return drawdown.min()

        df['roll_max_drawdown_20'] = returns.rolling(window=20).apply(max_drawdown)
        df['roll_max_drawdown_60'] = returns.rolling(window=60).apply(max_drawdown)

        # 9. Sharpe 比率 (假设无风险利率=0)
        df['roll_sharpe_20'] = (
            returns.rolling(window=20).mean() / returns.rolling(window=20).std()
        ) * np.sqrt(252)  # 年化

        # 10. Sortino 比率 (只考虑下行波动)
        def sortino_ratio(rets):
            downside = rets[rets < 0]
            if len(downside) > 0:
                downside_std = downside.std()
                if downside_std > 0:
                    return (rets.mean() / downside_std) * np.sqrt(252)
            return np.nan

        df['roll_sortino_20'] = returns.rolling(window=20).apply(sortino_ratio)

        # 11. Calmar 比率 (收益率 / 最大回撤)
        df['roll_calmar_60'] = (
            returns.rolling(window=60).mean() * 252 /  # 年化收益
            df['roll_max_drawdown_60'].abs()
        )

        # 12. 尾部比率
        def tail_ratio(rets):
            if len(rets) > 0:
                p95 = np.percentile(rets, 95)
                p05 = np.percentile(rets, 5)
                if p05 != 0:
                    return abs(p95 / p05)
            return np.nan

        df['roll_tail_ratio_20'] = returns.rolling(window=20).apply(tail_ratio)

        logger.info("Rolling Statistics 特征计算完成 (12 维)")
        return df

    @staticmethod
    def compute_cross_sectional_rank(df: pd.DataFrame, all_dfs: Dict[str, pd.DataFrame] = None) -> pd.DataFrame:
        """
        计算横截面排名特征 (6 维)
        相对于所有资产的排名

        特征列表:
        1. cs_rank_return_1d: 1 日收益率横截面排名
        2. cs_rank_return_5d: 5 日收益率横截面排名
        3. cs_rank_volatility: 波动率横截面排名
        4. cs_rank_volume: 成交量横截面排名
        5. cs_rank_rsi: RSI 横截面排名
        6. cs_rank_sentiment: 情感横截面排名

        Args:
            df: 当前资产的 DataFrame
            all_dfs: 所有资产的 DataFrame 字典 {symbol: df}

        Returns:
            添加了横截面排名特征的 DataFrame
        """
        logger.info("计算 Cross-Sectional Rank 特征...")

        if all_dfs is None or len(all_dfs) < 2:
            # 如果没有其他资产数据,设置为中位数 0.5
            logger.warning("没有其他资产数据,横截面排名特征设为 0.5")
            df['cs_rank_return_1d'] = 0.5
            df['cs_rank_return_5d'] = 0.5
            df['cs_rank_volatility'] = 0.5
            df['cs_rank_volume'] = 0.5
            df['cs_rank_rsi'] = 0.5
            df['cs_rank_sentiment'] = 0.5
            return df

        # 为每个日期计算横截面排名
        dates = df['date'].unique()

        for date in dates:
            # 收集所有资产在该日期的数据
            cross_section = []
            for symbol, other_df in all_dfs.items():
                date_data = other_df[other_df['date'] == date]
                if not date_data.empty:
                    cross_section.append({
                        'symbol': symbol,
                        'return_1d': date_data['return_1d'].iloc[0] if 'return_1d' in date_data.columns else np.nan,
                        'return_5d': date_data['return_5d'].iloc[0] if 'return_5d' in date_data.columns else np.nan,
                        'volatility': date_data['volatility_20d'].iloc[0] if 'volatility_20d' in date_data.columns else np.nan,
                        'volume': date_data['volume'].iloc[0],
                        'rsi': date_data['rsi_14'].iloc[0] if 'rsi_14' in date_data.columns else np.nan,
                        'sentiment': date_data['sentiment_mean'].iloc[0] if 'sentiment_mean' in date_data.columns else 0,
                    })

            if len(cross_section) > 1:
                cs_df = pd.DataFrame(cross_section)

                # 计算排名 (百分位数)
                current_symbol = df[df['date'] == date]['symbol'].iloc[0] if 'symbol' in df.columns else None

                if current_symbol:
                    for col, feature in [
                        ('return_1d', 'cs_rank_return_1d'),
                        ('return_5d', 'cs_rank_return_5d'),
                        ('volatility', 'cs_rank_volatility'),
                        ('volume', 'cs_rank_volume'),
                        ('rsi', 'cs_rank_rsi'),
                        ('sentiment', 'cs_rank_sentiment'),
                    ]:
                        if col in cs_df.columns:
                            cs_df[feature] = cs_df[col].rank(pct=True)
                            rank_value = cs_df[cs_df['symbol'] == current_symbol][feature].iloc[0] if not cs_df[cs_df['symbol'] == current_symbol].empty else 0.5
                            df.loc[df['date'] == date, feature] = rank_value

        logger.info("Cross-Sectional Rank 特征计算完成 (6 维)")
        return df

    @staticmethod
    def compute_sentiment_momentum(df: pd.DataFrame) -> pd.DataFrame:
        """
        计算情感动量特征 (8 维)

        特征列表:
        1. sentiment_momentum_5d: 5 日情感动量
        2. sentiment_momentum_20d: 20 日情感动量
        3. sentiment_acceleration: 情感加速度 (动量的变化)
        4. sentiment_divergence: 情感-价格背离 (情感上涨但价格下跌)
        5. sentiment_consistency_5d: 5 日情感一致性 (连续正/负的比例)
        6. sentiment_intensity: 情感强度 (绝对值的均值)
        7. sentiment_volatility_20d: 20 日情感波动率
        8. news_frequency_ma20: 20 日新闻频率移动平均

        Args:
            df: DataFrame

        Returns:
            添加了情感动量特征的 DataFrame
        """
        logger.info("计算 Sentiment Momentum 特征...")

        if 'sentiment_mean' not in df.columns:
            logger.warning("没有情感数据,情感动量特征设为 0")
            for feat in ['sentiment_momentum_5d', 'sentiment_momentum_20d',
                        'sentiment_acceleration', 'sentiment_divergence',
                        'sentiment_consistency_5d', 'sentiment_intensity',
                        'sentiment_volatility_20d', 'news_frequency_ma20']:
                df[feat] = 0.0
            return df

        # 1-2. 情感动量
        df['sentiment_momentum_5d'] = df['sentiment_mean'] - df['sentiment_mean'].shift(5)
        df['sentiment_momentum_20d'] = df['sentiment_mean'] - df['sentiment_mean'].shift(20)

        # 3. 情感加速度
        df['sentiment_acceleration'] = df['sentiment_momentum_5d'] - df['sentiment_momentum_5d'].shift(5)

        # 4. 情感-价格背离
        price_momentum = df['close'].pct_change(5)
        sentiment_momentum = df['sentiment_momentum_5d']
        df['sentiment_divergence'] = (
            ((sentiment_momentum > 0) & (price_momentum < 0)).astype(int) -
            ((sentiment_momentum < 0) & (price_momentum > 0)).astype(int)
        )

        # 5. 情感一致性 (5 日窗口内同向比例)
        def consistency(series):
            if len(series) == 0:
                return 0
            positive = (series > 0).sum()
            negative = (series < 0).sum()
            return max(positive, negative) / len(series)

        df['sentiment_consistency_5d'] = df['sentiment_mean'].rolling(window=5).apply(consistency)

        # 6. 情感强度
        df['sentiment_intensity'] = df['sentiment_mean'].abs().rolling(window=20).mean()

        # 7. 情感波动率
        df['sentiment_volatility_20d'] = df['sentiment_mean'].rolling(window=20).std()

        # 8. 新闻频率移动平均
        if 'news_count' in df.columns:
            df['news_frequency_ma20'] = df['news_count'].rolling(window=20).mean()
        else:
            df['news_frequency_ma20'] = 0.0

        logger.info("Sentiment Momentum 特征计算完成 (8 维)")
        return df

    @staticmethod
    def compute_adaptive_window_features(df: pd.DataFrame) -> pd.DataFrame:
        """
        计算自适应窗口特征 (3 维)
        根据市场波动率动态调整窗口大小

        特征列表:
        1. adaptive_ma: 自适应移动平均 (基于波动率调整窗口)
        2. adaptive_momentum: 自适应动量
        3. adaptive_volatility_ratio: 自适应波动率比率

        Args:
            df: DataFrame

        Returns:
            添加了自适应窗口特征的 DataFrame
        """
        logger.info("计算 Adaptive Window Features...")

        # 计算基准波动率
        returns = df['close'].pct_change()
        baseline_vol = returns.rolling(window=60).std()
        current_vol = returns.rolling(window=20).std()

        # 波动率比率 (当前/基准)
        vol_ratio = current_vol / baseline_vol
        vol_ratio = vol_ratio.fillna(1.0).clip(0.5, 2.0)  # 限制在 0.5-2 倍

        # 1. 自适应移动平均 (高波动时用短窗口,低波动时用长窗口)
        # 窗口: 10 到 50 天
        adaptive_window = (50 - 40 * (vol_ratio - 0.5) / 1.5).clip(10, 50).astype(int)

        df['adaptive_ma'] = np.nan
        for i in range(len(df)):
            if i >= 50:  # 确保有足够数据
                window = adaptive_window.iloc[i]
                df.loc[df.index[i], 'adaptive_ma'] = df['close'].iloc[i-window:i].mean()

        # 2. 自适应动量
        df['adaptive_momentum'] = df['close'] / df['adaptive_ma'] - 1

        # 3. 自适应波动率比率
        df['adaptive_volatility_ratio'] = vol_ratio

        logger.info("Adaptive Window Features 计算完成 (3 维)")
        return df

    @staticmethod
    def compute_cross_asset_features(df: pd.DataFrame, reference_df: pd.DataFrame = None,
                                    reference_symbol: str = 'GSPC.INDX') -> pd.DataFrame:
        """
        计算跨资产特征 (5 维)
        相对于基准资产(如 S&P 500)的特征

        特征列表:
        1. beta_to_market: 相对市场的 Beta (60日)
        2. correlation_to_market: 与市场的相关性 (60日)
        3. relative_strength: 相对强度 (当前资产收益 / 市场收益)
        4. alpha_to_market: 相对市场的 Alpha
        5. tracking_error: 跟踪误差

        Args:
            df: 当前资产的 DataFrame
            reference_df: 基准资产的 DataFrame
            reference_symbol: 基准资产名称

        Returns:
            添加了跨资产特征的 DataFrame
        """
        logger.info("计算 Cross-Asset Features...")

        if reference_df is None or reference_df.empty:
            logger.warning("没有基准资产数据,跨资产特征设为 0")
            df['beta_to_market'] = 0.0
            df['correlation_to_market'] = 0.0
            df['relative_strength'] = 0.0
            df['alpha_to_market'] = 0.0
            df['tracking_error'] = 0.0
            return df

        # 确保日期对齐
        df['date'] = pd.to_datetime(df['date'])
        reference_df['date'] = pd.to_datetime(reference_df['date'])

        # 合并数据
        merged = pd.merge(
            df[['date', 'close']],
            reference_df[['date', 'close']],
            on='date',
            how='left',
            suffixes=('', '_market')
        )

        # 计算收益率
        merged['return'] = merged['close'].pct_change()
        merged['return_market'] = merged['close_market'].pct_change()

        # 1. Beta (60日滚动)
        def rolling_beta(returns, market_returns):
            """计算 Beta"""
            # 去除 NaN
            mask = ~(np.isnan(returns) | np.isnan(market_returns))
            if mask.sum() < 10:
                return np.nan

            returns_clean = returns[mask]
            market_returns_clean = market_returns[mask]

            # 计算协方差和方差
            if len(returns_clean) < 10:
                return np.nan

            covariance = np.cov(returns_clean, market_returns_clean)[0, 1]
            market_variance = np.var(market_returns_clean)

            if market_variance > 0:
                return covariance / market_variance
            return np.nan

        # 计算滚动 Beta
        beta_values = []
        for i in range(len(merged)):
            if i < 60:
                beta_values.append(np.nan)
            else:
                window_returns = merged['return'].iloc[i-60:i].values
                window_market = merged['return_market'].iloc[i-60:i].values
                beta = rolling_beta(window_returns, window_market)
                beta_values.append(beta)

        merged['beta_to_market'] = beta_values

        # 2. 相关性 (60日)
        merged['correlation_to_market'] = merged['return'].rolling(window=60).corr(merged['return_market'])

        # 3. 相对强度 (20日累计收益比)
        merged['relative_strength'] = (
            (1 + merged['return']).rolling(window=20).apply(lambda x: x.prod()) /
            (1 + merged['return_market']).rolling(window=20).apply(lambda x: x.prod())
        )

        # 4. Alpha (收益率 - Beta * 市场收益率)
        merged['alpha_to_market'] = merged['return'] - merged['beta_to_market'] * merged['return_market']

        # 5. 跟踪误差 (60日)
        merged['tracking_error'] = (merged['return'] - merged['return_market']).rolling(window=60).std() * np.sqrt(252)

        # 合并回原 DataFrame
        df['beta_to_market'] = merged['beta_to_market'].values
        df['correlation_to_market'] = merged['correlation_to_market'].values
        df['relative_strength'] = merged['relative_strength'].values
        df['alpha_to_market'] = merged['alpha_to_market'].values
        df['tracking_error'] = merged['tracking_error'].values

        logger.info("Cross-Asset Features 计算完成 (5 维)")
        return df

    @staticmethod
    def compute_all_advanced_features(df: pd.DataFrame, all_dfs: Dict[str, pd.DataFrame] = None,
                                     reference_df: pd.DataFrame = None) -> pd.DataFrame:
        """
        计算所有高级特征 (40 维)

        Args:
            df: 当前资产的 DataFrame
            all_dfs: 所有资产的 DataFrame 字典 (用于横截面特征)
            reference_df: 基准资产的 DataFrame (用于跨资产特征)

        Returns:
            添加了所有高级特征的 DataFrame
        """
        logger.info("开始计算所有高级特征 (40 维)...")

        # 1. Fractional Differentiation (6 维)
        df = AdvancedFeatures.compute_fractional_features(df)

        # 2. Rolling Statistics (12 维)
        df = AdvancedFeatures.compute_rolling_statistics(df)

        # 3. Cross-Sectional Rank (6 维)
        df = AdvancedFeatures.compute_cross_sectional_rank(df, all_dfs)

        # 4. Sentiment Momentum (8 维)
        df = AdvancedFeatures.compute_sentiment_momentum(df)

        # 5. Adaptive Window Features (3 维)
        df = AdvancedFeatures.compute_adaptive_window_features(df)

        # 6. Cross-Asset Features (5 维)
        df = AdvancedFeatures.compute_cross_asset_features(df, reference_df)

        logger.info("所有高级特征计算完成 (40 维) ✓")
        return df


# 测试代码
if __name__ == '__main__':
    # 创建测试数据
    np.random.seed(42)
    dates = pd.date_range('2023-01-01', '2024-01-01', freq='D')

    test_df = pd.DataFrame({
        'date': dates,
        'symbol': 'TEST',
        'open': 100 + np.cumsum(np.random.randn(len(dates))),
        'high': 102 + np.cumsum(np.random.randn(len(dates))),
        'low': 98 + np.cumsum(np.random.randn(len(dates))),
        'close': 100 + np.cumsum(np.random.randn(len(dates))),
        'volume': np.random.randint(1000000, 10000000, len(dates)),
        'sentiment_mean': np.random.randn(len(dates)) * 0.5,
        'news_count': np.random.randint(0, 10, len(dates)),
    })

    # 添加基础特征
    test_df['return_1d'] = test_df['close'].pct_change()
    test_df['return_5d'] = test_df['close'].pct_change(5)
    test_df['volatility_20d'] = test_df['return_1d'].rolling(20).std()
    test_df['rsi_14'] = 50.0

    print("测试高级特征计算...")
    print("=" * 60)

    # 测试 Fractional Differentiation
    test_df = AdvancedFeatures.compute_fractional_features(test_df)
    print("\nFractional Differentiation 特征:")
    print(test_df[['date', 'frac_diff_close_05', 'frac_diff_close_07']].tail())

    # 测试 Rolling Statistics
    test_df = AdvancedFeatures.compute_rolling_statistics(test_df)
    print("\nRolling Statistics 特征:")
    print(test_df[['date', 'roll_skew_20', 'roll_sharpe_20']].tail())

    # 测试 Sentiment Momentum
    test_df = AdvancedFeatures.compute_sentiment_momentum(test_df)
    print("\nSentiment Momentum 特征:")
    print(test_df[['date', 'sentiment_momentum_5d', 'sentiment_divergence']].tail())

    # 测试 Adaptive Window Features
    test_df = AdvancedFeatures.compute_adaptive_window_features(test_df)
    print("\nAdaptive Window Features:")
    print(test_df[['date', 'adaptive_ma', 'adaptive_momentum']].tail())

    print("\n" + "=" * 60)
    print("高级特征测试完成!")
    print(f"总特征数: {len(test_df.columns)} 列")

```

## src/feature_engineering/labeling.py

```python
"""
标签生成模块 - Triple Barrier Labeling
用于监督学习的标签生成

来源: "Advances in Financial Machine Learning" by Marcos Lopez de Prado
"""

import logging
import numpy as np
import pandas as pd
from typing import Optional, Tuple

logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)


class TripleBarrierLabeling:
    """
    三重壁垒标签法 (Triple Barrier Method)

    为每个样本设置三个退出条件:
    1. 上界 (Upper Barrier): 价格上涨达到目标收益 -> 标签 = 1 (做多)
    2. 下界 (Lower Barrier): 价格下跌达到止损 -> 标签 = -1 (做空/止损)
    3. 时间界 (Vertical Barrier): 持有期到期 -> 标签 = 0 或基于收益方向

    优势:
    - 避免固定持有期的偏差
    - 考虑止损和止盈
    - 更符合实际交易逻辑
    """

    @staticmethod
    def apply_triple_barrier(
        prices: pd.Series,
        upper_barrier: float = 0.02,
        lower_barrier: float = -0.02,
        max_holding_period: int = 5,
        stop_loss: Optional[float] = None
    ) -> pd.DataFrame:
        """
        应用三重壁垒标签法

        Args:
            prices: 价格序列 (Series with datetime index)
            upper_barrier: 上界收益率阈值 (默认 2%)
            lower_barrier: 下界收益率阈值 (默认 -2%)
            max_holding_period: 最大持有期 (天数)
            stop_loss: 止损阈值 (可选,如 -1% 止损)

        Returns:
            DataFrame 包含:
                - label: 标签 (1=上涨, -1=下跌, 0=中性)
                - barrier_touched: 触发的壁垒类型 ('upper', 'lower', 'vertical')
                - holding_period: 实际持有期
                - return: 实际收益率
        """
        logger.info("应用 Triple Barrier Labeling...")

        results = []

        for i in range(len(prices) - max_holding_period):
            entry_price = prices.iloc[i]
            entry_date = prices.index[i]

            # 未来价格序列
            future_prices = prices.iloc[i+1:i+1+max_holding_period]

            if len(future_prices) == 0:
                continue

            # 计算收益率
            returns = (future_prices - entry_price) / entry_price

            # 检查壁垒触发
            label = 0
            barrier_touched = 'vertical'
            holding_period = max_holding_period
            actual_return = returns.iloc[-1] if len(returns) > 0 else 0

            # 1. 检查上界
            upper_touch = returns >= upper_barrier
            if upper_touch.any():
                upper_idx = upper_touch.idxmax()
                upper_day = returns.index.get_loc(upper_idx)

                # 2. 检查下界
                lower_touch = returns <= lower_barrier
                if lower_touch.any():
                    lower_idx = lower_touch.idxmax()
                    lower_day = returns.index.get_loc(lower_idx)

                    # 哪个先触发
                    if upper_day <= lower_day:
                        label = 1
                        barrier_touched = 'upper'
                        holding_period = upper_day + 1
                        actual_return = returns.iloc[upper_day]
                    else:
                        label = -1
                        barrier_touched = 'lower'
                        holding_period = lower_day + 1
                        actual_return = returns.iloc[lower_day]
                else:
                    # 只触发上界
                    label = 1
                    barrier_touched = 'upper'
                    holding_period = upper_day + 1
                    actual_return = returns.iloc[upper_day]

            else:
                # 3. 检查下界
                lower_touch = returns <= lower_barrier
                if lower_touch.any():
                    lower_idx = lower_touch.idxmax()
                    lower_day = returns.index.get_loc(lower_idx)
                    label = -1
                    barrier_touched = 'lower'
                    holding_period = lower_day + 1
                    actual_return = returns.iloc[lower_day]
                else:
                    # 到达时间界
                    # 基于最终收益方向判断标签
                    if actual_return > 0:
                        label = 1
                    elif actual_return < 0:
                        label = -1
                    else:
                        label = 0

            # 4. 检查止损 (可选)
            if stop_loss is not None and stop_loss < 0:
                stop_touch = returns <= stop_loss
                if stop_touch.any():
                    stop_idx = stop_touch.idxmax()
                    stop_day = returns.index.get_loc(stop_idx)

                    # 止损优先
                    if stop_day < holding_period:
                        label = -1
                        barrier_touched = 'stop_loss'
                        holding_period = stop_day + 1
                        actual_return = returns.iloc[stop_day]

            results.append({
                'date': entry_date,
                'label': label,
                'barrier_touched': barrier_touched,
                'holding_period': holding_period,
                'return': actual_return,
                'entry_price': entry_price,
            })

        result_df = pd.DataFrame(results)
        result_df.set_index('date', inplace=True)

        # 统计
        label_counts = result_df['label'].value_counts()
        logger.info(f"标签分布: {label_counts.to_dict()}")
        logger.info(f"平均持有期: {result_df['holding_period'].mean():.2f} 天")
        logger.info(f"触发统计: {result_df['barrier_touched'].value_counts().to_dict()}")

        return result_df

    @staticmethod
    def compute_meta_labels(
        predictions: pd.Series,
        actual_returns: pd.Series,
        threshold: float = 0.0
    ) -> pd.Series:
        """
        计算元标签 (Meta-Labeling)

        元标签用于二级模型,判断主模型的预测是否应该被信任

        Args:
            predictions: 主模型的预测 (1=做多, -1=做空)
            actual_returns: 实际收益率
            threshold: 收益率阈值 (默认 0,即盈利=1,亏损=0)

        Returns:
            元标签序列 (1=应该交易, 0=不应该交易)
        """
        logger.info("计算 Meta-Labels...")

        meta_labels = pd.Series(0, index=predictions.index)

        # 做多信号 -> 检查是否盈利
        long_signals = predictions == 1
        meta_labels[long_signals & (actual_returns > threshold)] = 1

        # 做空信号 -> 检查是否盈利
        short_signals = predictions == -1
        meta_labels[short_signals & (actual_returns < -threshold)] = 1

        positive_rate = meta_labels.mean()
        logger.info(f"元标签正样本比例: {positive_rate:.2%}")

        return meta_labels

    @staticmethod
    def compute_sample_weights(
        labels: pd.Series,
        returns: pd.Series,
        decay: float = 0.95
    ) -> pd.Series:
        """
        计算样本权重 (Sample Weights)

        考虑因素:
        1. 时间衰减: 近期样本权重更高
        2. 收益幅度: 收益越大权重越高
        3. 类别平衡: 少数类样本权重更高

        Args:
            labels: 标签序列
            returns: 收益率序列
            decay: 时间衰减系数 (默认 0.95)

        Returns:
            样本权重序列
        """
        logger.info("计算样本权重...")

        weights = pd.Series(1.0, index=labels.index)

        # 1. 时间衰减权重
        n = len(labels)
        time_weights = np.array([decay ** (n - i - 1) for i in range(n)])
        weights *= time_weights

        # 2. 收益幅度权重 (绝对收益越大权重越高)
        return_weights = 1 + np.abs(returns)
        weights *= return_weights

        # 3. 类别平衡权重
        label_counts = labels.value_counts()
        max_count = label_counts.max()

        for label, count in label_counts.items():
            class_weight = max_count / count
            weights[labels == label] *= class_weight

        # 归一化
        weights = weights / weights.sum() * len(weights)

        logger.info(f"权重统计: mean={weights.mean():.4f}, std={weights.std():.4f}, "
                   f"min={weights.min():.4f}, max={weights.max():.4f}")

        return weights

    @staticmethod
    def add_labels_to_dataframe(
        df: pd.DataFrame,
        price_column: str = 'close',
        upper_barrier: float = 0.02,
        lower_barrier: float = -0.02,
        max_holding_period: int = 5,
        stop_loss: Optional[float] = None
    ) -> pd.DataFrame:
        """
        将 Triple Barrier 标签添加到 DataFrame

        Args:
            df: 包含价格数据的 DataFrame
            price_column: 价格列名
            upper_barrier: 上界阈值
            lower_barrier: 下界阈值
            max_holding_period: 最大持有期
            stop_loss: 止损阈值

        Returns:
            添加了标签列的 DataFrame
        """
        logger.info(f"为 DataFrame 添加 Triple Barrier 标签...")

        # 应用三重壁垒
        prices = df.set_index('date')[price_column] if 'date' in df.columns else df[price_column]
        labels_df = TripleBarrierLabeling.apply_triple_barrier(
            prices,
            upper_barrier=upper_barrier,
            lower_barrier=lower_barrier,
            max_holding_period=max_holding_period,
            stop_loss=stop_loss
        )

        # 合并标签
        df = df.set_index('date') if 'date' in df.columns else df
        df = df.join(labels_df[['label', 'barrier_touched', 'holding_period', 'return']], how='left')

        # 填充未标注的行
        df['label'] = df['label'].fillna(0).astype(int)
        df['barrier_touched'] = df['barrier_touched'].fillna('none')
        df['holding_period'] = df['holding_period'].fillna(0).astype(int)
        df['return'] = df['return'].fillna(0)

        # 计算样本权重
        df['sample_weight'] = TripleBarrierLabeling.compute_sample_weights(
            df['label'],
            df['return']
        )

        df = df.reset_index()

        logger.info("标签添加完成 ✓")
        return df


# 测试代码
if __name__ == '__main__':
    # 创建测试数据
    np.random.seed(42)
    dates = pd.date_range('2023-01-01', '2024-01-01', freq='D')

    # 模拟价格序列 (带趋势和噪音)
    trend = np.linspace(100, 120, len(dates))
    noise = np.random.randn(len(dates)) * 2
    prices = pd.Series(trend + noise, index=dates)

    print("测试 Triple Barrier Labeling...")
    print("=" * 60)

    # 应用三重壁垒
    labels_df = TripleBarrierLabeling.apply_triple_barrier(
        prices,
        upper_barrier=0.03,
        lower_barrier=-0.02,
        max_holding_period=5,
        stop_loss=-0.01
    )

    print("\n标签结果:")
    print(labels_df.head(10))

    print("\n标签统计:")
    print(labels_df['label'].value_counts())
    print(f"\n平均持有期: {labels_df['holding_period'].mean():.2f} 天")

    print("\n触发类型统计:")
    print(labels_df['barrier_touched'].value_counts())

    print("\n收益率统计:")
    print(labels_df['return'].describe())

    # 测试添加到 DataFrame
    test_df = pd.DataFrame({
        'date': dates,
        'close': prices.values,
        'volume': np.random.randint(1000000, 10000000, len(dates)),
    })

    test_df = TripleBarrierLabeling.add_labels_to_dataframe(
        test_df,
        upper_barrier=0.03,
        lower_barrier=-0.02,
        max_holding_period=5
    )

    print("\n添加标签后的 DataFrame:")
    print(test_df[['date', 'close', 'label', 'barrier_touched', 'holding_period', 'sample_weight']].head(10))

    print("\n" + "=" * 60)
    print("Triple Barrier Labeling 测试完成!")

```

## nexus_with_proxy.py

```python
#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
Notion Nexus - 支持 API 中转的版本
支持多种 API 中转方案
"""

import os
import sys
import time
import textwrap
import requests
from dotenv import load_dotenv
from src.utils.path_utils import get_project_root

# 加载环境变量
load_dotenv()
NOTION_TOKEN = os.getenv("NOTION_TOKEN")
GEMINI_KEY = os.getenv("GEMINI_API_KEY")
PROXY_API_KEY = os.getenv("PROXY_API_KEY")
PROXY_API_URL = os.getenv("PROXY_API_URL")
DATABASE_ID = os.getenv("NOTION_DB_ID")
PROJECT_ROOT = str(get_project_root())

# Notion API 配置
NOTION_VERSION = "2022-06-28"
NOTION_BASE_URL = "https://api.notion.com/v1"

def notion_headers():
    """获取 Notion API 请求头"""
    return {
        "Authorization": f"Bearer {NOTION_TOKEN}",
        "Content-Type": "application/json",
        "Notion-Version": NOTION_VERSION
    }

def call_gemini_direct(prompt):
    """直接调用 Google Gemini API"""
    try:
        # 使用稳定版本 gemini-1.5-flash (修正：gemini-2.5-flash 不存在)
        # 参考 Gemini Pro 审查建议：验证正确的API模型名称
        url = f"https://generativelanguage.googleapis.com/v1beta/models/gemini-1.5-flash:generateContent?key={GEMINI_KEY}"

        data = {
            "contents": [{
                "parts": [{
                    "text": prompt
                }]
            }]
        }

        response = requests.post(url, json=data, timeout=30)

        if response.status_code == 200:
            result = response.json()
            if "candidates" in result and result["candidates"]:
                return result["candidates"][0]["content"]["parts"][0]["text"]
            else:
                return "❌ Gemini 返回空响应"
        else:
            return f"❌ Gemini API Error: {response.status_code} - {response.text}"

    except Exception as e:
        return f"❌ 调用 Gemini 时出错: {e}"

def call_gemini_proxy_1(prompt):
    """使用中转服务 1 - Gemini Proxy"""
    try:
        url = "https://api.aiproxy.io/v1/chat/completions"

        headers = {
            "Authorization": f"Bearer {PROXY_API_KEY}",
            "Content-Type": "application/json"
        }

        data = {
            "model": "gemini-2.0-flash-exp",
            "messages": [
                {
                    "role": "system",
                    "content": "你是一位资深的量化开发助手，请提供专业的技术分析和建议。"
                },
                {
                    "role": "user",
                    "content": prompt
                }
            ],
            "temperature": 0.7,
            "max_tokens": 4000
        }

        response = requests.post(url, headers=headers, json=data, timeout=30)

        if response.status_code == 200:
            result = response.json()
            if "choices" in result and result["choices"]:
                return result["choices"][0]["message"]["content"]
            else:
                return "❌ 中转服务返回空响应"
        else:
            return f"❌ 中转服务 Error: {response.status_code} - {response.text}"

    except Exception as e:
        return f"❌ 调用中转服务时出错: {e}"

def call_gemini_proxy_2(prompt):
    """使用中转服务 2 - 固定使用 Gemini 3 Pro Preview"""
    try:
        url = f"{PROXY_API_URL}/v1/chat/completions"

        headers = {
            'Accept': 'application/json',
            'Authorization': f'Bearer {PROXY_API_KEY}',
            'Content-Type': 'application/json'
        }

        data = {
            "model": "gemini-3-pro-preview",  # 固定使用 Gemini 3 Pro Preview (实测可用)
            "messages": [
                {
                    "role": "system",
                    "content": "你是一位资深的量化开发助手，请提供专业的技术分析和建议。"
                },
                {
                    "role": "user",
                    "content": prompt
                }
            ],
            "temperature": 0.7,
            "max_tokens": 4000
        }

        print(f"   -> 使用模型: gemini-3-pro-preview (Gemini 3 Pro)")
        response = requests.post(url, headers=headers, json=data, timeout=60)

        if response.status_code == 200:
            result = response.json()
            if "choices" in result and result["choices"]:
                return result["choices"][0]["message"]["content"]
            else:
                return "❌ 中转服务返回空响应"
        else:
            return f"❌ 中转服务 Error: {response.status_code} - {response.text}"

    except Exception as e:
        return f"❌ 调用 Gemini 3 Pro 时出错: {e}"

def call_gemini_api(prompt):
    """智能选择 Gemini API 调用方式"""
    print("   -> 🔄 选择 API 服务...")

    # 优先使用配置的中转服务
    if PROXY_API_URL and PROXY_API_KEY and not PROXY_API_KEY.startswith("your_"):
        print("   -> 📡 使用购买的中转服务...")
        result = call_gemini_proxy_2(prompt)
        if not result.startswith("❌"):
            print("   -> ✅ 中转服务成功")
            return result
        else:
            print(f"   -> ⚠️ 中转服务失败: {result}")

    # 备选：尝试其他中转服务
    if PROXY_API_KEY and not PROXY_API_KEY.startswith("your_"):
        print("   -> 📡 尝试备用中转服务...")
        result = call_gemini_proxy_1(prompt)
        if not result.startswith("❌"):
            print("   -> ✅ 备用中转成功")
            return result
        else:
            print(f"   -> ⚠️ 备用中转失败: {result}")

    # 最后尝试直接 API
    print("   -> 🔗 尝试直接 API...")
    result = call_gemini_direct(prompt)
    if result.startswith("❌"):
        print(f"   -> ❌ 所有 API 都失败了")
    else:
        print("   -> ✅ 直接 API 成功")

    return result

def read_local_file(filepath):
    """读取本地文件内容"""
    safe_path = os.path.normpath(os.path.join(PROJECT_ROOT, filepath.strip()))
    if not safe_path.startswith(PROJECT_ROOT):
        return f"\n[Security Alert: Access denied to {filepath}]\n"

    if os.path.exists(safe_path):
        try:
            with open(safe_path, 'r', encoding='utf-8') as f:
                content = f.read()
                if len(content) > 5000:
                    content = content[:5000] + "\n... [文件过长已截断]"
                return f"\n\n--- FILE: {filepath} ---\n{content}\n--- END FILE ---\n"
        except Exception as e:
            return f"\n[Error reading file: {e}]\n"
    return f"\n[WARNING: File not found: {filepath}]\n"

def add_response_to_page(page_id, response_text):
    """将回复添加到页面"""
    try:
        chunks = textwrap.wrap(response_text, width=1800, replace_whitespace=False)

        children = [
            {
                "object": "block",
                "type": "heading_2",
                "heading_2": {
                    "rich_text": [{"text": {"content": "🤖 AI Response (via Proxy)"}}]
                }
            },
            {
                "object": "block",
                "type": "divider",
                "divider": {}
            }
        ]

        for chunk in chunks:
            children.append({
                "object": "block",
                "type": "paragraph",
                "paragraph": {
                    "rich_text": [{"text": {"content": chunk}}]
                }
            })

        url = f"{NOTION_BASE_URL}/blocks/{page_id}/children"
        response = requests.patch(url, headers=notion_headers(), json={"children": children})

        if response.status_code != 200:
            print(f"⚠️ 添加回复失败: {response.status_code}")
            return False

        return True

    except Exception as e:
        print(f"⚠️ 添加回复时出错: {e}")
        return False

def process_page(page):
    """处理单个页面"""
    page_id = page["id"]
    props = page["properties"]

    # 获取标题
    title = "Untitled Task"
    for field_name in ["名称", "Topic", "Title", "Name"]:
        if field_name in props and props[field_name].get("title"):
            title = props[field_name]["title"][0]["plain_text"]
            break

    print(f"🚀 处理任务: {title}")

    # 检查是否已经有回复
    if page.get("has_children"):
        print("   -> 页面已有内容，跳过处理")
        return

    # 智能文件关联
    context_str = ""
    if "风险管理" in title or "risk" in title.lower():
        files_to_read = ["src/strategy/risk_manager.py", "docs/BACKTEST_GUIDE.md"]
    elif "特征工程" in title or "feature" in title.lower():
        files_to_read = ["src/feature_engineering/", "docs/ML_GUIDE.md"]
    elif "回测" in title or "backtest" in title.lower():
        files_to_read = ["bin/run_backtest.py", "src/reporting/"]
    elif "代码" in title or "code" in title.lower():
        files_to_read = ["src/"]
    else:
        files_to_read = []

    for filepath in files_to_read:
        print(f"   -> 读取文件: {filepath}")
        context_str += read_local_file(filepath)

    # 构建提示
    full_prompt = f"""你是一位资深的量化开发助手。用户提出了以下问题或任务：

任务标题: {title}

相关代码上下文:
{context_str}

请根据任务标题和上下文，提供专业的技术回答。如果涉及代码分析，请提供具体的建议和改进方案。请用中文回答，格式使用 Markdown。"""

    # 调用 AI
    print("   -> 🧠 AI 思考中...")
    reply_text = call_gemini_api(full_prompt)

    if "❌" in reply_text:
        print(f"   -> {reply_text}")

        # 如果所有 API 都失败，添加一个备用回复
        fallback_response = f"""# 🤖 AI 分析结果

## 任务：{title}

很抱歉，AI 服务暂时不可用。但根据任务标题，我可以提供以下基础分析：

## 建议的分析方向：

### 1. 代码质量检查
- 检查错误处理机制
- 分析性能瓶颈
- 审查代码结构

### 2. 功能分析
- 验证业务逻辑正确性
- 检查边界条件处理
- 评估可维护性

### 3. 优化建议
- 提升代码可读性
- 优化算法效率
- 增强错误处理

### 4. 手动检查文件
请检查以下相关文件：
{chr(10).join([f"- {file}" for file in files_to_read])}

---
*系统将在 API 服务恢复后提供完整的 AI 分析结果。*"""

        print("   -> 📝 写入备用回复...")
        add_response_to_page(page_id, fallback_response)
        print("✅ 处理完成（备用回复）")
        return

    # 写入回复
    print("   -> 📝 写入回复...")
    if add_response_to_page(page_id, reply_text):
        print("✅ 处理完成")
    else:
        print("❌ 写入失败")

def monitor_database():
    """监控数据库并处理新页面"""
    print(f"👀 正在监控 Notion 数据库...")
    print("检测到新页面时会自动调用 AI 处理")
    print("支持多种 API 中转方案")
    print("按 Ctrl+C 停止监控\n")

    processed_pages = set()

    while True:
        try:
            url = f"{NOTION_BASE_URL}/databases/{DATABASE_ID}/query"
            response = requests.post(url, headers=notion_headers(), json={})

            if response.status_code == 200:
                query_result = response.json()
                pages = query_result.get("results", [])

                new_pages = [page for page in pages if page["id"] not in processed_pages]

                if new_pages:
                    print(f"发现 {len(new_pages)} 个新页面")
                    for page in new_pages:
                        process_page(page)
                        processed_pages.add(page["id"])
                        print("-" * 40)
                else:
                    sys.stdout.write(".")
                    sys.stdout.flush()

        except KeyboardInterrupt:
            print("\n👋 监控已停止")
            break
        except Exception as e:
            print(f"\n⚠️ 监控错误: {e}")

        time.sleep(5)

def main():
    """主函数"""
    print("=" * 60)
    print("🚀 Notion Nexus - API 中转版")
    print("=" * 60)

    # 显示当前配置
    print("📋 当前配置:")
    print(f"   Notion Token: {'✅ 已配置' if NOTION_TOKEN else '❌ 未配置'}")
    print(f"   Gemini Key: {'✅ 已配置' if GEMINI_KEY else '❌ 未配置'}")
    print(f"   代理 API Key: {'✅ 已配置' if PROXY_API_KEY and not PROXY_API_KEY.startswith('your_') else '❌ 未配置'}")
    print(f"   代理 API URL: {'✅ 已配置' if PROXY_API_URL else '❌ 未配置'}")

    if not DATABASE_ID:
        print("❌ NOTION_DB_ID 未配置")
        return

    print(f"\n🔄 API 调用策略:")
    print("   1. 尝试中转服务 (如果配置了代理)")
    print("   2. 尝试自定义中转 (如果配置了URL)")
    print("   3. 尝试直接 Gemini API")
    print("   4. 如果都失败，提供基础分析")

    # 测试连接
    print(f"\n🔧 测试连接...")
    try:
        url = f"{NOTION_BASE_URL}/databases/{DATABASE_ID}"
        response = requests.get(url, headers=notion_headers())

        if response.status_code == 200:
            print("✅ Notion 连接成功！")
            db_info = response.json()
            print(f"📊 数据库: {db_info.get('title', [{}])[0].get('plain_text', 'Unknown')}")

            print("\n📝 使用说明:")
            print("1. 在 Notion 数据库中创建新页面")
            print("2. 设置页面标题，系统会自动处理")
            print("3. 支持多种 API 中转方案")
            print("4. 如果 API 不可用，会提供基础分析")
            print("\n开始监控...\n")

            monitor_database()
        else:
            print(f"❌ 无法访问数据库: {response.status_code}")

    except Exception as e:
        print(f"❌ 连接测试失败: {e}")

if __name__ == "__main__":
    main()
```

## gemini_review_bridge.py

```python
#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
Gemini Review Bridge v3.6 (Hybrid Force Audit Edition)
架构目标:
1. 穿透 Cloudflare (Titanium Shield).
2. 精准提取 JSON 用于控制脚本流程 (Pass/Fail).
3. 保留并展示 AI 的架构点评，供 Claude 学习改进.
4. 🆕 双重检查机制：检测未暂存变更并强制添加.
5. 🆕 强力编码处理：防止管道缓冲和编码错误导致的崩溃.
6. 🆕 Hybrid Force Audit (v3.6): 当 Git 无变更时，自动进入全量审计模式，扫描关键文件.
7. 🆕 智能配置加载 (v3.6): 优先级: src.config > settings.py > ENV.
"""
import os
import sys
import subprocess
import json
import datetime
import re
import uuid
from dotenv import load_dotenv

# --- 日志文件配置 ---
LOG_FILE = "VERIFY_LOG.log"

# --- 核心配置 ---
AUDIT_SCRIPT = "scripts/audit_current_task.py"
ENABLE_AI_REVIEW = True # 开启云端大脑

# --- 尝试导入核武器 (curl_cffi) ---
try:
    from curl_cffi import requests
    CURL_AVAILABLE = True
except ImportError:
    CURL_AVAILABLE = False
    print("⚠️  [WARN] 缺少 curl_cffi，建议运行: pip install curl_cffi")

# --- UI 颜色配置 (必须在使用前定义) ---
GREEN = "\033[92m"
RED = "\033[91m"
YELLOW = "\033[93m"
CYAN = "\033[96m"
BLUE = "\033[94m"  # AI 点评专用色
RESET = "\033[0m"

# --- 环境变量初始化 (必须在所有导入后立即执行) ---
load_dotenv()  # 从 .env 文件加载环境变量

# --- 🆕 v3.6: 智能配置加载 (多优先级策略) ---
GEMINI_API_KEY = None
GEMINI_BASE_URL = "https://api.yyds168.net/v1"
GEMINI_MODEL = "gemini-3-pro-preview"

# 优先级 1: 尝试从 src.config 导入 (项目标准配置模块)
try:
    from src.config import GEMINI_API_KEY as K, GEMINI_BASE_URL as U, GEMINI_MODEL as M
    GEMINI_API_KEY = K
    GEMINI_BASE_URL = U
    GEMINI_MODEL = M
    print(f"{GREEN}✅ [v3.6] Loaded config from src.config{RESET}")
except ImportError:
    # 优先级 2: 尝试从 settings.py 导入 (根目录配置)
    try:
        import settings
        GEMINI_API_KEY = settings.GEMINI_API_KEY
        GEMINI_BASE_URL = getattr(settings, 'GEMINI_BASE_URL', GEMINI_BASE_URL)
        GEMINI_MODEL = getattr(settings, 'GEMINI_MODEL', GEMINI_MODEL)
        print(f"{GREEN}✅ [v3.6] Loaded config from settings.py{RESET}")
    except ImportError:
        # 优先级 3: 使用环境变量 (最后的退路)
        GEMINI_API_KEY = os.getenv("GEMINI_API_KEY")
        GEMINI_BASE_URL = os.getenv("GEMINI_BASE_URL", GEMINI_BASE_URL)
        GEMINI_MODEL = os.getenv("GEMINI_MODEL", GEMINI_MODEL)
        print(f"{YELLOW}⚠️  [v3.6] Loaded config from Environment Variables{RESET}")

# --- 🆕 v3.6: 强制审计目标文件列表 (Hybrid Mode) ---
FORCE_AUDIT_TARGETS = [
    "docker-compose.data.yml",
    "src/infrastructure/init_db.py",
    "src/infrastructure/init_db.sql",
    "src/config.py"
]

# --- 启动时的配置验证 ---
def _verify_config():
    """验证关键配置是否已加载"""
    if not GEMINI_API_KEY:
        print(f"{RED}🔴 [FATAL] GEMINI_API_KEY 未设置{RESET}")
        print(f"{YELLOW}请检查 src.config, settings.py 或环境变量{RESET}")
        sys.exit(1)

    print(f"{GREEN}[INFO] 配置验证通过:{RESET}")
    print(f"  ✅ API Key: 已加载 (长度: {len(GEMINI_API_KEY)})")
    print(f"  ✅ Base URL: {GEMINI_BASE_URL}")
    print(f"  ✅ Model: {GEMINI_MODEL}")
    print()

def read_file_content(filepath):
    """🆕 v3.6: 读取指定文件内容 (用于强制审计模式)"""
    if os.path.exists(filepath):
        try:
            with open(filepath, "r", encoding="utf-8") as f:
                return f.read()
        except Exception as e:
            log(f"无法读取文件 {filepath}: {e}", "WARN")
            return None
    return None

def log(msg, level="INFO"):
    timestamp = datetime.datetime.now().strftime("%Y-%m-%d %H:%M:%S")
    colors = {"SUCCESS": GREEN, "ERROR": RED, "WARN": YELLOW, "PHASE": CYAN, "INFO": RESET}
    prefix = {'SUCCESS': '✅ ', 'ERROR': '⛔ ', 'WARN': '⚠️  ', 'PHASE': '🔹 '}.get(level, '')

    # 写入日志文件
    with open(LOG_FILE, "a", encoding="utf-8") as f:
        f.write(f"[{timestamp}] [{level:8s}] {msg}\n")

    # 打印到控制台
    print(f"[{timestamp}] {colors.get(level, RESET)}{prefix}{msg}{RESET}")

def run_cmd(cmd, shell=True):
    """
    🆕 v3.4: 强化的命令执行函数
    - 使用 encoding='utf-8', errors='replace' 防止编码崩溃
    - 确保所有输出都能被正确捕获
    """
    try:
        result = subprocess.run(
            cmd,
            shell=shell,
            stdout=subprocess.PIPE,
            stderr=subprocess.PIPE,
            text=True,
            encoding='utf-8',
            errors='replace'
        )
        return result.returncode, result.stdout.strip(), result.stderr.strip()
    except Exception as e:
        return 1, "", str(e)

def extract_json_and_comments(text):
    """
    智能分离器：从 AI 的回复中拆分出 JSON (给机器看) 和 点评 (给 Claude 看)
    返回: (json_obj, comment_text)
    """
    json_obj = None
    comment_text = ""

    # 1. 使用栈平衡法寻找第一个完整的 JSON 对象 {...}
    stack = 0
    start_index = -1
    end_index = -1
    
    for i, char in enumerate(text):
        if char == '{':
            if stack == 0: start_index = i
            stack += 1
        elif char == '}':
            stack -= 1
            if stack == 0 and start_index != -1:
                end_index = i + 1
                # 尝试解析找到的这一段
                try:
                    candidate = text[start_index : end_index]
                    json_obj = json.loads(candidate)
                    # 提取成功！剩下的全是评论
                    if end_index < len(text):
                        comment_text = text[end_index:].strip()
                    return json_obj, comment_text
                except:
                    continue # 解析失败，可能是个假括号，继续找
    
    # 2. 兜底：如果没找到复杂的，尝试把整段当 JSON
    if not json_obj:
        try:
            json_obj = json.loads(text)
        except:
            pass
            
    return json_obj, comment_text

# ==============================================================================
# 🧠 Phase 1: 本地审计 (硬性门槛)
# ==============================================================================
def phase_local_audit():
    if not os.path.exists(AUDIT_SCRIPT):
        log(f"未找到本地审计脚本，跳过。", "WARN")
        return True
    
    log(f"执行本地审计: {AUDIT_SCRIPT}", "INFO")
    code, out, err = run_cmd(f"python3 {AUDIT_SCRIPT}")
    
    if code == 0:
        log("本地审计通过。", "SUCCESS")
        return True
    else:
        log("本地审计失败！阻止提交。", "ERROR")
        print(f"{YELLOW}--- AUDIT LOG ---\n{out}\n{err}{RESET}")
        return False

# ==============================================================================
# 🧠 Phase 2: 外部 AI 深度审查 (核心逻辑 + v3.6 Hybrid Mode)
# ==============================================================================
def external_ai_review(diff_content, session_id, audit_mode="INCREMENTAL"):
    """
    🆕 v3.6: 支持 Hybrid Force Audit
    - audit_mode="INCREMENTAL": Git 变更审计 (增量模式)
    - audit_mode="FORCE_FULL": 全量文件扫描 (强制模式)
    """
    if not CURL_AVAILABLE or not GEMINI_API_KEY:
        log("跳过 AI 审查 (缺少配置或依赖)", "WARN")
        return None, session_id

    log(f"启动 curl_cffi 引擎，请求架构师审查... (模式: {audit_mode})", "PHASE")

    # Prompt: 根据模式调整审查重点
    if audit_mode == "FORCE_FULL":
        audit_context = f"""
        你是一位严厉的 DevOps Security Auditor。
        当前环境: Git 工作区干净，无代码变更。
        审查模式: 强制全量扫描 (Force Audit Mode)
        审查对象: Task #065 Phase 2 Data Infrastructure 的关键配置文件。

        请审查以下基础设施代码:
        {diff_content[:40000]}

        **审查重点 (Protocol v4.3 Compliance)**:
        1. Hardcoded Secrets (Critical) - 严禁硬编码密码、API Key
        2. Docker/Database Best Practices - 端口暴露、数据卷配置
        3. Logic Flaws & Error Handling - SQL 注入风险、异常处理
        """
    else:
        audit_context = f"""
        你是一位严厉的 Python 架构师。请审查以下 Git Diff:
        {diff_content[:40000]}
        """

    prompt = f"""
    {audit_context}

    **输出格式要求 (严格遵守)**:
    1. 第一部分：必须是一个标准的 JSON 对象。
    2. 第二部分（可选）：JSON 结束后，你可以用 Markdown 写出详细的改进建议、风险警告或重构思路。

    JSON 结构：
    {{
        "status": "PASS" | "FAIL",
        "reason": "一句话总结",
        "commit_message_suggestion": "feat(scope): ...",
        "session_id": "{session_id}"
    }}
    """
    
    try:
        resp = requests.post(
            f"{GEMINI_BASE_URL}/chat/completions",
            headers={"Authorization": f"Bearer {GEMINI_API_KEY}", "Content-Type": "application/json"},
            json={
                "model": GEMINI_MODEL,
                "messages": [{"role": "user", "content": prompt}],
                "temperature": 0.3 
            },
            timeout=60,
            impersonate="chrome110" 
        )
        
        if resp.status_code == 200:
            resp_data = resp.json()
            content = resp_data['choices'][0]['message']['content']

            # Extract and log token usage if available
            usage = resp_data.get('usage', {})
            input_tokens = usage.get('prompt_tokens', 0)
            output_tokens = usage.get('completion_tokens', 0)
            total_tokens = usage.get('total_tokens', 0)

            if input_tokens or output_tokens:
                log(f"[INFO] Token Usage: Input {input_tokens}, Output {output_tokens}, Total {total_tokens}", "INFO")

            log(f"API 响应: HTTP 200, Content-Type: {resp.headers.get('content-type')}", "INFO")

            # 使用分离器处理
            result, comments = extract_json_and_comments(content)

            if result:
                status = result.get("status", "FAIL")
                returned_session_id = result.get("session_id", session_id)

                # --- 🔥 关键：展示 AI 的"话痨"部分给 Claude 看 ---
                if comments:
                    print(f"\n{BLUE}================ 🧠 架构师点评 (AI Feedback) ================{RESET}")
                    print(f"{CYAN}{comments}{RESET}")
                    print(f"{BLUE}============================================================={RESET}\n")
                else:
                    print(f"\n{BLUE}ℹ️  架构师没有提供额外评论。{RESET}\n")
                # ----------------------------------------------------

                if status == "PASS":
                    log(f"AI 审查通过: {result.get('reason')}", "SUCCESS")
                    return result.get("commit_message_suggestion"), returned_session_id
                else:
                    log(f"AI 拒绝提交: {result.get('reason')}", "ERROR")
                    return "FAIL", returned_session_id
            else:
                log(f"[FATAL] AI 响应格式无效，无法解析。响应体: {content[:500]}", "ERROR")
                log("请检查 GEMINI_API_KEY 和网络连接", "ERROR")
                return "FATAL_ERROR", session_id
        else:
            log(f"[FATAL] API 返回错误状态码: {resp.status_code}", "ERROR")
            log(f"响应体: {resp.text[:500]}", "ERROR")
            return "FATAL_ERROR", session_id

    except requests.ConnectTimeout:
        log(f"[FATAL] 连接超时: 无法连接API服务器 (timeout=60s)", "ERROR")
        log(f"检查项: 1) 网络连接  2) VPN 状态  3) API 地址正确性", "ERROR")
        log(f"API 地址: {GEMINI_BASE_URL}", "ERROR")
        return "FATAL_ERROR", session_id

    except requests.ReadTimeout:
        log(f"[FATAL] 读取超时: API服务器响应过慢 (timeout=60s)", "ERROR")
        log(f"API 地址: {GEMINI_BASE_URL}", "ERROR")
        return "FATAL_ERROR", session_id

    except requests.RequestException as e:
        log(f"[FATAL] 网络异常: {type(e).__name__}: {str(e)[:200]}", "ERROR")
        log(f"API 地址: {GEMINI_BASE_URL}", "ERROR")
        return "FATAL_ERROR", session_id

    except Exception as e:
        log(f"[FATAL] 未知错误: {type(e).__name__}: {str(e)}", "ERROR")
        import traceback
        log(f"堆栈跟踪:\n{traceback.format_exc()[:500]}", "ERROR")
        return "FATAL_ERROR", session_id

# ==============================================================================
# 🚀 主流程 (v3.6 Hybrid Force Audit Edition)
# ==============================================================================
def main():
    # 🆕 v3.5: Anti-Hallucination Proof of Execution (PoE) Mechanism
    session_id = str(uuid.uuid4())
    session_start_time = datetime.datetime.now().isoformat()

    print(f"{CYAN}🛡️ Gemini Review Bridge v3.6 (Hybrid Force Audit Edition){RESET}")
    print(f"{CYAN}⚡ [PROOF] AUDIT SESSION ID: {session_id}{RESET}")
    print(f"{CYAN}⚡ [PROOF] SESSION START: {session_start_time}{RESET}")
    print()

    # 🆕 v3.4: 启动时验证关键配置
    _verify_config()

    # 🆕 v3.6: Hybrid Mode - 智能决策审计策略
    print(f"{BLUE}🐛 [DEBUG] 开始检查 Git 状态...{RESET}")

    # Check 1: 检查是否有未暂存的变更
    rc1, raw_status, _ = run_cmd("git status --porcelain")

    audit_mode = "INCREMENTAL"
    diff_content = ""

    if not raw_status:
        # 🆕 v3.6: 工作区干净 -> 切换到强制全量审计模式
        print(f"{YELLOW}⚡ No git changes detected.{RESET}")
        print(f"{YELLOW}⚡ Switching to FORCE AUDIT MODE (Full Scan).{RESET}")
        print()

        audit_mode = "FORCE_FULL"
        found_count = 0

        for fpath in FORCE_AUDIT_TARGETS:
            content = read_file_content(fpath)
            if content:
                found_count += 1
                print(f"{GREEN}  ✅ Loaded: {fpath} ({len(content)} chars){RESET}")
                diff_content += f"\n--- FILE: {fpath} ---\n{content}\n"
            else:
                print(f"{YELLOW}  ⚠️  Not found: {fpath}{RESET}")

        print()

        if found_count == 0:
            log("🔴 No target files found for force audit.", "ERROR")
            sys.exit(1)

        log(f"✅ Force Audit Mode activated. Scanning {found_count} files.", "INFO")

    else:
        # 🆕 v3.6: 有 Git 变更 -> 正常增量审计模式
        audit_mode = "INCREMENTAL"

        print(f"{BLUE}🐛 [DEBUG] 检测到以下文件变更:{RESET}")
        for line in raw_status.splitlines():
            print(f"{BLUE}    {line}{RESET}")

        # Check 2: 执行强制暂存
        print(f"{BLUE}🐛 [DEBUG] 执行 Git 暂存 (git add -A)...{RESET}")
        run_cmd("git add -A")

        # Check 3: 验证暂存区是否有文件
        rc2, staged_files, _ = run_cmd("git diff --cached --name-only")

        if not staged_files:
            log("异常：git status 显示有变更，但暂存区为空", "ERROR")
            log("这可能是 Git 索引损坏，请运行: git reset && git status", "ERROR")
            sys.exit(1)

        print(f"{BLUE}🐛 [DEBUG] 已暂存 {len(staged_files.splitlines())} 个文件{RESET}")

        # 获取 diff 内容
        _, diff_content, _ = run_cmd("git diff --cached")

        if not diff_content:
            log("工作区干净，无代码变更。", "WARN")
            sys.exit(0)

        print(f"{GREEN}✅ [INFO] 检测到以下文件变更...{RESET}")
        for line in staged_files.splitlines():
            print(f"{GREEN}    + {line}{RESET}")
        print()

    # 1. 本地审计 (Claude 自测) - 仅在 INCREMENTAL 模式下执行
    if audit_mode == "INCREMENTAL":
        if not phase_local_audit():
            sys.exit(1)
    else:
        log("跳过本地审计 (FORCE_FULL 模式无 Git 变更)", "INFO")

    # 2. 外部 AI 审查 (架构师把关)
    ai_commit_msg = None
    if ENABLE_AI_REVIEW:
        log("=" * 80, "INFO")
        log(f"启动外部AI审查... (模式: {audit_mode})", "PHASE")
        log("=" * 80, "INFO")
        print()

        review_result, session_id = external_ai_review(diff_content, session_id, audit_mode)

        if review_result == "FAIL":
            print()
            print(f"{RED}{'=' * 80}{RESET}")
            log("AI审查拒绝提交", "ERROR")
            print(f"{RED}{'=' * 80}{RESET}")
            log("修复上述问题后重新运行finish命令", "ERROR")
            sys.exit(1)  # AI 明确拒绝，阻断提交

        elif review_result == "FATAL_ERROR":
            # 硬性失败 → 立即中止（不允许继续）
            print()
            print(f"{RED}{'=' * 80}{RESET}")
            log("[CRITICAL] AI 审查不可用，流程中止", "ERROR")
            log("故障排查步骤:", "ERROR")
            log("  1. 检查网络连接: ping api.yyds168.net", "ERROR")
            log("  2. 验证 API Key: echo $GEMINI_API_KEY", "ERROR")
            log("  3. 查看详细日志: cat VERIFY_LOG.log | tail -50", "ERROR")
            print(f"{RED}{'=' * 80}{RESET}")
            sys.exit(1)  # 硬性失败，阻止提交

        ai_commit_msg = review_result

    # 3. 🆕 v3.6: FORCE_FULL 模式下不执行 Git 提交（仅审计）
    if audit_mode == "FORCE_FULL":
        session_end_time = datetime.datetime.now().isoformat()
        print()
        print(f"{GREEN}{'=' * 80}{RESET}")
        log("✅ Force Audit 完成 (仅审查，无 Git 提交)", "SUCCESS")
        print(f"{GREEN}{'=' * 80}{RESET}")
        print(f"{CYAN}⚡ [PROOF] SESSION COMPLETED: {session_id}{RESET}")
        print(f"{CYAN}⚡ [PROOF] SESSION END: {session_end_time}{RESET}")
        log(f"[PROOF] Session {session_id} completed successfully (FORCE_FULL mode)", "INFO")
        sys.exit(0)

    # 4. INCREMENTAL 模式: 决定提交信息并执行提交
    if ai_commit_msg:
        commit_msg = ai_commit_msg
    else:
        # 降级或 AI 故障时的默认信息
        _, files, _ = run_cmd("git diff --cached --name-only")
        cnt = len([f for f in files.splitlines() if f])
        commit_msg = f"feat(auto): update {cnt} files (local audit passed)"

    # 5. 执行提交
    log(f"执行提交: {commit_msg}", "INFO")
    code, out, err = run_cmd(f'git commit -m "{commit_msg}"')

    if code == 0:
        log("代码已成功提交！", "SUCCESS")
        # 🆕 v3.5: Log session completion proof
        session_end_time = datetime.datetime.now().isoformat()
        print(f"{CYAN}⚡ [PROOF] SESSION COMPLETED: {session_id}{RESET}")
        print(f"{CYAN}⚡ [PROOF] SESSION END: {session_end_time}{RESET}")
        log(f"[PROOF] Session {session_id} completed successfully", "INFO")
        sys.exit(0)
    else:
        log(f"提交失败: {err}", "ERROR")
        # 🆕 v3.5: Log session failure proof
        session_end_time = datetime.datetime.now().isoformat()
        print(f"{RED}⚡ [PROOF] SESSION FAILED: {session_id}{RESET}")
        print(f"{RED}⚡ [PROOF] SESSION END: {session_end_time}{RESET}")
        log(f"[PROOF] Session {session_id} failed", "ERROR")
        sys.exit(1)

if __name__ == "__main__":
    main()

```


---

**导出统计**: 6/7 个文件

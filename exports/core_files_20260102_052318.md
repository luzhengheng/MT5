# æ ¸å¿ƒä»£ç æ–‡ä»¶

## src/strategy/risk_manager.py

```python
"""
é£é™©ç®¡ç†æ¨¡å— - Kelly Criterion æ³¨ç ç­–ç•¥ä¸åŠ¨æ€é£æ§

æ ¸å¿ƒç»„ä»¶ï¼š
1. KellySizer: åŸºäº Kelly å…¬å¼çš„åŠ¨æ€ä»“ä½ç®¡ç†
2. DynamicRiskManager: è´¦æˆ·çº§é£é™©ç›‘æ§å’Œç†”æ–­æœºåˆ¶
"""

import backtrader as bt
import numpy as np
import logging
from typing import Optional
from src.strategy.session_risk_manager import SessionRiskManager, get_session_risk_manager

logger = logging.getLogger(__name__)


class KellySizer(bt.Sizer):
    """
    Kelly Criterion ä»“ä½ç®¡ç†å™¨ï¼ˆé€šç”¨å…¬å¼ç‰ˆæœ¬ï¼‰

    å…¬å¼ï¼š
        f* = [p(b+1) - 1] / b

    å…¶ä¸­ï¼š
        - f*: Kelly é£é™©æ¯”ä¾‹ï¼ˆOptimal Risk Fractionï¼‰
        - p: é¢„æµ‹èƒœç‡ï¼ˆä» ML æ¨¡å‹è¾“å‡ºçš„ y_pred_proba æˆ– HierarchicalSignalFusion ç½®ä¿¡åº¦ï¼‰
        - b: èµ”ç‡ï¼ˆç­–ç•¥çš„ take_profit_ratioï¼Œå³ç›ˆäºæ¯”ï¼‰

    ä»“ä½è®¡ç®—ï¼š
        Risk Amount = Account Value * f* * kelly_fraction
        Position Size = Risk Amount / (ATR * stop_loss_multiplier)

    é‡è¦åŒºåˆ«ï¼š
        - f* æ˜¯"é£é™©æ¯”ä¾‹"ï¼Œä¸æ˜¯"æŒä»“æ¯”ä¾‹"
        - å®é™…ä»“ä½å¤§å°å–å†³äºæ­¢æŸè·ç¦»ï¼ˆATR * multiplierï¼‰
        - èµ”ç‡ b=2.0 æ„å‘³ç€ç›ˆåˆ©æ˜¯äºæŸçš„ 2 å€

    å‚æ•°ï¼š
        kelly_fraction (float): Kelly æ¯”ä¾‹ (0-1)ï¼Œå»ºè®® 0.25 (å››åˆ†ä¹‹ä¸€ Kelly)
        max_position_pct (float): å•ç¬”æœ€å¤§ä»“ä½å æ¯” (é»˜è®¤ 50%)
        min_position_pct (float): å•ç¬”æœ€å°ä»“ä½å æ¯” (é»˜è®¤ 1%)
        stop_loss_multiplier (float): æ­¢æŸå€æ•° (é»˜è®¤ 2.0, å³ 2*ATR)
        use_hierarchical_signals (bool): ä¼˜å…ˆä½¿ç”¨ HierarchicalSignalFusion ç½®ä¿¡åº¦ (é»˜è®¤ True)

    P2-03 æ”¹è¿› (2025-12-21):
        - æ·»åŠ  _get_win_probability() æ–¹æ³•
        - ä¼˜å…ˆä» HierarchicalSignalFusion è·å–ç½®ä¿¡åº¦
        - å›é€€åˆ°æ•°æ®æºçš„ y_pred_proba
        - ç¡®ä¿ Kelly å…¬å¼è·å¾—é«˜è´¨é‡çš„èƒœç‡è¾“å…¥
    """

    params = (
        ('kelly_fraction', 0.25),  # ä¿å®ˆçš„å››åˆ†ä¹‹ä¸€ Kelly
        ('max_position_pct', 0.50),  # æœ€å¤§ 50% ä»“ä½ï¼ˆå› ä¸ºæ˜¯æŒä»“æ¯”ï¼Œè€Œéé£é™©æ¯”ï¼‰
        ('min_position_pct', 0.01),  # æœ€å° 1% ä»“ä½
        ('stop_loss_multiplier', 2.0),  # æ­¢æŸè·ç¦»ä¸º 2*ATR
        ('max_leverage', 3.0),  # æœ€å¤§æ æ†å€æ•° (Geminiå»ºè®®æ·»åŠ ç¡¬çº¦æŸ)
        ('max_risk_per_trade', 0.02),  # å•ç¬”æœ€å¤§é£é™©é‡‘é¢å æ¯” (é»˜è®¤ 2%, Geminiå»ºè®®)
        ('use_hierarchical_signals', True),  # P2-03: ä¼˜å…ˆä½¿ç”¨åˆ†å±‚ä¿¡å·ç½®ä¿¡åº¦
    )

    def _get_win_probability(self, data, isbuy: bool) -> Optional[float]:
        """
        è·å–äº¤æ˜“çš„èµ¢ç‡æ¦‚ç‡

        P2-03 æ”¹è¿›: æ”¯æŒå¤šä¸ªæ¦‚ç‡æ¥æº
        1. ä¼˜å…ˆä» HierarchicalSignalFusion è·å–ç½®ä¿¡åº¦ (highest quality)
        2. å…¶æ¬¡ä»æ•°æ®æºè·å– y_pred_proba (fallback)
        3. è¿”å› None å¦‚æœéƒ½æ— æ³•è·å–

        Args:
            data: Backtrader æ•°æ®æº
            isbuy: True ä¸ºä¹°å…¥ï¼ŒFalse ä¸ºå–å‡º

        Returns:
            float: èµ¢ç‡æ¦‚ç‡ (0-1)ï¼Œæˆ– None å¦‚æœæ— æ³•è·å–
        """
        p_win = None

        # P2-03: æ–¹å¼ 1 - ä» HierarchicalSignalFusion è·å–ç½®ä¿¡åº¦
        if self.params.use_hierarchical_signals:
            try:
                if hasattr(self.strategy, 'hierarchical_signals'):
                    fusion_engine = self.strategy.hierarchical_signals
                    last_result = fusion_engine.get_last_signal()

                    if last_result is not None:
                        # ä½¿ç”¨èåˆç»“æœçš„ç½®ä¿¡åº¦ä½œä¸ºèµ¢ç‡
                        p_win = last_result.confidence
                        logger.debug(
                            f"ä» HierarchicalSignalFusion è·å–èµ¢ç‡: {p_win:.4f} "
                            f"(ä¿¡å·: {last_result.final_signal})"
                        )
                        return p_win
            except (AttributeError, Exception) as e:
                logger.debug(f"æ— æ³•ä» HierarchicalSignalFusion è·å–èµ¢ç‡: {e}")

        # P2-03: æ–¹å¼ 2 - ä»æ•°æ®æºè·å– y_pred_proba (å›é€€æ–¹æ¡ˆ)
        try:
            if isbuy:
                p_win = data.y_pred_proba_long[0]
            else:
                p_win = data.y_pred_proba_short[0]

            # éªŒè¯æœ‰æ•ˆæ€§
            if np.isnan(p_win) or p_win <= 0:
                return None

            logger.debug(
                f"ä»æ•°æ®æºè·å–èµ¢ç‡ (å›é€€): {p_win:.4f} "
                f"({'y_pred_proba_long' if isbuy else 'y_pred_proba_short'})"
            )
            return p_win

        except (AttributeError, IndexError):
            logger.debug("æ— æ³•ä»æ•°æ®æºè·å– y_pred_proba")
            return None

    def _getsizing(self, comminfo, cash, data, isbuy):
        """
        è®¡ç®—ä»“ä½å¤§å°ï¼ˆä½¿ç”¨é€šç”¨ Kelly å…¬å¼ï¼‰

        Returns:
            int: äº¤æ˜“æ‰‹æ•°ï¼ˆæ­£æ•°ä¸ºä¹°å…¥ï¼Œè´Ÿæ•°ä¸ºå–å‡ºï¼‰
        """
        # ============================================================
        # Gemini Pro å®¡æŸ¥å»ºè®®ä¿®å¤:
        # ä½¿ç”¨ getcash() æˆ– Balance è€Œé getvalue() (Equity)
        # åŸå› : Equity ä¼šå› æŒä»“æµ®åŠ¨ç›ˆäºå‰§çƒˆè·³åŠ¨ï¼Œå¯¼è‡´ä»“ä½éœ‡è¡
        # ============================================================

        # ä¼˜å…ˆä½¿ç”¨ getcash() è·å–å¯ç”¨èµ„é‡‘
        # å¦‚æœç­–ç•¥ä¸­æœ‰æ˜ç¡®çš„ initial_capital è®¾ç½®ï¼Œä½¿ç”¨è¯¥å€¼
        if hasattr(self.broker, 'getcash'):
            account_value = self.broker.getcash() + self.broker.getvalue() - self.broker.getcash()
            # ç®€åŒ–ï¼šç›´æ¥ä½¿ç”¨å¯ç”¨ç°é‡‘ + å½“å‰æŒä»“æˆæœ¬
            # é¿å…ä½¿ç”¨åŠ¨æ€æƒç›Š (Equity = Balance + æµ®åŠ¨ç›ˆäº)
            try:
                # è·å–åˆå§‹èµ„é‡‘ä½œä¸ºåŸºå‡†
                if hasattr(self.strategy, 'initial_capital'):
                    account_value = self.strategy.initial_capital
                else:
                    # å›é€€åˆ°å¯ç”¨ç°é‡‘
                    account_value = self.broker.getcash()
            except (AttributeError, Exception):
                # æœ€ç»ˆå›é€€æ–¹æ¡ˆ
                account_value = self.broker.getvalue()
                logger.debug("ä½¿ç”¨ getvalue() ä½œä¸ºè´¦æˆ·ä»·å€¼ï¼ˆå¯èƒ½å—æµ®åŠ¨ç›ˆäºå½±å“ï¼‰")
        else:
            account_value = self.broker.getvalue()

        current_price = data.close[0]

        if current_price <= 0:
            return 0

        # P2-03: ä½¿ç”¨æ–°çš„ _get_win_probability() æ–¹æ³•è·å–èµ¢ç‡
        # ä¼˜å…ˆä» HierarchicalSignalFusion è·å–ç½®ä¿¡åº¦ï¼Œå†å›é€€åˆ°æ•°æ®æº
        p_win = self._get_win_probability(data, isbuy)

        if p_win is None or p_win <= 0:
            logger.debug("æ— æ³•è·å–æœ‰æ•ˆçš„èµ¢ç‡æ¦‚ç‡ï¼Œè·³è¿‡ä»“ä½è®¡ç®—")
            return 0

        # æ³¨æ„ï¼šè¿™é‡Œä¸å†è¦æ±‚ p_win > 0.5
        # é€šç”¨ Kelly å…¬å¼å¯ä»¥å¤„ç†ä½èƒœç‡é«˜èµ”ç‡çš„æƒ…å†µ

        # è·å–ç­–ç•¥çš„ç›ˆäºæ¯”ï¼ˆèµ”ç‡ bï¼‰
        try:
            if hasattr(self.strategy, 'params') and hasattr(self.strategy.params, 'take_profit_ratio'):
                b = self.strategy.params.take_profit_ratio
            else:
                # å¦‚æœç­–ç•¥æ²¡æœ‰å®šä¹‰ï¼Œä½¿ç”¨ä¿å®ˆé»˜è®¤å€¼
                b = 2.0
                logger.debug("ç­–ç•¥æœªå®šä¹‰ take_profit_ratioï¼Œä½¿ç”¨é»˜è®¤å€¼ 2.0")
        except (AttributeError, Exception) as e:
            logger.warning(f"è·å– take_profit_ratio å¤±è´¥: {e}ï¼Œä½¿ç”¨é»˜è®¤å€¼ 2.0")
            b = 2.0

        # é˜²æ­¢é™¤é›¶é”™è¯¯
        if b <= 0:
            logger.warning(f"æ— æ•ˆçš„èµ”ç‡ b={b}ï¼Œè·³è¿‡ä»“ä½è®¡ç®—")
            return 0

        # ============================================================
        # é€šç”¨ Kelly å…¬å¼ï¼šf* = [p(b+1) - 1] / b
        # ============================================================
        kelly_f = (p_win * (b + 1) - 1) / b

        # å¦‚æœ Kelly æ¯”ä¾‹ä¸ºè´Ÿæ•°ï¼Œè¯´æ˜è¯¥äº¤æ˜“æœŸæœ›å€¼ä¸ºè´Ÿï¼Œä¸åº”å¼€ä»“
        if kelly_f <= 0:
            logger.debug(f"Kelly f*={kelly_f:.4f} <= 0 (p={p_win:.3f}, b={b:.2f})ï¼Œè·³è¿‡äº¤æ˜“")
            return 0

        # åº”ç”¨ä¿å®ˆç³»æ•°ï¼ˆå››åˆ†ä¹‹ä¸€ Kellyï¼‰
        risk_pct = kelly_f * self.params.kelly_fraction

        # ============================================================
        # Gemini Pro å»ºè®®: æ·»åŠ ç¡¬æ€§çº¦æŸ
        # é˜²æ­¢æç«¯æƒ…å†µä¸‹çš„è¿‡é«˜æ æ†
        # ============================================================

        # 1. é£é™©é‡‘é¢ç¡¬çº¦æŸ (æ¯ç¬”æœ€å¤§äºæŸ)
        max_risk_amount = account_value * self.params.max_risk_per_trade
        risk_pct = min(risk_pct, self.params.max_risk_per_trade)

        logger.debug(
            f"åº”ç”¨é£é™©çº¦æŸ: risk_pct={risk_pct:.2%}, max_allowed={self.params.max_risk_per_trade:.2%}"
        )

        # è®¡ç®— ATRï¼ˆç”¨äºç¡®å®šæ­¢æŸè·ç¦»ï¼‰
        try:
            if hasattr(self.strategy, 'atr'):
                atr_value = self.strategy.atr[0]
            else:
                # ä½¿ç”¨ç®€åŒ–çš„ ATR ä¼°è®¡ï¼ˆHigh-Lowï¼‰
                atr_value = abs(data.high[0] - data.low[0])
        except (AttributeError, IndexError):
            # å¦‚æœæ— æ³•è·å–ï¼Œä½¿ç”¨ä»·æ ¼çš„ 1% ä½œä¸ºä¼°è®¡
            atr_value = current_price * 0.01
            logger.debug(f"æ— æ³•è·å– ATRï¼Œä½¿ç”¨ä¼°è®¡å€¼ {atr_value:.5f}")

        if atr_value <= 0:
            logger.warning(f"ATR å€¼æ— æ•ˆ ({atr_value})ï¼Œè·³è¿‡ä»“ä½è®¡ç®—")
            return 0

        # ============================================================
        # ä»“ä½è®¡ç®—ï¼šä»"é£é™©æ¯”ä¾‹"è½¬æ¢ä¸º"æŒä»“æ•°é‡"
        # ============================================================
        # 1. è®¡ç®—ç›®æ ‡é£é™©é‡‘é¢
        risk_amount = account_value * risk_pct

        # 2. è®¡ç®—å•è‚¡é£é™©ï¼ˆæ­¢æŸè·ç¦»ï¼‰
        risk_per_share = atr_value * self.params.stop_loss_multiplier

        if risk_per_share <= 0:
            logger.warning(f"å•è‚¡é£é™©æ— æ•ˆ ({risk_per_share})ï¼Œè·³è¿‡ä»“ä½è®¡ç®—")
            return 0

        # 3. è®¡ç®—ç›®æ ‡è‚¡æ•°
        target_shares = risk_amount / risk_per_share

        # 4. è®¡ç®—å®é™…æŒä»“ä»·å€¼å æ¯”ï¼ˆç”¨äºè¾¹ç•Œæ£€æŸ¥ï¼‰
        position_value = target_shares * current_price
        position_pct = position_value / account_value

        # ============================================================
        # Gemini Pro å»ºè®®: æ æ†ç¡¬çº¦æŸ
        # é˜²æ­¢æç«¯èƒœç‡å¯¼è‡´çš„è¿‡é«˜æ æ†
        # ============================================================
        # 2. æ æ†çº¦æŸ (position_value / account_value)
        leverage = position_value / account_value
        if leverage > self.params.max_leverage:
            logger.warning(
                f"æ æ† {leverage:.2f}x è¶…è¿‡æœ€å¤§é™åˆ¶ {self.params.max_leverage}xï¼Œç¼©å‡ä»“ä½"
            )
            target_shares = target_shares * (self.params.max_leverage / leverage)
            position_value = target_shares * current_price
            position_pct = position_value / account_value

        # 5. åº”ç”¨æŒä»“æ¯”ä¾‹é™åˆ¶
        if position_pct > self.params.max_position_pct:
            # è¶…è¿‡æœ€å¤§æŒä»“æ¯”ä¾‹ï¼ŒæŒ‰æ¯”ä¾‹ç¼©å‡
            target_shares = target_shares * (self.params.max_position_pct / position_pct)
            position_pct = self.params.max_position_pct
            logger.debug(f"æŒä»“æ¯”ä¾‹è¶…é™ï¼Œç¼©å‡è‡³ {self.params.max_position_pct:.1%}")

        if position_pct < self.params.min_position_pct:
            # ä½äºæœ€å°æŒä»“æ¯”ä¾‹ï¼Œä¸å¼€ä»“
            logger.debug(f"æŒä»“æ¯”ä¾‹ {position_pct:.3%} < æœ€å°å€¼ {self.params.min_position_pct:.1%}ï¼Œè·³è¿‡äº¤æ˜“")
            return 0

        # 6. å‘ä¸‹å–æ•´ï¼ˆç¡®ä¿ä¸è¶…å‡ºèµ„é‡‘é™åˆ¶ï¼‰
        size = int(target_shares)

        # 7. æœ€ç»ˆéªŒè¯
        if size <= 0:
            return 0

        # è®°å½•è¯¦ç»†æ—¥å¿—
        logger.debug(
            f"Kelly Sizer - "
            f"P={p_win:.3f}, b={b:.2f}, f*={kelly_f:.4f}, "
            f"Risk%={risk_pct:.2%}, Position%={position_pct:.2%}, "
            f"ATR={atr_value:.5f}, Size={size}"
        )

        return size


class FixedFractionalSizer(bt.Sizer):
    """
    å›ºå®šæ¯”ä¾‹ä»“ä½ç®¡ç†å™¨ï¼ˆå¤‡ç”¨æ–¹æ¡ˆï¼‰

    æ¯æ¬¡ä½¿ç”¨å›ºå®šç™¾åˆ†æ¯”çš„è´¦æˆ·èµ„é‡‘å¼€ä»“

    å‚æ•°ï¼š
        percents (float): æ¯æ¬¡äº¤æ˜“ä½¿ç”¨çš„èµ„é‡‘æ¯”ä¾‹ (é»˜è®¤ 10%)
    """

    params = (
        ('percents', 10),
    )

    def _getsizing(self, comminfo, cash, data, isbuy):
        account_value = self.broker.getvalue()
        current_price = data.close[0]

        if current_price <= 0:
            return 0

        position_value = account_value * (self.params.percents / 100.0)
        size = int(position_value / current_price)

        return size


class DynamicRiskManager:
    """
    åŠ¨æ€é£é™©ç®¡ç†å™¨

    åŠŸèƒ½ï¼š
    1. ç›‘æ§è´¦æˆ·å›æ’¤ï¼Œè§¦å‘ç†”æ–­æœºåˆ¶
    2. è·Ÿè¸ªæœ€é«˜å‡€å€¼ï¼Œè®¡ç®—å®æ—¶å›æ’¤
    3. æä¾›é£é™©æŠ¥å‘Š

    å‚æ•°ï¼š
        max_drawdown_pct (float): æœ€å¤§å›æ’¤æ¯”ä¾‹ï¼Œè¶…è¿‡åˆ™ç†”æ–­ (é»˜è®¤ 10%)
        stop_trading_on_breach (bool): è§¦å‘ç†”æ–­æ—¶æ˜¯å¦åœæ­¢äº¤æ˜“ (é»˜è®¤ True)
    """

    def __init__(self, broker: bt.brokers.BackBroker,
                 max_drawdown_pct: float = 10.0,
                 stop_trading_on_breach: bool = True,
                 daily_loss_limit: float = -0.05):
        self.broker = broker
        self.max_drawdown_pct = max_drawdown_pct / 100.0
        self.stop_trading_on_breach = stop_trading_on_breach

        self.peak_value = broker.getvalue()
        self.is_halted = False
        self.breach_datetime = None

        # ä¼šè¯é£æ§ç®¡ç†å™¨ - ç›‘æ§æ¯æ—¥æŸå¤±é™åˆ¶
        self.session_risk = get_session_risk_manager(daily_loss_limit)

        logger.info(f"é£é™©ç®¡ç†å™¨åˆå§‹åŒ– - æœ€å¤§å›æ’¤: {max_drawdown_pct}%, æ¯æ—¥æŸå¤±é™åˆ¶: {daily_loss_limit*100:.0f}%")

    def update(self, current_datetime=None) -> dict:
        """
        æ›´æ–°é£é™©çŠ¶æ€

        Returns:
            dict: é£é™©æŠ¥å‘Š
                - current_value: å½“å‰è´¦æˆ·ä»·å€¼
                - peak_value: å†å²æœ€é«˜ä»·å€¼
                - drawdown: å½“å‰å›æ’¤æ¯”ä¾‹
                - is_halted: æ˜¯å¦å·²ç†”æ–­
        """
        current_value = self.broker.getvalue()

        # æ›´æ–°å³°å€¼
        if current_value > self.peak_value:
            self.peak_value = current_value
            # å¦‚æœæ¢å¤åˆ°æ–°é«˜ï¼Œè§£é™¤ç†”æ–­
            if self.is_halted:
                logger.info(f"è´¦æˆ·æ¢å¤è‡³æ–°é«˜ {current_value:.2f}ï¼Œè§£é™¤ç†”æ–­")
                self.is_halted = False
                self.breach_datetime = None

        # è®¡ç®—å›æ’¤
        drawdown = (self.peak_value - current_value) / self.peak_value

        # æ£€æŸ¥æ˜¯å¦è¶…è¿‡æœ€å¤§å›æ’¤
        if drawdown > self.max_drawdown_pct and not self.is_halted:
            self.is_halted = True
            self.breach_datetime = current_datetime
            logger.warning(f"ğŸš¨ è§¦å‘ç†”æ–­ï¼å›æ’¤: {drawdown:.2%}, é˜ˆå€¼: {self.max_drawdown_pct:.2%}")

        return {
            'current_value': current_value,
            'peak_value': self.peak_value,
            'drawdown': drawdown,
            'is_halted': self.is_halted,
            'breach_datetime': self.breach_datetime
        }

    def can_trade(self) -> bool:
        """
        æ£€æŸ¥æ˜¯å¦å¯ä»¥äº¤æ˜“

        Returns:
            bool: True è¡¨ç¤ºå¯ä»¥äº¤æ˜“ï¼ŒFalse è¡¨ç¤ºè¢«ç†”æ–­æˆ–æ¯æ—¥åœæŸ
        """
        # æ£€æŸ¥æœ€å¤§å›æ’¤é™åˆ¶
        if self.stop_trading_on_breach and self.is_halted:
            logger.warning("âš ï¸ è´¦æˆ·å›æ’¤ç†”æ–­ï¼Œç¦æ­¢äº¤æ˜“")
            return False

        # æ£€æŸ¥æ¯æ—¥æŸå¤±é™åˆ¶
        if not self.session_risk.can_trade():
            daily_stats = self.session_risk.get_daily_stats()
            if daily_stats:
                logger.warning(f"âš ï¸ æ¯æ—¥æŸå¤±é™åˆ¶è§¦å‘ï¼Œå½“æ—¥æŸå¤±: {daily_stats['daily_loss_pct']}")
            return False

        return True

    def get_summary(self) -> str:
        """
        è·å–é£é™©ç®¡ç†æ‘˜è¦

        Returns:
            str: æ ¼å¼åŒ–çš„é£é™©æŠ¥å‘Š
        """
        report = self.update()
        daily_stats = self.session_risk.get_daily_stats()

        summary = f"""
========== é£é™©ç®¡ç†æŠ¥å‘Š ==========
å½“å‰è´¦æˆ·ä»·å€¼: ${report['current_value']:,.2f}
å†å²æœ€é«˜ä»·å€¼: ${report['peak_value']:,.2f}
å½“å‰å›æ’¤: {report['drawdown']:.2%}
æœ€å¤§å›æ’¤é™åˆ¶: {self.max_drawdown_pct:.2%}
ç†”æ–­çŠ¶æ€: {'ğŸš¨ å·²è§¦å‘' if report['is_halted'] else 'âœ… æ­£å¸¸'}
"""
        if report['breach_datetime']:
            summary += f"ç†”æ–­æ—¶é—´: {report['breach_datetime']}\n"

        # æ·»åŠ æ¯æ—¥æŸå¤±ä¿¡æ¯
        if daily_stats:
            summary += f"""
========== æ¯æ—¥æŸå¤±æŠ¥å‘Š ==========
å½“æ—¥å·²å®ç° P&L: {daily_stats['daily_realized_pnl']}
å½“æ—¥æœªå®ç° P&L: {daily_stats['daily_unrealized_pnl']}
å½“æ—¥æ€» P&L: {daily_stats['daily_total_pnl']}
å½“æ—¥æŸå¤±ç™¾åˆ†æ¯”: {daily_stats['daily_loss_pct']}
"""

        summary += "=================================\n"

        return summary


class PositionSizer:
    """
    é€šç”¨ä»“ä½è®¡ç®—å·¥å…·ç±»

    æä¾›å¤šç§ä»“ä½è®¡ç®—æ–¹æ³•çš„é™æ€å·¥å…·
    """

    @staticmethod
    def kelly_criterion(p_win: float, p_lose: float, win_amount: float, lose_amount: float) -> float:
        """
        æ ‡å‡† Kelly Criterion å…¬å¼

        Args:
            p_win: èƒœç‡
            p_lose: è´¥ç‡
            win_amount: å¹³å‡ç›ˆåˆ©é‡‘é¢
            lose_amount: å¹³å‡äºæŸé‡‘é¢

        Returns:
            float: Kelly æ¯”ä¾‹ (0-1)
        """
        if lose_amount == 0:
            return 0.0

        kelly = (p_win * win_amount - p_lose * lose_amount) / lose_amount
        return max(0.0, min(kelly, 1.0))

    @staticmethod
    def optimal_f(trades: list, account_size: float) -> float:
        """
        Optimal F (æœ€ä¼˜ f å€¼)

        Args:
            trades: äº¤æ˜“ç»“æœåˆ—è¡¨ï¼ˆç›ˆäºé‡‘é¢ï¼‰
            account_size: è´¦æˆ·è§„æ¨¡

        Returns:
            float: æœ€ä¼˜ f å€¼ (0-1)
        """
        if not trades:
            return 0.0

        max_loss = abs(min(trades))
        if max_loss == 0:
            return 0.0

        # ä½¿ç”¨äºŒåˆ†æœç´¢æ‰¾åˆ°æœ€ä¼˜ f
        best_f = 0.0
        best_twr = 0.0  # Terminal Wealth Relative

        for f in np.linspace(0.01, 1.0, 100):
            twr = 1.0
            for trade in trades:
                hpr = 1.0 + f * (trade / max_loss)  # Holding Period Return
                if hpr <= 0:
                    twr = 0
                    break
                twr *= hpr

            if twr > best_twr:
                best_twr = twr
                best_f = f

        return best_f

    @staticmethod
    def volatility_adjusted_position(account_value: float,
                                     current_price: float,
                                     target_risk_pct: float,
                                     atr: float) -> int:
        """
        åŸºäºæ³¢åŠ¨ç‡è°ƒæ•´çš„ä»“ä½

        Args:
            account_value: è´¦æˆ·ä»·å€¼
            current_price: å½“å‰ä»·æ ¼
            target_risk_pct: ç›®æ ‡é£é™©æ¯”ä¾‹ (å¦‚ 2% = 0.02)
            atr: ATR å€¼

        Returns:
            int: å»ºè®®æ‰‹æ•°
        """
        if atr == 0 or current_price == 0:
            return 0

        # è®¡ç®—å•ä½é£é™©
        risk_per_unit = atr

        # è®¡ç®—ç›®æ ‡é£é™©é‡‘é¢
        target_risk = account_value * target_risk_pct

        # è®¡ç®—ä»“ä½
        position_size = int(target_risk / risk_per_unit)

        return max(0, position_size)

```

## src/feature_engineering/basic_features.py

```python
"""
åŸºç¡€æŠ€æœ¯æŒ‡æ ‡ç‰¹å¾è®¡ç®—
ä½¿ç”¨ pandas å’Œ numpy å®ç°ï¼ˆé¿å… ta-lib ä¾èµ–ï¼‰
"""

import numpy as np
import pandas as pd
import logging

logger = logging.getLogger(__name__)


class BasicFeatures:
    """åŸºç¡€æŠ€æœ¯æŒ‡æ ‡ç‰¹å¾è®¡ç®—å™¨"""

    @staticmethod
    def compute_ema(series: pd.Series, period: int) -> pd.Series:
        """è®¡ç®—æŒ‡æ•°ç§»åŠ¨å¹³å‡ï¼ˆEMAï¼‰"""
        return series.ewm(span=period, adjust=False).mean()

    @staticmethod
    def compute_sma(series: pd.Series, period: int) -> pd.Series:
        """è®¡ç®—ç®€å•ç§»åŠ¨å¹³å‡ï¼ˆSMAï¼‰"""
        return series.rolling(window=period).mean()

    @staticmethod
    def compute_rsi(series: pd.Series, period: int = 14) -> pd.Series:
        """è®¡ç®—ç›¸å¯¹å¼ºå¼±æŒ‡æ ‡ï¼ˆRSIï¼‰"""
        delta = series.diff()
        gain = (delta.where(delta > 0, 0)).rolling(window=period).mean()
        loss = (-delta.where(delta < 0, 0)).rolling(window=period).mean()

        rs = gain / loss
        rsi = 100 - (100 / (1 + rs))
        return rsi

    @staticmethod
    def compute_macd(series: pd.Series, fast: int = 12, slow: int = 26, signal: int = 9) -> pd.DataFrame:
        """è®¡ç®— MACD æŒ‡æ ‡"""
        ema_fast = BasicFeatures.compute_ema(series, fast)
        ema_slow = BasicFeatures.compute_ema(series, slow)

        macd_line = ema_fast - ema_slow
        signal_line = BasicFeatures.compute_ema(macd_line, signal)
        histogram = macd_line - signal_line

        return pd.DataFrame({
            'macd': macd_line,
            'macd_signal': signal_line,
            'macd_hist': histogram
        })

    @staticmethod
    def compute_atr(high: pd.Series, low: pd.Series, close: pd.Series, period: int = 14) -> pd.Series:
        """è®¡ç®—å¹³å‡çœŸå®æ³¢å¹…ï¼ˆATRï¼‰"""
        # True Range
        tr1 = high - low
        tr2 = abs(high - close.shift())
        tr3 = abs(low - close.shift())

        tr = pd.concat([tr1, tr2, tr3], axis=1).max(axis=1)

        # ATR æ˜¯ TR çš„ç§»åŠ¨å¹³å‡
        atr = tr.rolling(window=period).mean()
        return atr

    @staticmethod
    def compute_bollinger_bands(series: pd.Series, period: int = 20, std: int = 2) -> pd.DataFrame:
        """è®¡ç®—å¸ƒæ—å¸¦"""
        sma = BasicFeatures.compute_sma(series, period)
        rolling_std = series.rolling(window=period).std()

        upper = sma + (rolling_std * std)
        lower = sma - (rolling_std * std)

        return pd.DataFrame({
            'bbands_upper': upper,
            'bbands_middle': sma,
            'bbands_lower': lower,
            'bbands_width': (upper - lower) / sma
        })

    @staticmethod
    def compute_stochastic(high: pd.Series, low: pd.Series, close: pd.Series,
                          k_period: int = 14, d_period: int = 3) -> pd.DataFrame:
        """è®¡ç®—éšæœºéœ‡è¡æŒ‡æ ‡ï¼ˆStochasticï¼‰"""
        lowest_low = low.rolling(window=k_period).min()
        highest_high = high.rolling(window=k_period).max()

        k = 100 * (close - lowest_low) / (highest_high - lowest_low)
        d = k.rolling(window=d_period).mean()

        return pd.DataFrame({
            'stochastic_k': k,
            'stochastic_d': d
        })

    @staticmethod
    def compute_williams_r(high: pd.Series, low: pd.Series, close: pd.Series, period: int = 14) -> pd.Series:
        """è®¡ç®—å¨å»‰æŒ‡æ ‡ï¼ˆWilliams %Rï¼‰"""
        highest_high = high.rolling(window=period).max()
        lowest_low = low.rolling(window=period).min()

        williams_r = -100 * (highest_high - close) / (highest_high - lowest_low)
        return williams_r

    @staticmethod
    def compute_roc(series: pd.Series, period: int = 10) -> pd.Series:
        """è®¡ç®—å˜åŒ–ç‡ï¼ˆROC - Rate of Changeï¼‰"""
        roc = ((series - series.shift(period)) / series.shift(period)) * 100
        return roc

    @staticmethod
    def compute_obv(close: pd.Series, volume: pd.Series) -> pd.Series:
        """è®¡ç®—èƒ½é‡æ½®ï¼ˆOBV - On-Balance Volumeï¼‰"""
        obv = (np.sign(close.diff()) * volume).fillna(0).cumsum()
        return obv

    @staticmethod
    def compute_realized_volatility(returns: pd.Series, period: int = 20) -> pd.Series:
        """è®¡ç®—å·²å®ç°æ³¢åŠ¨ç‡"""
        return returns.rolling(window=period).std() * np.sqrt(252)  # å¹´åŒ–

    @staticmethod
    def compute_returns(close: pd.Series, periods: list = [1, 3, 5, 10, 20]) -> pd.DataFrame:
        """è®¡ç®—å¤šæœŸæ»åå›æŠ¥"""
        returns_df = pd.DataFrame()

        for period in periods:
            returns_df[f'return_{period}d'] = close.pct_change(period)

        return returns_df

    @staticmethod
    def compute_all_basic_features(df: pd.DataFrame) -> pd.DataFrame:
        """
        è®¡ç®—æ‰€æœ‰åŸºç¡€ç‰¹å¾ï¼ˆ30 ç»´ï¼‰

        Args:
            df: å¿…é¡»åŒ…å« ['open', 'high', 'low', 'close', 'volume'] åˆ—

        Returns:
            æ·»åŠ äº†åŸºç¡€ç‰¹å¾çš„ DataFrame
        """
        df = df.copy()

        logger.info("è®¡ç®—åŸºç¡€æŠ€æœ¯æŒ‡æ ‡ç‰¹å¾...")

        # è¶‹åŠ¿ç±»ç‰¹å¾ (10 ç»´)
        df['ema_12'] = BasicFeatures.compute_ema(df['close'], 12)
        df['ema_26'] = BasicFeatures.compute_ema(df['close'], 26)
        df['ema_50'] = BasicFeatures.compute_ema(df['close'], 50)
        df['ema_200'] = BasicFeatures.compute_ema(df['close'], 200)
        df['sma_20'] = BasicFeatures.compute_sma(df['close'], 20)
        df['sma_60'] = BasicFeatures.compute_sma(df['close'], 60)

        df['price_vs_ema200'] = (df['close'] - df['ema_200']) / df['ema_200']
        df['golden_cross'] = (df['ema_50'] > df['ema_200']).astype(int)
        df['death_cross'] = (df['ema_50'] < df['ema_200']).astype(int)
        df['trend_strength'] = (df['ema_12'] - df['ema_200']) / df['ema_200']

        # åŠ¨é‡ç±»ç‰¹å¾ (8 ç»´)
        df['rsi_14'] = BasicFeatures.compute_rsi(df['close'], 14)
        macd_df = BasicFeatures.compute_macd(df['close'])
        df = pd.concat([df, macd_df], axis=1)
        df['roc_10'] = BasicFeatures.compute_roc(df['close'], 10)

        stoch_df = BasicFeatures.compute_stochastic(df['high'], df['low'], df['close'])
        df = pd.concat([df, stoch_df], axis=1)

        df['williams_r'] = BasicFeatures.compute_williams_r(df['high'], df['low'], df['close'], 14)

        # æ³¢åŠ¨ç±»ç‰¹å¾ (6 ç»´)
        df['atr_14'] = BasicFeatures.compute_atr(df['high'], df['low'], df['close'], 14)

        bbands_df = BasicFeatures.compute_bollinger_bands(df['close'])
        df = pd.concat([df, bbands_df], axis=1)

        df['return_1d'] = df['close'].pct_change()
        df['realized_volatility_20'] = BasicFeatures.compute_realized_volatility(df['return_1d'], 20)

        # æˆäº¤é‡ç±»ç‰¹å¾ (3 ç»´)
        df['volume_sma20'] = BasicFeatures.compute_sma(df['volume'], 20)
        df['volume_ratio'] = df['volume'] / df['volume_sma20']
        df['obv'] = BasicFeatures.compute_obv(df['close'], df['volume'])

        # æ»åå›æŠ¥ç±»ç‰¹å¾ (5 ç»´) - return_1d å·²è®¡ç®—
        returns_df = BasicFeatures.compute_returns(df['close'], periods=[3, 5, 10, 20])
        df = pd.concat([df, returns_df], axis=1)

        logger.info(f"åŸºç¡€ç‰¹å¾è®¡ç®—å®Œæˆï¼Œæ–°å¢ {len(df.columns) - 6} ä¸ªç‰¹å¾")

        return df


def main():
    """æµ‹è¯•åŸºç¡€ç‰¹å¾è®¡ç®—"""
    # åˆ›å»ºæµ‹è¯•æ•°æ®
    dates = pd.date_range('2023-01-01', periods=300, freq='D')
    np.random.seed(42)

    test_df = pd.DataFrame({
        'date': dates,
        'open': 100 + np.random.randn(300).cumsum(),
        'high': 101 + np.random.randn(300).cumsum(),
        'low': 99 + np.random.randn(300).cumsum(),
        'close': 100 + np.random.randn(300).cumsum(),
        'volume': np.random.randint(1000000, 10000000, 300)
    })

    print("åŸå§‹æ•°æ®:")
    print(test_df.head())
    print(f"\nåŸå§‹åˆ—æ•°: {len(test_df.columns)}")

    # è®¡ç®—åŸºç¡€ç‰¹å¾
    result_df = BasicFeatures.compute_all_basic_features(test_df)

    print(f"\næ·»åŠ ç‰¹å¾ååˆ—æ•°: {len(result_df.columns)}")
    print("\næ–°å¢ç‰¹å¾:")
    new_features = [col for col in result_df.columns if col not in test_df.columns]
    for i, feat in enumerate(new_features, 1):
        print(f"{i:2d}. {feat}")

    print(f"\nç‰¹å¾æ•°æ®é¢„è§ˆ:")
    print(result_df[new_features].tail(5))

    # æ£€æŸ¥ç¼ºå¤±å€¼
    print(f"\nç¼ºå¤±å€¼ç»Ÿè®¡:")
    missing_counts = result_df[new_features].isnull().sum()
    print(missing_counts[missing_counts > 0])

    print(f"\nç‰¹å¾å®Œæ•´ç‡: {(1 - result_df[new_features].isnull().sum().sum() / (len(result_df) * len(new_features))):.2%}")


if __name__ == '__main__':
    main()

```

## src/feature_engineering/advanced_features.py

```python
"""
é«˜çº§ç‰¹å¾å·¥ç¨‹æ¨¡å— - å®ç° 40 ç»´é«˜çº§ç‰¹å¾
åŒ…æ‹¬:
1. Fractional Differentiation (6 ç»´)
2. Rolling Statistics (12 ç»´)
3. Cross-Sectional Rank (6 ç»´)
4. Sentiment Momentum (8 ç»´)
5. Adaptive Window Features (3 ç»´)
6. Cross-Asset Features (5 ç»´)
"""

import logging
import numpy as np
import pandas as pd
from typing import Dict, List, Optional

logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)


class AdvancedFeatures:
    """é«˜çº§ç‰¹å¾è®¡ç®—ç±»"""

    @staticmethod
    def fractional_diff(series: pd.Series, d: float = 0.5, threshold: float = 1e-5) -> pd.Series:
        """
        åˆ†æ•°é˜¶å·®åˆ† (Fractional Differentiation)
        ä¿ç•™è®°å¿†æ€§çš„åŒæ—¶å®ç°å¹³ç¨³åŒ–

        æ¥æº: "Advances in Financial Machine Learning" by Marcos Lopez de Prado

        Args:
            series: æ—¶é—´åºåˆ—
            d: å·®åˆ†é˜¶æ•° (0 < d < 1)ï¼Œd=1 ä¸ºå®Œå…¨å·®åˆ†ï¼Œd=0.5 ä¸ºåŠå·®åˆ†
            threshold: æƒé‡æˆªæ–­é˜ˆå€¼

        Returns:
            åˆ†æ•°é˜¶å·®åˆ†åçš„åºåˆ—
        """
        # è®¡ç®—æƒé‡
        weights = [1.0]
        k = 1

        # è¿­ä»£è®¡ç®—æƒé‡ç›´åˆ°å°äºé˜ˆå€¼
        while True:
            weight = -weights[-1] * (d - k + 1) / k
            if abs(weight) < threshold:
                break
            weights.append(weight)
            k += 1

        weights = np.array(weights[::-1])  # åè½¬æƒé‡

        # åº”ç”¨å·ç§¯
        result = pd.Series(index=series.index, dtype=float)
        for i in range(len(weights) - 1, len(series)):
            result.iloc[i] = np.dot(weights, series.iloc[i - len(weights) + 1:i + 1])

        return result

    @staticmethod
    def compute_fractional_features(df: pd.DataFrame) -> pd.DataFrame:
        """
        è®¡ç®— Fractional Differentiation ç‰¹å¾ (6 ç»´)

        ç‰¹å¾åˆ—è¡¨:
        1. frac_diff_close_05: æ”¶ç›˜ä»· d=0.5 åˆ†æ•°å·®åˆ†
        2. frac_diff_close_07: æ”¶ç›˜ä»· d=0.7 åˆ†æ•°å·®åˆ†
        3. frac_diff_volume_05: æˆäº¤é‡ d=0.5 åˆ†æ•°å·®åˆ†
        4. frac_diff_returns_05: æ”¶ç›Šç‡ d=0.5 åˆ†æ•°å·®åˆ†
        5. frac_diff_volatility_05: æ³¢åŠ¨ç‡ d=0.5 åˆ†æ•°å·®åˆ†
        6. frac_diff_sentiment_05: æƒ…æ„Ÿ d=0.5 åˆ†æ•°å·®åˆ†

        Args:
            df: åŒ…å« OHLCV å’Œæƒ…æ„Ÿæ•°æ®çš„ DataFrame

        Returns:
            æ·»åŠ äº† Fractional Differentiation ç‰¹å¾çš„ DataFrame
        """
        logger.info("è®¡ç®— Fractional Differentiation ç‰¹å¾...")

        # 1. æ”¶ç›˜ä»· d=0.5
        df['frac_diff_close_05'] = AdvancedFeatures.fractional_diff(
            df['close'], d=0.5
        )

        # 2. æ”¶ç›˜ä»· d=0.7 (æ›´å¼ºçš„å·®åˆ†)
        df['frac_diff_close_07'] = AdvancedFeatures.fractional_diff(
            df['close'], d=0.7
        )

        # 3. æˆäº¤é‡ d=0.5
        df['frac_diff_volume_05'] = AdvancedFeatures.fractional_diff(
            df['volume'], d=0.5
        )

        # 4. æ”¶ç›Šç‡ d=0.5
        returns = df['close'].pct_change()
        df['frac_diff_returns_05'] = AdvancedFeatures.fractional_diff(
            returns, d=0.5
        )

        # 5. æ³¢åŠ¨ç‡ d=0.5 (ä½¿ç”¨ 20 æ—¥æ»šåŠ¨æ ‡å‡†å·®)
        volatility = df['close'].pct_change().rolling(window=20).std()
        df['frac_diff_volatility_05'] = AdvancedFeatures.fractional_diff(
            volatility, d=0.5
        )

        # 6. æƒ…æ„Ÿ d=0.5
        if 'sentiment_mean' in df.columns:
            df['frac_diff_sentiment_05'] = AdvancedFeatures.fractional_diff(
                df['sentiment_mean'], d=0.5
            )
        else:
            df['frac_diff_sentiment_05'] = 0.0

        logger.info("Fractional Differentiation ç‰¹å¾è®¡ç®—å®Œæˆ (6 ç»´)")
        return df

    @staticmethod
    def compute_rolling_statistics(df: pd.DataFrame) -> pd.DataFrame:
        """
        è®¡ç®—æ»šåŠ¨ç»Ÿè®¡ç‰¹å¾ (12 ç»´)

        ç‰¹å¾åˆ—è¡¨:
        1. roll_skew_20: 20 æ—¥æ”¶ç›Šç‡ååº¦
        2. roll_kurt_20: 20 æ—¥æ”¶ç›Šç‡å³°åº¦
        3. roll_skew_60: 60 æ—¥æ”¶ç›Šç‡ååº¦
        4. roll_kurt_60: 60 æ—¥æ”¶ç›Šç‡å³°åº¦
        5. roll_autocorr_1: æ”¶ç›Šç‡è‡ªç›¸å…³(lag=1)
        6. roll_autocorr_5: æ”¶ç›Šç‡è‡ªç›¸å…³(lag=5)
        7. roll_max_drawdown_20: 20 æ—¥æœ€å¤§å›æ’¤
        8. roll_max_drawdown_60: 60 æ—¥æœ€å¤§å›æ’¤
        9. roll_sharpe_20: 20 æ—¥ Sharpe æ¯”ç‡
        10. roll_sortino_20: 20 æ—¥ Sortino æ¯”ç‡
        11. roll_calmar_60: 60 æ—¥ Calmar æ¯”ç‡
        12. roll_tail_ratio_20: 20 æ—¥å°¾éƒ¨æ¯”ç‡ (95th/5th percentile)

        Args:
            df: DataFrame

        Returns:
            æ·»åŠ äº†æ»šåŠ¨ç»Ÿè®¡ç‰¹å¾çš„ DataFrame
        """
        logger.info("è®¡ç®— Rolling Statistics ç‰¹å¾...")

        returns = df['close'].pct_change()

        # 1-2. 20 æ—¥ååº¦å’Œå³°åº¦
        df['roll_skew_20'] = returns.rolling(window=20).skew()
        df['roll_kurt_20'] = returns.rolling(window=20).kurt()

        # 3-4. 60 æ—¥ååº¦å’Œå³°åº¦
        df['roll_skew_60'] = returns.rolling(window=60).skew()
        df['roll_kurt_60'] = returns.rolling(window=60).kurt()

        # 5-6. è‡ªç›¸å…³
        df['roll_autocorr_1'] = returns.rolling(window=20).apply(
            lambda x: x.autocorr(lag=1) if len(x) > 1 else np.nan
        )
        df['roll_autocorr_5'] = returns.rolling(window=20).apply(
            lambda x: x.autocorr(lag=5) if len(x) > 5 else np.nan
        )

        # 7-8. æœ€å¤§å›æ’¤
        def max_drawdown(prices):
            cumulative = (1 + prices).cumprod()
            running_max = cumulative.expanding().max()
            drawdown = (cumulative - running_max) / running_max
            return drawdown.min()

        df['roll_max_drawdown_20'] = returns.rolling(window=20).apply(max_drawdown)
        df['roll_max_drawdown_60'] = returns.rolling(window=60).apply(max_drawdown)

        # 9. Sharpe æ¯”ç‡ (å‡è®¾æ— é£é™©åˆ©ç‡=0)
        df['roll_sharpe_20'] = (
            returns.rolling(window=20).mean() / returns.rolling(window=20).std()
        ) * np.sqrt(252)  # å¹´åŒ–

        # 10. Sortino æ¯”ç‡ (åªè€ƒè™‘ä¸‹è¡Œæ³¢åŠ¨)
        def sortino_ratio(rets):
            downside = rets[rets < 0]
            if len(downside) > 0:
                downside_std = downside.std()
                if downside_std > 0:
                    return (rets.mean() / downside_std) * np.sqrt(252)
            return np.nan

        df['roll_sortino_20'] = returns.rolling(window=20).apply(sortino_ratio)

        # 11. Calmar æ¯”ç‡ (æ”¶ç›Šç‡ / æœ€å¤§å›æ’¤)
        df['roll_calmar_60'] = (
            returns.rolling(window=60).mean() * 252 /  # å¹´åŒ–æ”¶ç›Š
            df['roll_max_drawdown_60'].abs()
        )

        # 12. å°¾éƒ¨æ¯”ç‡
        def tail_ratio(rets):
            if len(rets) > 0:
                p95 = np.percentile(rets, 95)
                p05 = np.percentile(rets, 5)
                if p05 != 0:
                    return abs(p95 / p05)
            return np.nan

        df['roll_tail_ratio_20'] = returns.rolling(window=20).apply(tail_ratio)

        logger.info("Rolling Statistics ç‰¹å¾è®¡ç®—å®Œæˆ (12 ç»´)")
        return df

    @staticmethod
    def compute_cross_sectional_rank(df: pd.DataFrame, all_dfs: Dict[str, pd.DataFrame] = None) -> pd.DataFrame:
        """
        è®¡ç®—æ¨ªæˆªé¢æ’åç‰¹å¾ (6 ç»´)
        ç›¸å¯¹äºæ‰€æœ‰èµ„äº§çš„æ’å

        ç‰¹å¾åˆ—è¡¨:
        1. cs_rank_return_1d: 1 æ—¥æ”¶ç›Šç‡æ¨ªæˆªé¢æ’å
        2. cs_rank_return_5d: 5 æ—¥æ”¶ç›Šç‡æ¨ªæˆªé¢æ’å
        3. cs_rank_volatility: æ³¢åŠ¨ç‡æ¨ªæˆªé¢æ’å
        4. cs_rank_volume: æˆäº¤é‡æ¨ªæˆªé¢æ’å
        5. cs_rank_rsi: RSI æ¨ªæˆªé¢æ’å
        6. cs_rank_sentiment: æƒ…æ„Ÿæ¨ªæˆªé¢æ’å

        Args:
            df: å½“å‰èµ„äº§çš„ DataFrame
            all_dfs: æ‰€æœ‰èµ„äº§çš„ DataFrame å­—å…¸ {symbol: df}

        Returns:
            æ·»åŠ äº†æ¨ªæˆªé¢æ’åç‰¹å¾çš„ DataFrame
        """
        logger.info("è®¡ç®— Cross-Sectional Rank ç‰¹å¾...")

        if all_dfs is None or len(all_dfs) < 2:
            # å¦‚æœæ²¡æœ‰å…¶ä»–èµ„äº§æ•°æ®,è®¾ç½®ä¸ºä¸­ä½æ•° 0.5
            logger.warning("æ²¡æœ‰å…¶ä»–èµ„äº§æ•°æ®,æ¨ªæˆªé¢æ’åç‰¹å¾è®¾ä¸º 0.5")
            df['cs_rank_return_1d'] = 0.5
            df['cs_rank_return_5d'] = 0.5
            df['cs_rank_volatility'] = 0.5
            df['cs_rank_volume'] = 0.5
            df['cs_rank_rsi'] = 0.5
            df['cs_rank_sentiment'] = 0.5
            return df

        # ä¸ºæ¯ä¸ªæ—¥æœŸè®¡ç®—æ¨ªæˆªé¢æ’å
        dates = df['date'].unique()

        for date in dates:
            # æ”¶é›†æ‰€æœ‰èµ„äº§åœ¨è¯¥æ—¥æœŸçš„æ•°æ®
            cross_section = []
            for symbol, other_df in all_dfs.items():
                date_data = other_df[other_df['date'] == date]
                if not date_data.empty:
                    cross_section.append({
                        'symbol': symbol,
                        'return_1d': date_data['return_1d'].iloc[0] if 'return_1d' in date_data.columns else np.nan,
                        'return_5d': date_data['return_5d'].iloc[0] if 'return_5d' in date_data.columns else np.nan,
                        'volatility': date_data['volatility_20d'].iloc[0] if 'volatility_20d' in date_data.columns else np.nan,
                        'volume': date_data['volume'].iloc[0],
                        'rsi': date_data['rsi_14'].iloc[0] if 'rsi_14' in date_data.columns else np.nan,
                        'sentiment': date_data['sentiment_mean'].iloc[0] if 'sentiment_mean' in date_data.columns else 0,
                    })

            if len(cross_section) > 1:
                cs_df = pd.DataFrame(cross_section)

                # è®¡ç®—æ’å (ç™¾åˆ†ä½æ•°)
                current_symbol = df[df['date'] == date]['symbol'].iloc[0] if 'symbol' in df.columns else None

                if current_symbol:
                    for col, feature in [
                        ('return_1d', 'cs_rank_return_1d'),
                        ('return_5d', 'cs_rank_return_5d'),
                        ('volatility', 'cs_rank_volatility'),
                        ('volume', 'cs_rank_volume'),
                        ('rsi', 'cs_rank_rsi'),
                        ('sentiment', 'cs_rank_sentiment'),
                    ]:
                        if col in cs_df.columns:
                            cs_df[feature] = cs_df[col].rank(pct=True)
                            rank_value = cs_df[cs_df['symbol'] == current_symbol][feature].iloc[0] if not cs_df[cs_df['symbol'] == current_symbol].empty else 0.5
                            df.loc[df['date'] == date, feature] = rank_value

        logger.info("Cross-Sectional Rank ç‰¹å¾è®¡ç®—å®Œæˆ (6 ç»´)")
        return df

    @staticmethod
    def compute_sentiment_momentum(df: pd.DataFrame) -> pd.DataFrame:
        """
        è®¡ç®—æƒ…æ„ŸåŠ¨é‡ç‰¹å¾ (8 ç»´)

        ç‰¹å¾åˆ—è¡¨:
        1. sentiment_momentum_5d: 5 æ—¥æƒ…æ„ŸåŠ¨é‡
        2. sentiment_momentum_20d: 20 æ—¥æƒ…æ„ŸåŠ¨é‡
        3. sentiment_acceleration: æƒ…æ„ŸåŠ é€Ÿåº¦ (åŠ¨é‡çš„å˜åŒ–)
        4. sentiment_divergence: æƒ…æ„Ÿ-ä»·æ ¼èƒŒç¦» (æƒ…æ„Ÿä¸Šæ¶¨ä½†ä»·æ ¼ä¸‹è·Œ)
        5. sentiment_consistency_5d: 5 æ—¥æƒ…æ„Ÿä¸€è‡´æ€§ (è¿ç»­æ­£/è´Ÿçš„æ¯”ä¾‹)
        6. sentiment_intensity: æƒ…æ„Ÿå¼ºåº¦ (ç»å¯¹å€¼çš„å‡å€¼)
        7. sentiment_volatility_20d: 20 æ—¥æƒ…æ„Ÿæ³¢åŠ¨ç‡
        8. news_frequency_ma20: 20 æ—¥æ–°é—»é¢‘ç‡ç§»åŠ¨å¹³å‡

        Args:
            df: DataFrame

        Returns:
            æ·»åŠ äº†æƒ…æ„ŸåŠ¨é‡ç‰¹å¾çš„ DataFrame
        """
        logger.info("è®¡ç®— Sentiment Momentum ç‰¹å¾...")

        if 'sentiment_mean' not in df.columns:
            logger.warning("æ²¡æœ‰æƒ…æ„Ÿæ•°æ®,æƒ…æ„ŸåŠ¨é‡ç‰¹å¾è®¾ä¸º 0")
            for feat in ['sentiment_momentum_5d', 'sentiment_momentum_20d',
                        'sentiment_acceleration', 'sentiment_divergence',
                        'sentiment_consistency_5d', 'sentiment_intensity',
                        'sentiment_volatility_20d', 'news_frequency_ma20']:
                df[feat] = 0.0
            return df

        # 1-2. æƒ…æ„ŸåŠ¨é‡
        df['sentiment_momentum_5d'] = df['sentiment_mean'] - df['sentiment_mean'].shift(5)
        df['sentiment_momentum_20d'] = df['sentiment_mean'] - df['sentiment_mean'].shift(20)

        # 3. æƒ…æ„ŸåŠ é€Ÿåº¦
        df['sentiment_acceleration'] = df['sentiment_momentum_5d'] - df['sentiment_momentum_5d'].shift(5)

        # 4. æƒ…æ„Ÿ-ä»·æ ¼èƒŒç¦»
        price_momentum = df['close'].pct_change(5)
        sentiment_momentum = df['sentiment_momentum_5d']
        df['sentiment_divergence'] = (
            ((sentiment_momentum > 0) & (price_momentum < 0)).astype(int) -
            ((sentiment_momentum < 0) & (price_momentum > 0)).astype(int)
        )

        # 5. æƒ…æ„Ÿä¸€è‡´æ€§ (5 æ—¥çª—å£å†…åŒå‘æ¯”ä¾‹)
        def consistency(series):
            if len(series) == 0:
                return 0
            positive = (series > 0).sum()
            negative = (series < 0).sum()
            return max(positive, negative) / len(series)

        df['sentiment_consistency_5d'] = df['sentiment_mean'].rolling(window=5).apply(consistency)

        # 6. æƒ…æ„Ÿå¼ºåº¦
        df['sentiment_intensity'] = df['sentiment_mean'].abs().rolling(window=20).mean()

        # 7. æƒ…æ„Ÿæ³¢åŠ¨ç‡
        df['sentiment_volatility_20d'] = df['sentiment_mean'].rolling(window=20).std()

        # 8. æ–°é—»é¢‘ç‡ç§»åŠ¨å¹³å‡
        if 'news_count' in df.columns:
            df['news_frequency_ma20'] = df['news_count'].rolling(window=20).mean()
        else:
            df['news_frequency_ma20'] = 0.0

        logger.info("Sentiment Momentum ç‰¹å¾è®¡ç®—å®Œæˆ (8 ç»´)")
        return df

    @staticmethod
    def compute_adaptive_window_features(df: pd.DataFrame) -> pd.DataFrame:
        """
        è®¡ç®—è‡ªé€‚åº”çª—å£ç‰¹å¾ (3 ç»´)
        æ ¹æ®å¸‚åœºæ³¢åŠ¨ç‡åŠ¨æ€è°ƒæ•´çª—å£å¤§å°

        ç‰¹å¾åˆ—è¡¨:
        1. adaptive_ma: è‡ªé€‚åº”ç§»åŠ¨å¹³å‡ (åŸºäºæ³¢åŠ¨ç‡è°ƒæ•´çª—å£)
        2. adaptive_momentum: è‡ªé€‚åº”åŠ¨é‡
        3. adaptive_volatility_ratio: è‡ªé€‚åº”æ³¢åŠ¨ç‡æ¯”ç‡

        Args:
            df: DataFrame

        Returns:
            æ·»åŠ äº†è‡ªé€‚åº”çª—å£ç‰¹å¾çš„ DataFrame
        """
        logger.info("è®¡ç®— Adaptive Window Features...")

        # è®¡ç®—åŸºå‡†æ³¢åŠ¨ç‡
        returns = df['close'].pct_change()
        baseline_vol = returns.rolling(window=60).std()
        current_vol = returns.rolling(window=20).std()

        # æ³¢åŠ¨ç‡æ¯”ç‡ (å½“å‰/åŸºå‡†)
        vol_ratio = current_vol / baseline_vol
        vol_ratio = vol_ratio.fillna(1.0).clip(0.5, 2.0)  # é™åˆ¶åœ¨ 0.5-2 å€

        # 1. è‡ªé€‚åº”ç§»åŠ¨å¹³å‡ (é«˜æ³¢åŠ¨æ—¶ç”¨çŸ­çª—å£,ä½æ³¢åŠ¨æ—¶ç”¨é•¿çª—å£)
        # çª—å£: 10 åˆ° 50 å¤©
        adaptive_window = (50 - 40 * (vol_ratio - 0.5) / 1.5).clip(10, 50).astype(int)

        df['adaptive_ma'] = np.nan
        for i in range(len(df)):
            if i >= 50:  # ç¡®ä¿æœ‰è¶³å¤Ÿæ•°æ®
                window = adaptive_window.iloc[i]
                df.loc[df.index[i], 'adaptive_ma'] = df['close'].iloc[i-window:i].mean()

        # 2. è‡ªé€‚åº”åŠ¨é‡
        df['adaptive_momentum'] = df['close'] / df['adaptive_ma'] - 1

        # 3. è‡ªé€‚åº”æ³¢åŠ¨ç‡æ¯”ç‡
        df['adaptive_volatility_ratio'] = vol_ratio

        logger.info("Adaptive Window Features è®¡ç®—å®Œæˆ (3 ç»´)")
        return df

    @staticmethod
    def compute_cross_asset_features(df: pd.DataFrame, reference_df: pd.DataFrame = None,
                                    reference_symbol: str = 'GSPC.INDX') -> pd.DataFrame:
        """
        è®¡ç®—è·¨èµ„äº§ç‰¹å¾ (5 ç»´)
        ç›¸å¯¹äºåŸºå‡†èµ„äº§(å¦‚ S&P 500)çš„ç‰¹å¾

        ç‰¹å¾åˆ—è¡¨:
        1. beta_to_market: ç›¸å¯¹å¸‚åœºçš„ Beta (60æ—¥)
        2. correlation_to_market: ä¸å¸‚åœºçš„ç›¸å…³æ€§ (60æ—¥)
        3. relative_strength: ç›¸å¯¹å¼ºåº¦ (å½“å‰èµ„äº§æ”¶ç›Š / å¸‚åœºæ”¶ç›Š)
        4. alpha_to_market: ç›¸å¯¹å¸‚åœºçš„ Alpha
        5. tracking_error: è·Ÿè¸ªè¯¯å·®

        Args:
            df: å½“å‰èµ„äº§çš„ DataFrame
            reference_df: åŸºå‡†èµ„äº§çš„ DataFrame
            reference_symbol: åŸºå‡†èµ„äº§åç§°

        Returns:
            æ·»åŠ äº†è·¨èµ„äº§ç‰¹å¾çš„ DataFrame
        """
        logger.info("è®¡ç®— Cross-Asset Features...")

        if reference_df is None or reference_df.empty:
            logger.warning("æ²¡æœ‰åŸºå‡†èµ„äº§æ•°æ®,è·¨èµ„äº§ç‰¹å¾è®¾ä¸º 0")
            df['beta_to_market'] = 0.0
            df['correlation_to_market'] = 0.0
            df['relative_strength'] = 0.0
            df['alpha_to_market'] = 0.0
            df['tracking_error'] = 0.0
            return df

        # ç¡®ä¿æ—¥æœŸå¯¹é½
        df['date'] = pd.to_datetime(df['date'])
        reference_df['date'] = pd.to_datetime(reference_df['date'])

        # åˆå¹¶æ•°æ®
        merged = pd.merge(
            df[['date', 'close']],
            reference_df[['date', 'close']],
            on='date',
            how='left',
            suffixes=('', '_market')
        )

        # è®¡ç®—æ”¶ç›Šç‡
        merged['return'] = merged['close'].pct_change()
        merged['return_market'] = merged['close_market'].pct_change()

        # 1. Beta (60æ—¥æ»šåŠ¨)
        def rolling_beta(returns, market_returns):
            """è®¡ç®— Beta"""
            # å»é™¤ NaN
            mask = ~(np.isnan(returns) | np.isnan(market_returns))
            if mask.sum() < 10:
                return np.nan

            returns_clean = returns[mask]
            market_returns_clean = market_returns[mask]

            # è®¡ç®—åæ–¹å·®å’Œæ–¹å·®
            if len(returns_clean) < 10:
                return np.nan

            covariance = np.cov(returns_clean, market_returns_clean)[0, 1]
            market_variance = np.var(market_returns_clean)

            if market_variance > 0:
                return covariance / market_variance
            return np.nan

        # è®¡ç®—æ»šåŠ¨ Beta
        beta_values = []
        for i in range(len(merged)):
            if i < 60:
                beta_values.append(np.nan)
            else:
                window_returns = merged['return'].iloc[i-60:i].values
                window_market = merged['return_market'].iloc[i-60:i].values
                beta = rolling_beta(window_returns, window_market)
                beta_values.append(beta)

        merged['beta_to_market'] = beta_values

        # 2. ç›¸å…³æ€§ (60æ—¥)
        merged['correlation_to_market'] = merged['return'].rolling(window=60).corr(merged['return_market'])

        # 3. ç›¸å¯¹å¼ºåº¦ (20æ—¥ç´¯è®¡æ”¶ç›Šæ¯”)
        merged['relative_strength'] = (
            (1 + merged['return']).rolling(window=20).apply(lambda x: x.prod()) /
            (1 + merged['return_market']).rolling(window=20).apply(lambda x: x.prod())
        )

        # 4. Alpha (æ”¶ç›Šç‡ - Beta * å¸‚åœºæ”¶ç›Šç‡)
        merged['alpha_to_market'] = merged['return'] - merged['beta_to_market'] * merged['return_market']

        # 5. è·Ÿè¸ªè¯¯å·® (60æ—¥)
        merged['tracking_error'] = (merged['return'] - merged['return_market']).rolling(window=60).std() * np.sqrt(252)

        # åˆå¹¶å›åŸ DataFrame
        df['beta_to_market'] = merged['beta_to_market'].values
        df['correlation_to_market'] = merged['correlation_to_market'].values
        df['relative_strength'] = merged['relative_strength'].values
        df['alpha_to_market'] = merged['alpha_to_market'].values
        df['tracking_error'] = merged['tracking_error'].values

        logger.info("Cross-Asset Features è®¡ç®—å®Œæˆ (5 ç»´)")
        return df

    @staticmethod
    def compute_all_advanced_features(df: pd.DataFrame, all_dfs: Dict[str, pd.DataFrame] = None,
                                     reference_df: pd.DataFrame = None) -> pd.DataFrame:
        """
        è®¡ç®—æ‰€æœ‰é«˜çº§ç‰¹å¾ (40 ç»´)

        Args:
            df: å½“å‰èµ„äº§çš„ DataFrame
            all_dfs: æ‰€æœ‰èµ„äº§çš„ DataFrame å­—å…¸ (ç”¨äºæ¨ªæˆªé¢ç‰¹å¾)
            reference_df: åŸºå‡†èµ„äº§çš„ DataFrame (ç”¨äºè·¨èµ„äº§ç‰¹å¾)

        Returns:
            æ·»åŠ äº†æ‰€æœ‰é«˜çº§ç‰¹å¾çš„ DataFrame
        """
        logger.info("å¼€å§‹è®¡ç®—æ‰€æœ‰é«˜çº§ç‰¹å¾ (40 ç»´)...")

        # 1. Fractional Differentiation (6 ç»´)
        df = AdvancedFeatures.compute_fractional_features(df)

        # 2. Rolling Statistics (12 ç»´)
        df = AdvancedFeatures.compute_rolling_statistics(df)

        # 3. Cross-Sectional Rank (6 ç»´)
        df = AdvancedFeatures.compute_cross_sectional_rank(df, all_dfs)

        # 4. Sentiment Momentum (8 ç»´)
        df = AdvancedFeatures.compute_sentiment_momentum(df)

        # 5. Adaptive Window Features (3 ç»´)
        df = AdvancedFeatures.compute_adaptive_window_features(df)

        # 6. Cross-Asset Features (5 ç»´)
        df = AdvancedFeatures.compute_cross_asset_features(df, reference_df)

        logger.info("æ‰€æœ‰é«˜çº§ç‰¹å¾è®¡ç®—å®Œæˆ (40 ç»´) âœ“")
        return df


# æµ‹è¯•ä»£ç 
if __name__ == '__main__':
    # åˆ›å»ºæµ‹è¯•æ•°æ®
    np.random.seed(42)
    dates = pd.date_range('2023-01-01', '2024-01-01', freq='D')

    test_df = pd.DataFrame({
        'date': dates,
        'symbol': 'TEST',
        'open': 100 + np.cumsum(np.random.randn(len(dates))),
        'high': 102 + np.cumsum(np.random.randn(len(dates))),
        'low': 98 + np.cumsum(np.random.randn(len(dates))),
        'close': 100 + np.cumsum(np.random.randn(len(dates))),
        'volume': np.random.randint(1000000, 10000000, len(dates)),
        'sentiment_mean': np.random.randn(len(dates)) * 0.5,
        'news_count': np.random.randint(0, 10, len(dates)),
    })

    # æ·»åŠ åŸºç¡€ç‰¹å¾
    test_df['return_1d'] = test_df['close'].pct_change()
    test_df['return_5d'] = test_df['close'].pct_change(5)
    test_df['volatility_20d'] = test_df['return_1d'].rolling(20).std()
    test_df['rsi_14'] = 50.0

    print("æµ‹è¯•é«˜çº§ç‰¹å¾è®¡ç®—...")
    print("=" * 60)

    # æµ‹è¯• Fractional Differentiation
    test_df = AdvancedFeatures.compute_fractional_features(test_df)
    print("\nFractional Differentiation ç‰¹å¾:")
    print(test_df[['date', 'frac_diff_close_05', 'frac_diff_close_07']].tail())

    # æµ‹è¯• Rolling Statistics
    test_df = AdvancedFeatures.compute_rolling_statistics(test_df)
    print("\nRolling Statistics ç‰¹å¾:")
    print(test_df[['date', 'roll_skew_20', 'roll_sharpe_20']].tail())

    # æµ‹è¯• Sentiment Momentum
    test_df = AdvancedFeatures.compute_sentiment_momentum(test_df)
    print("\nSentiment Momentum ç‰¹å¾:")
    print(test_df[['date', 'sentiment_momentum_5d', 'sentiment_divergence']].tail())

    # æµ‹è¯• Adaptive Window Features
    test_df = AdvancedFeatures.compute_adaptive_window_features(test_df)
    print("\nAdaptive Window Features:")
    print(test_df[['date', 'adaptive_ma', 'adaptive_momentum']].tail())

    print("\n" + "=" * 60)
    print("é«˜çº§ç‰¹å¾æµ‹è¯•å®Œæˆ!")
    print(f"æ€»ç‰¹å¾æ•°: {len(test_df.columns)} åˆ—")

```

## src/feature_engineering/labeling.py

```python
"""
æ ‡ç­¾ç”Ÿæˆæ¨¡å— - Triple Barrier Labeling
ç”¨äºç›‘ç£å­¦ä¹ çš„æ ‡ç­¾ç”Ÿæˆ

æ¥æº: "Advances in Financial Machine Learning" by Marcos Lopez de Prado
"""

import logging
import numpy as np
import pandas as pd
from typing import Optional, Tuple

logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)


class TripleBarrierLabeling:
    """
    ä¸‰é‡å£å’æ ‡ç­¾æ³• (Triple Barrier Method)

    ä¸ºæ¯ä¸ªæ ·æœ¬è®¾ç½®ä¸‰ä¸ªé€€å‡ºæ¡ä»¶:
    1. ä¸Šç•Œ (Upper Barrier): ä»·æ ¼ä¸Šæ¶¨è¾¾åˆ°ç›®æ ‡æ”¶ç›Š -> æ ‡ç­¾ = 1 (åšå¤š)
    2. ä¸‹ç•Œ (Lower Barrier): ä»·æ ¼ä¸‹è·Œè¾¾åˆ°æ­¢æŸ -> æ ‡ç­¾ = -1 (åšç©º/æ­¢æŸ)
    3. æ—¶é—´ç•Œ (Vertical Barrier): æŒæœ‰æœŸåˆ°æœŸ -> æ ‡ç­¾ = 0 æˆ–åŸºäºæ”¶ç›Šæ–¹å‘

    ä¼˜åŠ¿:
    - é¿å…å›ºå®šæŒæœ‰æœŸçš„åå·®
    - è€ƒè™‘æ­¢æŸå’Œæ­¢ç›ˆ
    - æ›´ç¬¦åˆå®é™…äº¤æ˜“é€»è¾‘
    """

    @staticmethod
    def apply_triple_barrier(
        prices: pd.Series,
        upper_barrier: float = 0.02,
        lower_barrier: float = -0.02,
        max_holding_period: int = 5,
        stop_loss: Optional[float] = None
    ) -> pd.DataFrame:
        """
        åº”ç”¨ä¸‰é‡å£å’æ ‡ç­¾æ³•

        Args:
            prices: ä»·æ ¼åºåˆ— (Series with datetime index)
            upper_barrier: ä¸Šç•Œæ”¶ç›Šç‡é˜ˆå€¼ (é»˜è®¤ 2%)
            lower_barrier: ä¸‹ç•Œæ”¶ç›Šç‡é˜ˆå€¼ (é»˜è®¤ -2%)
            max_holding_period: æœ€å¤§æŒæœ‰æœŸ (å¤©æ•°)
            stop_loss: æ­¢æŸé˜ˆå€¼ (å¯é€‰,å¦‚ -1% æ­¢æŸ)

        Returns:
            DataFrame åŒ…å«:
                - label: æ ‡ç­¾ (1=ä¸Šæ¶¨, -1=ä¸‹è·Œ, 0=ä¸­æ€§)
                - barrier_touched: è§¦å‘çš„å£å’ç±»å‹ ('upper', 'lower', 'vertical')
                - holding_period: å®é™…æŒæœ‰æœŸ
                - return: å®é™…æ”¶ç›Šç‡
        """
        logger.info("åº”ç”¨ Triple Barrier Labeling...")

        results = []

        for i in range(len(prices) - max_holding_period):
            entry_price = prices.iloc[i]
            entry_date = prices.index[i]

            # æœªæ¥ä»·æ ¼åºåˆ—
            future_prices = prices.iloc[i+1:i+1+max_holding_period]

            if len(future_prices) == 0:
                continue

            # è®¡ç®—æ”¶ç›Šç‡
            returns = (future_prices - entry_price) / entry_price

            # æ£€æŸ¥å£å’è§¦å‘
            label = 0
            barrier_touched = 'vertical'
            holding_period = max_holding_period
            actual_return = returns.iloc[-1] if len(returns) > 0 else 0

            # 1. æ£€æŸ¥ä¸Šç•Œ
            upper_touch = returns >= upper_barrier
            if upper_touch.any():
                upper_idx = upper_touch.idxmax()
                upper_day = returns.index.get_loc(upper_idx)

                # 2. æ£€æŸ¥ä¸‹ç•Œ
                lower_touch = returns <= lower_barrier
                if lower_touch.any():
                    lower_idx = lower_touch.idxmax()
                    lower_day = returns.index.get_loc(lower_idx)

                    # å“ªä¸ªå…ˆè§¦å‘
                    if upper_day <= lower_day:
                        label = 1
                        barrier_touched = 'upper'
                        holding_period = upper_day + 1
                        actual_return = returns.iloc[upper_day]
                    else:
                        label = -1
                        barrier_touched = 'lower'
                        holding_period = lower_day + 1
                        actual_return = returns.iloc[lower_day]
                else:
                    # åªè§¦å‘ä¸Šç•Œ
                    label = 1
                    barrier_touched = 'upper'
                    holding_period = upper_day + 1
                    actual_return = returns.iloc[upper_day]

            else:
                # 3. æ£€æŸ¥ä¸‹ç•Œ
                lower_touch = returns <= lower_barrier
                if lower_touch.any():
                    lower_idx = lower_touch.idxmax()
                    lower_day = returns.index.get_loc(lower_idx)
                    label = -1
                    barrier_touched = 'lower'
                    holding_period = lower_day + 1
                    actual_return = returns.iloc[lower_day]
                else:
                    # åˆ°è¾¾æ—¶é—´ç•Œ
                    # åŸºäºæœ€ç»ˆæ”¶ç›Šæ–¹å‘åˆ¤æ–­æ ‡ç­¾
                    if actual_return > 0:
                        label = 1
                    elif actual_return < 0:
                        label = -1
                    else:
                        label = 0

            # 4. æ£€æŸ¥æ­¢æŸ (å¯é€‰)
            if stop_loss is not None and stop_loss < 0:
                stop_touch = returns <= stop_loss
                if stop_touch.any():
                    stop_idx = stop_touch.idxmax()
                    stop_day = returns.index.get_loc(stop_idx)

                    # æ­¢æŸä¼˜å…ˆ
                    if stop_day < holding_period:
                        label = -1
                        barrier_touched = 'stop_loss'
                        holding_period = stop_day + 1
                        actual_return = returns.iloc[stop_day]

            results.append({
                'date': entry_date,
                'label': label,
                'barrier_touched': barrier_touched,
                'holding_period': holding_period,
                'return': actual_return,
                'entry_price': entry_price,
            })

        result_df = pd.DataFrame(results)
        result_df.set_index('date', inplace=True)

        # ç»Ÿè®¡
        label_counts = result_df['label'].value_counts()
        logger.info(f"æ ‡ç­¾åˆ†å¸ƒ: {label_counts.to_dict()}")
        logger.info(f"å¹³å‡æŒæœ‰æœŸ: {result_df['holding_period'].mean():.2f} å¤©")
        logger.info(f"è§¦å‘ç»Ÿè®¡: {result_df['barrier_touched'].value_counts().to_dict()}")

        return result_df

    @staticmethod
    def compute_meta_labels(
        predictions: pd.Series,
        actual_returns: pd.Series,
        threshold: float = 0.0
    ) -> pd.Series:
        """
        è®¡ç®—å…ƒæ ‡ç­¾ (Meta-Labeling)

        å…ƒæ ‡ç­¾ç”¨äºäºŒçº§æ¨¡å‹,åˆ¤æ–­ä¸»æ¨¡å‹çš„é¢„æµ‹æ˜¯å¦åº”è¯¥è¢«ä¿¡ä»»

        Args:
            predictions: ä¸»æ¨¡å‹çš„é¢„æµ‹ (1=åšå¤š, -1=åšç©º)
            actual_returns: å®é™…æ”¶ç›Šç‡
            threshold: æ”¶ç›Šç‡é˜ˆå€¼ (é»˜è®¤ 0,å³ç›ˆåˆ©=1,äºæŸ=0)

        Returns:
            å…ƒæ ‡ç­¾åºåˆ— (1=åº”è¯¥äº¤æ˜“, 0=ä¸åº”è¯¥äº¤æ˜“)
        """
        logger.info("è®¡ç®— Meta-Labels...")

        meta_labels = pd.Series(0, index=predictions.index)

        # åšå¤šä¿¡å· -> æ£€æŸ¥æ˜¯å¦ç›ˆåˆ©
        long_signals = predictions == 1
        meta_labels[long_signals & (actual_returns > threshold)] = 1

        # åšç©ºä¿¡å· -> æ£€æŸ¥æ˜¯å¦ç›ˆåˆ©
        short_signals = predictions == -1
        meta_labels[short_signals & (actual_returns < -threshold)] = 1

        positive_rate = meta_labels.mean()
        logger.info(f"å…ƒæ ‡ç­¾æ­£æ ·æœ¬æ¯”ä¾‹: {positive_rate:.2%}")

        return meta_labels

    @staticmethod
    def compute_sample_weights(
        labels: pd.Series,
        returns: pd.Series,
        decay: float = 0.95
    ) -> pd.Series:
        """
        è®¡ç®—æ ·æœ¬æƒé‡ (Sample Weights)

        è€ƒè™‘å› ç´ :
        1. æ—¶é—´è¡°å‡: è¿‘æœŸæ ·æœ¬æƒé‡æ›´é«˜
        2. æ”¶ç›Šå¹…åº¦: æ”¶ç›Šè¶Šå¤§æƒé‡è¶Šé«˜
        3. ç±»åˆ«å¹³è¡¡: å°‘æ•°ç±»æ ·æœ¬æƒé‡æ›´é«˜

        Args:
            labels: æ ‡ç­¾åºåˆ—
            returns: æ”¶ç›Šç‡åºåˆ—
            decay: æ—¶é—´è¡°å‡ç³»æ•° (é»˜è®¤ 0.95)

        Returns:
            æ ·æœ¬æƒé‡åºåˆ—
        """
        logger.info("è®¡ç®—æ ·æœ¬æƒé‡...")

        weights = pd.Series(1.0, index=labels.index)

        # 1. æ—¶é—´è¡°å‡æƒé‡
        n = len(labels)
        time_weights = np.array([decay ** (n - i - 1) for i in range(n)])
        weights *= time_weights

        # 2. æ”¶ç›Šå¹…åº¦æƒé‡ (ç»å¯¹æ”¶ç›Šè¶Šå¤§æƒé‡è¶Šé«˜)
        return_weights = 1 + np.abs(returns)
        weights *= return_weights

        # 3. ç±»åˆ«å¹³è¡¡æƒé‡
        label_counts = labels.value_counts()
        max_count = label_counts.max()

        for label, count in label_counts.items():
            class_weight = max_count / count
            weights[labels == label] *= class_weight

        # å½’ä¸€åŒ–
        weights = weights / weights.sum() * len(weights)

        logger.info(f"æƒé‡ç»Ÿè®¡: mean={weights.mean():.4f}, std={weights.std():.4f}, "
                   f"min={weights.min():.4f}, max={weights.max():.4f}")

        return weights

    @staticmethod
    def add_labels_to_dataframe(
        df: pd.DataFrame,
        price_column: str = 'close',
        upper_barrier: float = 0.02,
        lower_barrier: float = -0.02,
        max_holding_period: int = 5,
        stop_loss: Optional[float] = None
    ) -> pd.DataFrame:
        """
        å°† Triple Barrier æ ‡ç­¾æ·»åŠ åˆ° DataFrame

        Args:
            df: åŒ…å«ä»·æ ¼æ•°æ®çš„ DataFrame
            price_column: ä»·æ ¼åˆ—å
            upper_barrier: ä¸Šç•Œé˜ˆå€¼
            lower_barrier: ä¸‹ç•Œé˜ˆå€¼
            max_holding_period: æœ€å¤§æŒæœ‰æœŸ
            stop_loss: æ­¢æŸé˜ˆå€¼

        Returns:
            æ·»åŠ äº†æ ‡ç­¾åˆ—çš„ DataFrame
        """
        logger.info(f"ä¸º DataFrame æ·»åŠ  Triple Barrier æ ‡ç­¾...")

        # åº”ç”¨ä¸‰é‡å£å’
        prices = df.set_index('date')[price_column] if 'date' in df.columns else df[price_column]
        labels_df = TripleBarrierLabeling.apply_triple_barrier(
            prices,
            upper_barrier=upper_barrier,
            lower_barrier=lower_barrier,
            max_holding_period=max_holding_period,
            stop_loss=stop_loss
        )

        # åˆå¹¶æ ‡ç­¾
        df = df.set_index('date') if 'date' in df.columns else df
        df = df.join(labels_df[['label', 'barrier_touched', 'holding_period', 'return']], how='left')

        # å¡«å……æœªæ ‡æ³¨çš„è¡Œ
        df['label'] = df['label'].fillna(0).astype(int)
        df['barrier_touched'] = df['barrier_touched'].fillna('none')
        df['holding_period'] = df['holding_period'].fillna(0).astype(int)
        df['return'] = df['return'].fillna(0)

        # è®¡ç®—æ ·æœ¬æƒé‡
        df['sample_weight'] = TripleBarrierLabeling.compute_sample_weights(
            df['label'],
            df['return']
        )

        df = df.reset_index()

        logger.info("æ ‡ç­¾æ·»åŠ å®Œæˆ âœ“")
        return df


# æµ‹è¯•ä»£ç 
if __name__ == '__main__':
    # åˆ›å»ºæµ‹è¯•æ•°æ®
    np.random.seed(42)
    dates = pd.date_range('2023-01-01', '2024-01-01', freq='D')

    # æ¨¡æ‹Ÿä»·æ ¼åºåˆ— (å¸¦è¶‹åŠ¿å’Œå™ªéŸ³)
    trend = np.linspace(100, 120, len(dates))
    noise = np.random.randn(len(dates)) * 2
    prices = pd.Series(trend + noise, index=dates)

    print("æµ‹è¯• Triple Barrier Labeling...")
    print("=" * 60)

    # åº”ç”¨ä¸‰é‡å£å’
    labels_df = TripleBarrierLabeling.apply_triple_barrier(
        prices,
        upper_barrier=0.03,
        lower_barrier=-0.02,
        max_holding_period=5,
        stop_loss=-0.01
    )

    print("\næ ‡ç­¾ç»“æœ:")
    print(labels_df.head(10))

    print("\næ ‡ç­¾ç»Ÿè®¡:")
    print(labels_df['label'].value_counts())
    print(f"\nå¹³å‡æŒæœ‰æœŸ: {labels_df['holding_period'].mean():.2f} å¤©")

    print("\nè§¦å‘ç±»å‹ç»Ÿè®¡:")
    print(labels_df['barrier_touched'].value_counts())

    print("\næ”¶ç›Šç‡ç»Ÿè®¡:")
    print(labels_df['return'].describe())

    # æµ‹è¯•æ·»åŠ åˆ° DataFrame
    test_df = pd.DataFrame({
        'date': dates,
        'close': prices.values,
        'volume': np.random.randint(1000000, 10000000, len(dates)),
    })

    test_df = TripleBarrierLabeling.add_labels_to_dataframe(
        test_df,
        upper_barrier=0.03,
        lower_barrier=-0.02,
        max_holding_period=5
    )

    print("\næ·»åŠ æ ‡ç­¾åçš„ DataFrame:")
    print(test_df[['date', 'close', 'label', 'barrier_touched', 'holding_period', 'sample_weight']].head(10))

    print("\n" + "=" * 60)
    print("Triple Barrier Labeling æµ‹è¯•å®Œæˆ!")

```

## nexus_with_proxy.py

```python
#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
Notion Nexus - æ”¯æŒ API ä¸­è½¬çš„ç‰ˆæœ¬
æ”¯æŒå¤šç§ API ä¸­è½¬æ–¹æ¡ˆ
"""

import os
import sys
import time
import textwrap
import requests
from dotenv import load_dotenv
from src.utils.path_utils import get_project_root

# åŠ è½½ç¯å¢ƒå˜é‡
load_dotenv()
NOTION_TOKEN = os.getenv("NOTION_TOKEN")
GEMINI_KEY = os.getenv("GEMINI_API_KEY")
PROXY_API_KEY = os.getenv("PROXY_API_KEY")
PROXY_API_URL = os.getenv("PROXY_API_URL")
DATABASE_ID = os.getenv("NOTION_DB_ID")
PROJECT_ROOT = str(get_project_root())

# Notion API é…ç½®
NOTION_VERSION = "2022-06-28"
NOTION_BASE_URL = "https://api.notion.com/v1"

def notion_headers():
    """è·å– Notion API è¯·æ±‚å¤´"""
    return {
        "Authorization": f"Bearer {NOTION_TOKEN}",
        "Content-Type": "application/json",
        "Notion-Version": NOTION_VERSION
    }

def call_gemini_direct(prompt):
    """ç›´æ¥è°ƒç”¨ Google Gemini API"""
    try:
        # ä½¿ç”¨ç¨³å®šç‰ˆæœ¬ gemini-1.5-flash (ä¿®æ­£ï¼šgemini-2.5-flash ä¸å­˜åœ¨)
        # å‚è€ƒ Gemini Pro å®¡æŸ¥å»ºè®®ï¼šéªŒè¯æ­£ç¡®çš„APIæ¨¡å‹åç§°
        url = f"https://generativelanguage.googleapis.com/v1beta/models/gemini-1.5-flash:generateContent?key={GEMINI_KEY}"

        data = {
            "contents": [{
                "parts": [{
                    "text": prompt
                }]
            }]
        }

        response = requests.post(url, json=data, timeout=30)

        if response.status_code == 200:
            result = response.json()
            if "candidates" in result and result["candidates"]:
                return result["candidates"][0]["content"]["parts"][0]["text"]
            else:
                return "âŒ Gemini è¿”å›ç©ºå“åº”"
        else:
            return f"âŒ Gemini API Error: {response.status_code} - {response.text}"

    except Exception as e:
        return f"âŒ è°ƒç”¨ Gemini æ—¶å‡ºé”™: {e}"

def call_gemini_proxy_1(prompt):
    """ä½¿ç”¨ä¸­è½¬æœåŠ¡ 1 - Gemini Proxy"""
    try:
        url = "https://api.aiproxy.io/v1/chat/completions"

        headers = {
            "Authorization": f"Bearer {PROXY_API_KEY}",
            "Content-Type": "application/json"
        }

        data = {
            "model": "gemini-2.0-flash-exp",
            "messages": [
                {
                    "role": "system",
                    "content": "ä½ æ˜¯ä¸€ä½èµ„æ·±çš„é‡åŒ–å¼€å‘åŠ©æ‰‹ï¼Œè¯·æä¾›ä¸“ä¸šçš„æŠ€æœ¯åˆ†æå’Œå»ºè®®ã€‚"
                },
                {
                    "role": "user",
                    "content": prompt
                }
            ],
            "temperature": 0.7,
            "max_tokens": 4000
        }

        response = requests.post(url, headers=headers, json=data, timeout=30)

        if response.status_code == 200:
            result = response.json()
            if "choices" in result and result["choices"]:
                return result["choices"][0]["message"]["content"]
            else:
                return "âŒ ä¸­è½¬æœåŠ¡è¿”å›ç©ºå“åº”"
        else:
            return f"âŒ ä¸­è½¬æœåŠ¡ Error: {response.status_code} - {response.text}"

    except Exception as e:
        return f"âŒ è°ƒç”¨ä¸­è½¬æœåŠ¡æ—¶å‡ºé”™: {e}"

def call_gemini_proxy_2(prompt):
    """ä½¿ç”¨ä¸­è½¬æœåŠ¡ 2 - å›ºå®šä½¿ç”¨ Gemini 3 Pro Preview"""
    try:
        url = f"{PROXY_API_URL}/v1/chat/completions"

        headers = {
            'Accept': 'application/json',
            'Authorization': f'Bearer {PROXY_API_KEY}',
            'Content-Type': 'application/json'
        }

        data = {
            "model": "gemini-3-pro-preview",  # å›ºå®šä½¿ç”¨ Gemini 3 Pro Preview (å®æµ‹å¯ç”¨)
            "messages": [
                {
                    "role": "system",
                    "content": "ä½ æ˜¯ä¸€ä½èµ„æ·±çš„é‡åŒ–å¼€å‘åŠ©æ‰‹ï¼Œè¯·æä¾›ä¸“ä¸šçš„æŠ€æœ¯åˆ†æå’Œå»ºè®®ã€‚"
                },
                {
                    "role": "user",
                    "content": prompt
                }
            ],
            "temperature": 0.7,
            "max_tokens": 4000
        }

        print(f"   -> ä½¿ç”¨æ¨¡å‹: gemini-3-pro-preview (Gemini 3 Pro)")
        response = requests.post(url, headers=headers, json=data, timeout=60)

        if response.status_code == 200:
            result = response.json()
            if "choices" in result and result["choices"]:
                return result["choices"][0]["message"]["content"]
            else:
                return "âŒ ä¸­è½¬æœåŠ¡è¿”å›ç©ºå“åº”"
        else:
            return f"âŒ ä¸­è½¬æœåŠ¡ Error: {response.status_code} - {response.text}"

    except Exception as e:
        return f"âŒ è°ƒç”¨ Gemini 3 Pro æ—¶å‡ºé”™: {e}"

def call_gemini_api(prompt):
    """æ™ºèƒ½é€‰æ‹© Gemini API è°ƒç”¨æ–¹å¼"""
    print("   -> ğŸ”„ é€‰æ‹© API æœåŠ¡...")

    # ä¼˜å…ˆä½¿ç”¨é…ç½®çš„ä¸­è½¬æœåŠ¡
    if PROXY_API_URL and PROXY_API_KEY and not PROXY_API_KEY.startswith("your_"):
        print("   -> ğŸ“¡ ä½¿ç”¨è´­ä¹°çš„ä¸­è½¬æœåŠ¡...")
        result = call_gemini_proxy_2(prompt)
        if not result.startswith("âŒ"):
            print("   -> âœ… ä¸­è½¬æœåŠ¡æˆåŠŸ")
            return result
        else:
            print(f"   -> âš ï¸ ä¸­è½¬æœåŠ¡å¤±è´¥: {result}")

    # å¤‡é€‰ï¼šå°è¯•å…¶ä»–ä¸­è½¬æœåŠ¡
    if PROXY_API_KEY and not PROXY_API_KEY.startswith("your_"):
        print("   -> ğŸ“¡ å°è¯•å¤‡ç”¨ä¸­è½¬æœåŠ¡...")
        result = call_gemini_proxy_1(prompt)
        if not result.startswith("âŒ"):
            print("   -> âœ… å¤‡ç”¨ä¸­è½¬æˆåŠŸ")
            return result
        else:
            print(f"   -> âš ï¸ å¤‡ç”¨ä¸­è½¬å¤±è´¥: {result}")

    # æœ€åå°è¯•ç›´æ¥ API
    print("   -> ğŸ”— å°è¯•ç›´æ¥ API...")
    result = call_gemini_direct(prompt)
    if result.startswith("âŒ"):
        print(f"   -> âŒ æ‰€æœ‰ API éƒ½å¤±è´¥äº†")
    else:
        print("   -> âœ… ç›´æ¥ API æˆåŠŸ")

    return result

def read_local_file(filepath):
    """è¯»å–æœ¬åœ°æ–‡ä»¶å†…å®¹"""
    safe_path = os.path.normpath(os.path.join(PROJECT_ROOT, filepath.strip()))
    if not safe_path.startswith(PROJECT_ROOT):
        return f"\n[Security Alert: Access denied to {filepath}]\n"

    if os.path.exists(safe_path):
        try:
            with open(safe_path, 'r', encoding='utf-8') as f:
                content = f.read()
                if len(content) > 5000:
                    content = content[:5000] + "\n... [æ–‡ä»¶è¿‡é•¿å·²æˆªæ–­]"
                return f"\n\n--- FILE: {filepath} ---\n{content}\n--- END FILE ---\n"
        except Exception as e:
            return f"\n[Error reading file: {e}]\n"
    return f"\n[WARNING: File not found: {filepath}]\n"

def add_response_to_page(page_id, response_text):
    """å°†å›å¤æ·»åŠ åˆ°é¡µé¢"""
    try:
        chunks = textwrap.wrap(response_text, width=1800, replace_whitespace=False)

        children = [
            {
                "object": "block",
                "type": "heading_2",
                "heading_2": {
                    "rich_text": [{"text": {"content": "ğŸ¤– AI Response (via Proxy)"}}]
                }
            },
            {
                "object": "block",
                "type": "divider",
                "divider": {}
            }
        ]

        for chunk in chunks:
            children.append({
                "object": "block",
                "type": "paragraph",
                "paragraph": {
                    "rich_text": [{"text": {"content": chunk}}]
                }
            })

        url = f"{NOTION_BASE_URL}/blocks/{page_id}/children"
        response = requests.patch(url, headers=notion_headers(), json={"children": children})

        if response.status_code != 200:
            print(f"âš ï¸ æ·»åŠ å›å¤å¤±è´¥: {response.status_code}")
            return False

        return True

    except Exception as e:
        print(f"âš ï¸ æ·»åŠ å›å¤æ—¶å‡ºé”™: {e}")
        return False

def process_page(page):
    """å¤„ç†å•ä¸ªé¡µé¢"""
    page_id = page["id"]
    props = page["properties"]

    # è·å–æ ‡é¢˜
    title = "Untitled Task"
    for field_name in ["åç§°", "Topic", "Title", "Name"]:
        if field_name in props and props[field_name].get("title"):
            title = props[field_name]["title"][0]["plain_text"]
            break

    print(f"ğŸš€ å¤„ç†ä»»åŠ¡: {title}")

    # æ£€æŸ¥æ˜¯å¦å·²ç»æœ‰å›å¤
    if page.get("has_children"):
        print("   -> é¡µé¢å·²æœ‰å†…å®¹ï¼Œè·³è¿‡å¤„ç†")
        return

    # æ™ºèƒ½æ–‡ä»¶å…³è”
    context_str = ""
    if "é£é™©ç®¡ç†" in title or "risk" in title.lower():
        files_to_read = ["src/strategy/risk_manager.py", "docs/BACKTEST_GUIDE.md"]
    elif "ç‰¹å¾å·¥ç¨‹" in title or "feature" in title.lower():
        files_to_read = ["src/feature_engineering/", "docs/ML_GUIDE.md"]
    elif "å›æµ‹" in title or "backtest" in title.lower():
        files_to_read = ["bin/run_backtest.py", "src/reporting/"]
    elif "ä»£ç " in title or "code" in title.lower():
        files_to_read = ["src/"]
    else:
        files_to_read = []

    for filepath in files_to_read:
        print(f"   -> è¯»å–æ–‡ä»¶: {filepath}")
        context_str += read_local_file(filepath)

    # æ„å»ºæç¤º
    full_prompt = f"""ä½ æ˜¯ä¸€ä½èµ„æ·±çš„é‡åŒ–å¼€å‘åŠ©æ‰‹ã€‚ç”¨æˆ·æå‡ºäº†ä»¥ä¸‹é—®é¢˜æˆ–ä»»åŠ¡ï¼š

ä»»åŠ¡æ ‡é¢˜: {title}

ç›¸å…³ä»£ç ä¸Šä¸‹æ–‡:
{context_str}

è¯·æ ¹æ®ä»»åŠ¡æ ‡é¢˜å’Œä¸Šä¸‹æ–‡ï¼Œæä¾›ä¸“ä¸šçš„æŠ€æœ¯å›ç­”ã€‚å¦‚æœæ¶‰åŠä»£ç åˆ†æï¼Œè¯·æä¾›å…·ä½“çš„å»ºè®®å’Œæ”¹è¿›æ–¹æ¡ˆã€‚è¯·ç”¨ä¸­æ–‡å›ç­”ï¼Œæ ¼å¼ä½¿ç”¨ Markdownã€‚"""

    # è°ƒç”¨ AI
    print("   -> ğŸ§  AI æ€è€ƒä¸­...")
    reply_text = call_gemini_api(full_prompt)

    if "âŒ" in reply_text:
        print(f"   -> {reply_text}")

        # å¦‚æœæ‰€æœ‰ API éƒ½å¤±è´¥ï¼Œæ·»åŠ ä¸€ä¸ªå¤‡ç”¨å›å¤
        fallback_response = f"""# ğŸ¤– AI åˆ†æç»“æœ

## ä»»åŠ¡ï¼š{title}

å¾ˆæŠ±æ­‰ï¼ŒAI æœåŠ¡æš‚æ—¶ä¸å¯ç”¨ã€‚ä½†æ ¹æ®ä»»åŠ¡æ ‡é¢˜ï¼Œæˆ‘å¯ä»¥æä¾›ä»¥ä¸‹åŸºç¡€åˆ†æï¼š

## å»ºè®®çš„åˆ†ææ–¹å‘ï¼š

### 1. ä»£ç è´¨é‡æ£€æŸ¥
- æ£€æŸ¥é”™è¯¯å¤„ç†æœºåˆ¶
- åˆ†ææ€§èƒ½ç“¶é¢ˆ
- å®¡æŸ¥ä»£ç ç»“æ„

### 2. åŠŸèƒ½åˆ†æ
- éªŒè¯ä¸šåŠ¡é€»è¾‘æ­£ç¡®æ€§
- æ£€æŸ¥è¾¹ç•Œæ¡ä»¶å¤„ç†
- è¯„ä¼°å¯ç»´æŠ¤æ€§

### 3. ä¼˜åŒ–å»ºè®®
- æå‡ä»£ç å¯è¯»æ€§
- ä¼˜åŒ–ç®—æ³•æ•ˆç‡
- å¢å¼ºé”™è¯¯å¤„ç†

### 4. æ‰‹åŠ¨æ£€æŸ¥æ–‡ä»¶
è¯·æ£€æŸ¥ä»¥ä¸‹ç›¸å…³æ–‡ä»¶ï¼š
{chr(10).join([f"- {file}" for file in files_to_read])}

---
*ç³»ç»Ÿå°†åœ¨ API æœåŠ¡æ¢å¤åæä¾›å®Œæ•´çš„ AI åˆ†æç»“æœã€‚*"""

        print("   -> ğŸ“ å†™å…¥å¤‡ç”¨å›å¤...")
        add_response_to_page(page_id, fallback_response)
        print("âœ… å¤„ç†å®Œæˆï¼ˆå¤‡ç”¨å›å¤ï¼‰")
        return

    # å†™å…¥å›å¤
    print("   -> ğŸ“ å†™å…¥å›å¤...")
    if add_response_to_page(page_id, reply_text):
        print("âœ… å¤„ç†å®Œæˆ")
    else:
        print("âŒ å†™å…¥å¤±è´¥")

def monitor_database():
    """ç›‘æ§æ•°æ®åº“å¹¶å¤„ç†æ–°é¡µé¢"""
    print(f"ğŸ‘€ æ­£åœ¨ç›‘æ§ Notion æ•°æ®åº“...")
    print("æ£€æµ‹åˆ°æ–°é¡µé¢æ—¶ä¼šè‡ªåŠ¨è°ƒç”¨ AI å¤„ç†")
    print("æ”¯æŒå¤šç§ API ä¸­è½¬æ–¹æ¡ˆ")
    print("æŒ‰ Ctrl+C åœæ­¢ç›‘æ§\n")

    processed_pages = set()

    while True:
        try:
            url = f"{NOTION_BASE_URL}/databases/{DATABASE_ID}/query"
            response = requests.post(url, headers=notion_headers(), json={})

            if response.status_code == 200:
                query_result = response.json()
                pages = query_result.get("results", [])

                new_pages = [page for page in pages if page["id"] not in processed_pages]

                if new_pages:
                    print(f"å‘ç° {len(new_pages)} ä¸ªæ–°é¡µé¢")
                    for page in new_pages:
                        process_page(page)
                        processed_pages.add(page["id"])
                        print("-" * 40)
                else:
                    sys.stdout.write(".")
                    sys.stdout.flush()

        except KeyboardInterrupt:
            print("\nğŸ‘‹ ç›‘æ§å·²åœæ­¢")
            break
        except Exception as e:
            print(f"\nâš ï¸ ç›‘æ§é”™è¯¯: {e}")

        time.sleep(5)

def main():
    """ä¸»å‡½æ•°"""
    print("=" * 60)
    print("ğŸš€ Notion Nexus - API ä¸­è½¬ç‰ˆ")
    print("=" * 60)

    # æ˜¾ç¤ºå½“å‰é…ç½®
    print("ğŸ“‹ å½“å‰é…ç½®:")
    print(f"   Notion Token: {'âœ… å·²é…ç½®' if NOTION_TOKEN else 'âŒ æœªé…ç½®'}")
    print(f"   Gemini Key: {'âœ… å·²é…ç½®' if GEMINI_KEY else 'âŒ æœªé…ç½®'}")
    print(f"   ä»£ç† API Key: {'âœ… å·²é…ç½®' if PROXY_API_KEY and not PROXY_API_KEY.startswith('your_') else 'âŒ æœªé…ç½®'}")
    print(f"   ä»£ç† API URL: {'âœ… å·²é…ç½®' if PROXY_API_URL else 'âŒ æœªé…ç½®'}")

    if not DATABASE_ID:
        print("âŒ NOTION_DB_ID æœªé…ç½®")
        return

    print(f"\nğŸ”„ API è°ƒç”¨ç­–ç•¥:")
    print("   1. å°è¯•ä¸­è½¬æœåŠ¡ (å¦‚æœé…ç½®äº†ä»£ç†)")
    print("   2. å°è¯•è‡ªå®šä¹‰ä¸­è½¬ (å¦‚æœé…ç½®äº†URL)")
    print("   3. å°è¯•ç›´æ¥ Gemini API")
    print("   4. å¦‚æœéƒ½å¤±è´¥ï¼Œæä¾›åŸºç¡€åˆ†æ")

    # æµ‹è¯•è¿æ¥
    print(f"\nğŸ”§ æµ‹è¯•è¿æ¥...")
    try:
        url = f"{NOTION_BASE_URL}/databases/{DATABASE_ID}"
        response = requests.get(url, headers=notion_headers())

        if response.status_code == 200:
            print("âœ… Notion è¿æ¥æˆåŠŸï¼")
            db_info = response.json()
            print(f"ğŸ“Š æ•°æ®åº“: {db_info.get('title', [{}])[0].get('plain_text', 'Unknown')}")

            print("\nğŸ“ ä½¿ç”¨è¯´æ˜:")
            print("1. åœ¨ Notion æ•°æ®åº“ä¸­åˆ›å»ºæ–°é¡µé¢")
            print("2. è®¾ç½®é¡µé¢æ ‡é¢˜ï¼Œç³»ç»Ÿä¼šè‡ªåŠ¨å¤„ç†")
            print("3. æ”¯æŒå¤šç§ API ä¸­è½¬æ–¹æ¡ˆ")
            print("4. å¦‚æœ API ä¸å¯ç”¨ï¼Œä¼šæä¾›åŸºç¡€åˆ†æ")
            print("\nå¼€å§‹ç›‘æ§...\n")

            monitor_database()
        else:
            print(f"âŒ æ— æ³•è®¿é—®æ•°æ®åº“: {response.status_code}")

    except Exception as e:
        print(f"âŒ è¿æ¥æµ‹è¯•å¤±è´¥: {e}")

if __name__ == "__main__":
    main()
```

## gemini_review_bridge.py

```python
#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
Gemini Review Bridge v3.3 (Insightful Edition)
æ¶æ„ç›®æ ‡: 
1. ç©¿é€ Cloudflare (Titanium Shield).
2. ç²¾å‡†æå– JSON ç”¨äºæ§åˆ¶è„šæœ¬æµç¨‹ (Pass/Fail).
3. ä¿ç•™å¹¶å±•ç¤º AI çš„æ¶æ„ç‚¹è¯„ï¼Œä¾› Claude å­¦ä¹ æ”¹è¿›.
"""
import os
import sys
import subprocess
import json
import datetime
import re
from dotenv import load_dotenv

# --- æ ¸å¿ƒé…ç½® ---
AUDIT_SCRIPT = "scripts/audit_current_task.py"
ENABLE_AI_REVIEW = True # å¼€å¯äº‘ç«¯å¤§è„‘

# --- å°è¯•å¯¼å…¥æ ¸æ­¦å™¨ (curl_cffi) ---
try:
    from curl_cffi import requests
    CURL_AVAILABLE = True
except ImportError:
    CURL_AVAILABLE = False
    print("âš ï¸  [WARN] ç¼ºå°‘ curl_cffiï¼Œå»ºè®®è¿è¡Œ: pip install curl_cffi")

load_dotenv()
GEMINI_API_KEY = os.getenv("GEMINI_API_KEY")
GEMINI_BASE_URL = os.getenv("GEMINI_BASE_URL", "https://api.yyds168.net/v1")
GEMINI_MODEL = os.getenv("GEMINI_MODEL", "gemini-pro")

# --- UI é¢œè‰²é…ç½® ---
GREEN = "\033[92m"
RED = "\033[91m"
YELLOW = "\033[93m"
CYAN = "\033[96m"
BLUE = "\033[94m"  # AI ç‚¹è¯„ä¸“ç”¨è‰²
RESET = "\033[0m"

def log(msg, level="INFO"):
    timestamp = datetime.datetime.now().strftime("%H:%M:%S")
    colors = {"SUCCESS": GREEN, "ERROR": RED, "WARN": YELLOW, "PHASE": CYAN, "INFO": RESET}
    prefix = {'SUCCESS': 'âœ… ', 'ERROR': 'â›” ', 'WARN': 'âš ï¸  ', 'PHASE': 'ğŸ”¹ '}.get(level, '')
    print(f"[{timestamp}] {colors.get(level, RESET)}{prefix}{msg}{RESET}")

def run_cmd(cmd, shell=True):
    try:
        result = subprocess.run(cmd, shell=shell, stdout=subprocess.PIPE, stderr=subprocess.PIPE, text=True)
        return result.returncode, result.stdout.strip(), result.stderr.strip()
    except Exception as e:
        return 1, "", str(e)

def extract_json_and_comments(text):
    """
    æ™ºèƒ½åˆ†ç¦»å™¨ï¼šä» AI çš„å›å¤ä¸­æ‹†åˆ†å‡º JSON (ç»™æœºå™¨çœ‹) å’Œ ç‚¹è¯„ (ç»™ Claude çœ‹)
    è¿”å›: (json_obj, comment_text)
    """
    json_obj = None
    comment_text = ""

    # 1. ä½¿ç”¨æ ˆå¹³è¡¡æ³•å¯»æ‰¾ç¬¬ä¸€ä¸ªå®Œæ•´çš„ JSON å¯¹è±¡ {...}
    stack = 0
    start_index = -1
    end_index = -1
    
    for i, char in enumerate(text):
        if char == '{':
            if stack == 0: start_index = i
            stack += 1
        elif char == '}':
            stack -= 1
            if stack == 0 and start_index != -1:
                end_index = i + 1
                # å°è¯•è§£ææ‰¾åˆ°çš„è¿™ä¸€æ®µ
                try:
                    candidate = text[start_index : end_index]
                    json_obj = json.loads(candidate)
                    # æå–æˆåŠŸï¼å‰©ä¸‹çš„å…¨æ˜¯è¯„è®º
                    if end_index < len(text):
                        comment_text = text[end_index:].strip()
                    return json_obj, comment_text
                except:
                    continue # è§£æå¤±è´¥ï¼Œå¯èƒ½æ˜¯ä¸ªå‡æ‹¬å·ï¼Œç»§ç»­æ‰¾
    
    # 2. å…œåº•ï¼šå¦‚æœæ²¡æ‰¾åˆ°å¤æ‚çš„ï¼Œå°è¯•æŠŠæ•´æ®µå½“ JSON
    if not json_obj:
        try:
            json_obj = json.loads(text)
        except:
            pass
            
    return json_obj, comment_text

# ==============================================================================
# ğŸ§  Phase 1: æœ¬åœ°å®¡è®¡ (ç¡¬æ€§é—¨æ§›)
# ==============================================================================
def phase_local_audit():
    if not os.path.exists(AUDIT_SCRIPT):
        log(f"æœªæ‰¾åˆ°æœ¬åœ°å®¡è®¡è„šæœ¬ï¼Œè·³è¿‡ã€‚", "WARN")
        return True
    
    log(f"æ‰§è¡Œæœ¬åœ°å®¡è®¡: {AUDIT_SCRIPT}", "INFO")
    code, out, err = run_cmd(f"python3 {AUDIT_SCRIPT}")
    
    if code == 0:
        log("æœ¬åœ°å®¡è®¡é€šè¿‡ã€‚", "SUCCESS")
        return True
    else:
        log("æœ¬åœ°å®¡è®¡å¤±è´¥ï¼é˜»æ­¢æäº¤ã€‚", "ERROR")
        print(f"{YELLOW}--- AUDIT LOG ---\n{out}\n{err}{RESET}")
        return False

# ==============================================================================
# ğŸ§  Phase 2: å¤–éƒ¨ AI æ·±åº¦å®¡æŸ¥ (æ ¸å¿ƒé€»è¾‘)
# ==============================================================================
def external_ai_review(diff_content):
    if not CURL_AVAILABLE or not GEMINI_API_KEY:
        log("è·³è¿‡ AI å®¡æŸ¥ (ç¼ºå°‘é…ç½®æˆ–ä¾èµ–)", "WARN")
        return None

    log("å¯åŠ¨ curl_cffi å¼•æ“ï¼Œè¯·æ±‚æ¶æ„å¸ˆå®¡æŸ¥...", "PHASE")
    
    # Prompt: æ˜ç¡®è¦æ±‚ JSON åœ¨å‰ï¼Œè¯„è®ºåœ¨å
    prompt = f"""
    ä½ æ˜¯ä¸€ä½ä¸¥å‰çš„ Python æ¶æ„å¸ˆã€‚è¯·å®¡æŸ¥ä»¥ä¸‹ Git Diff:
    {diff_content[:15000]}
    
    **è¾“å‡ºæ ¼å¼è¦æ±‚ (ä¸¥æ ¼éµå®ˆ)**:
    1. ç¬¬ä¸€éƒ¨åˆ†ï¼šå¿…é¡»æ˜¯ä¸€ä¸ªæ ‡å‡†çš„ JSON å¯¹è±¡ã€‚
    2. ç¬¬äºŒéƒ¨åˆ†ï¼ˆå¯é€‰ï¼‰ï¼šJSON ç»“æŸåï¼Œä½ å¯ä»¥ç”¨ Markdown å†™å‡ºè¯¦ç»†çš„æ”¹è¿›å»ºè®®ã€é£é™©è­¦å‘Šæˆ–é‡æ„æ€è·¯ã€‚
    
    JSON ç»“æ„ï¼š
    {{
        "status": "PASS" | "FAIL",
        "reason": "ä¸€å¥è¯æ€»ç»“",
        "commit_message_suggestion": "feat(scope): ..."
    }}
    """
    
    try:
        resp = requests.post(
            f"{GEMINI_BASE_URL}/chat/completions",
            headers={"Authorization": f"Bearer {GEMINI_API_KEY}", "Content-Type": "application/json"},
            json={
                "model": GEMINI_MODEL,
                "messages": [{"role": "user", "content": prompt}],
                "temperature": 0.3 
            },
            timeout=60,
            impersonate="chrome110" 
        )
        
        if resp.status_code == 200:
            content = resp.json()['choices'][0]['message']['content']
            
            # ä½¿ç”¨åˆ†ç¦»å™¨å¤„ç†
            result, comments = extract_json_and_comments(content)
            
            if result:
                status = result.get("status", "FAIL")
                
                # --- ğŸ”¥ å…³é”®ï¼šå±•ç¤º AI çš„â€œè¯ç—¨â€éƒ¨åˆ†ç»™ Claude çœ‹ ---
                if comments:
                    print(f"\n{BLUE}================ ğŸ§  æ¶æ„å¸ˆç‚¹è¯„ (AI Feedback) ================{RESET}")
                    print(f"{CYAN}{comments}{RESET}")
                    print(f"{BLUE}============================================================={RESET}\n")
                else:
                    print(f"\n{BLUE}â„¹ï¸  æ¶æ„å¸ˆæ²¡æœ‰æä¾›é¢å¤–è¯„è®ºã€‚{RESET}\n")
                # ----------------------------------------------------

                if status == "PASS":
                    log(f"AI å®¡æŸ¥é€šè¿‡: {result.get('reason')}", "SUCCESS")
                    return result.get("commit_message_suggestion")
                else:
                    log(f"AI æ‹’ç»æäº¤: {result.get('reason')}", "ERROR")
                    return "FAIL" 
            else:
                log("æ— æ³•è§£æ AI å“åº”æ ¼å¼ï¼Œé™çº§é€šè¿‡ã€‚", "WARN")
                return None
        else:
            log(f"API è¯·æ±‚å¤±è´¥: {resp.status_code}", "ERROR")
            return None

    except requests.ConnectTimeout:
        log(f"è¿æ¥è¶…æ—¶: æ— æ³•è¿æ¥APIæœåŠ¡å™¨ (timeout=60s)", "ERROR")
        log(f"è¯·æ£€æŸ¥ç½‘ç»œè¿æ¥å’ŒAPIåœ°å€: {GEMINI_BASE_URL}", "ERROR")
        return None

    except requests.ReadTimeout:
        log(f"è¯»å–è¶…æ—¶: APIæœåŠ¡å™¨å“åº”è¿‡æ…¢ (timeout=60s)", "ERROR")
        log(f"è¯·æ£€æŸ¥ç½‘ç»œè¿æ¥æˆ–ç¨åé‡è¯•", "ERROR")
        return None

    except requests.RequestException as e:
        log(f"ç½‘ç»œé”™è¯¯: {e}", "ERROR")
        log(f"APIåœ°å€: {GEMINI_BASE_URL}", "ERROR")
        log(f"è¯·æ£€æŸ¥ç½‘ç»œè¿æ¥å¹¶é‡è¯•", "ERROR")
        return None

    except Exception as e:
        log(f"AIå®¡æŸ¥å¤±è´¥: {e}", "ERROR")
        import traceback
        traceback.print_exc()
        return None

# ==============================================================================
# ğŸš€ ä¸»æµç¨‹
# ==============================================================================
def main():
    print(f"{CYAN}ğŸ›¡ï¸ Gemini Review Bridge v3.3 (Insightful Edition){RESET}")
    
    # 0. è‡ªåŠ¨æš‚å­˜
    run_cmd("git add .")
    _, diff, _ = run_cmd("git diff --cached")
    
    if not diff:
        log("å·¥ä½œåŒºå¹²å‡€ï¼Œæ— ä»£ç å˜æ›´ã€‚", "WARN")
        sys.exit(0)

    # 1. æœ¬åœ°å®¡è®¡ (Claude è‡ªæµ‹)
    if not phase_local_audit():
        sys.exit(1)

    # 2. å¤–éƒ¨ AI å®¡æŸ¥ (æ¶æ„å¸ˆæŠŠå…³)
    ai_commit_msg = None
    if ENABLE_AI_REVIEW:
        log("=" * 80, "INFO")
        log("å¯åŠ¨å¤–éƒ¨AIå®¡æŸ¥...", "PHASE")
        log("=" * 80, "INFO")
        print()

        review_result = external_ai_review(diff)

        if review_result == "FAIL":
            print()
            print(f"{RED}{'=' * 80}{RESET}")
            log("AIå®¡æŸ¥æ‹’ç»æäº¤", "ERROR")
            print(f"{RED}{'=' * 80}{RESET}")
            log("ä¿®å¤ä¸Šè¿°é—®é¢˜åé‡æ–°è¿è¡Œfinishå‘½ä»¤", "ERROR")
            sys.exit(1)  # AI æ˜ç¡®æ‹’ç»ï¼Œé˜»æ–­æäº¤

        elif review_result is None:
            print()
            print(f"{YELLOW}{'=' * 80}{RESET}")
            log("AIå®¡æŸ¥æœåŠ¡ä¸å¯ç”¨", "WARN")
            print(f"{YELLOW}{'=' * 80}{RESET}")
            log("å¯èƒ½åŸå› :", "WARN")
            log("  - ç½‘ç»œè¿æ¥å¤±è´¥", "WARN")
            log("  - APIå¯†é’¥æ— æ•ˆæˆ–æœªè®¾ç½®", "WARN")
            log("  - APIæœåŠ¡å™¨æ— å“åº”", "WARN")
            print()
            log("å°†ç»§ç»­ä½¿ç”¨æœ¬åœ°æäº¤ä¿¡æ¯", "WARN")
            print(f"{YELLOW}{'=' * 80}{RESET}")
            print()

        ai_commit_msg = review_result

    # 3. å†³å®šæäº¤ä¿¡æ¯
    if ai_commit_msg:
        commit_msg = ai_commit_msg
    else:
        # é™çº§æˆ– AI æ•…éšœæ—¶çš„é»˜è®¤ä¿¡æ¯
        _, files, _ = run_cmd("git diff --cached --name-only")
        cnt = len([f for f in files.splitlines() if f])
        commit_msg = f"feat(auto): update {cnt} files (local audit passed)"

    # 4. æ‰§è¡Œæäº¤
    log(f"æ‰§è¡Œæäº¤: {commit_msg}", "INFO")
    code, out, err = run_cmd(f'git commit -m "{commit_msg}"')
    
    if code == 0:
        log("ä»£ç å·²æˆåŠŸæäº¤ï¼", "SUCCESS")
        sys.exit(0)
    else:
        log(f"æäº¤å¤±è´¥: {err}", "ERROR")
        sys.exit(1)

if __name__ == "__main__":
    main()

```


---

**å¯¼å‡ºç»Ÿè®¡**: 6/7 ä¸ªæ–‡ä»¶

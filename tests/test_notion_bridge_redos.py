"""
æµ‹è¯• Notion Bridge ReDoS é˜²æŠ¤æœºåˆ¶ (Protocol v4.4 ä¼˜åŒ– 1)

è¦†ç›–èŒƒå›´:
  1. validate_regex_safety() å‡½æ•°æµ‹è¯•
  2. extract_report_summary() å››å±‚é˜²æŠ¤æµ‹è¯•
  3. é¢„ç¼–è¯‘æ­£åˆ™æ¨¡å¼éªŒè¯

è¿è¡Œ: pytest tests/test_notion_bridge_redos.py -v
"""

import pytest
import re
import sys
import signal
import tempfile
from pathlib import Path

# æ·»åŠ é¡¹ç›®è·¯å¾„ä»¥å¯¼å…¥ notion_bridge
project_root = Path(__file__).parent.parent
sys.path.insert(0, str(project_root))

from scripts.ops.notion_bridge import (
    validate_regex_safety,
    extract_report_summary,
    TASK_ID_PATTERN,
    TASK_ID_STRICT_PATTERN,
    DANGEROUS_CHARS_PATTERN,
    SUMMARY_PATTERN,
    FileTooLargeError,
    FileException,
    EncodingError,
)


# ============================================================================
# æµ‹è¯• 1: validate_regex_safety() å‡½æ•°
# ============================================================================

class TestValidateRegexSafety:
    """ReDoS é˜²æŠ¤å‡½æ•°æµ‹è¯•"""

    def test_safe_regex_passes(self):
        """âœ… æ­£å¸¸æ­£åˆ™è¡¨è¾¾å¼åº”è¯¥é€šè¿‡éªŒè¯"""
        pattern = re.compile(r'^\d+$')
        assert validate_regex_safety(pattern, '12345') is True

    def test_safe_regex_with_long_input(self):
        """âœ… é•¿è¾“å…¥çš„å®‰å…¨æ­£åˆ™åº”è¯¥é€šè¿‡"""
        pattern = re.compile(r'^[a-z]+$')
        long_input = 'a' * 1000
        assert validate_regex_safety(pattern, long_input)

    def test_task_id_pattern_passes(self):
        """âœ… ä»»åŠ¡ ID æ¨¡å¼åº”è¯¥é€šè¿‡"""
        assert validate_regex_safety(TASK_ID_PATTERN, '130.2') is True
        assert validate_regex_safety(TASK_ID_STRICT_PATTERN, '130') is True

    def test_redos_regex_timeout(self):
        """âš ï¸ ç¾éš¾æ€§å›æº¯æ­£åˆ™åº”è¯¥è¶…æ—¶æˆ–å¤„ç†

        (a+)+b æ˜¯ç»å…¸ ReDoS æ­£åˆ™ï¼Œä¼šå¯¼è‡´æŒ‡æ•°çº§å›æº¯ã€‚
        è¾“å…¥ 'aaa...a' (ä¸ä»¥ b ç»“å°¾) ä¼šè§¦å‘æœ€åæƒ…å†µã€‚
        """
        pattern = re.compile(r'(a+)+b')
        # éªŒè¯å‡½æ•°èƒ½å¤Ÿå¤„ç†æ½œåœ¨çš„ ReDoS æ¨¡å¼
        result = validate_regex_safety(pattern, 'a' * 20)
        # ç»“æœåº”è¯¥æ˜¯å¸ƒå°”å€¼ï¼Œä¸åº”è¯¥æŠ›å‡ºå¼‚å¸¸
        assert isinstance(result, bool)

    def test_redos_regex_variations(self):
        """âš ï¸ å…¶ä»– ReDoS æ¨¡å¼ä¹Ÿåº”è¯¥è¶…æ—¶"""
        patterns_to_test = [
            (r'(.*)*b', 'a' * 15),  # è´ªå¿ƒé‡è¯åµŒå¥—
            (r'(a|ab)+c', 'a' * 15),  # é‡å æ›¿ä»£
            (r'(a|a)*b', 'a' * 15),  # é‡å¤æ›¿ä»£
        ]

        for pattern_str, input_str in patterns_to_test:
            pattern = re.compile(pattern_str)
            if hasattr(signal, 'SIGALRM'):
                # éªŒè¯è¿”å›å€¼ï¼ˆå¯èƒ½æ˜¯ True æˆ– Falseï¼Œå–å†³äºæ¨¡å¼å’Œè¾“å…¥ï¼‰
                result = validate_regex_safety(pattern, input_str)
                assert isinstance(result, bool)

    def test_empty_input(self):
        """âœ… ç©ºè¾“å…¥åº”è¯¥å®‰å…¨é€šè¿‡"""
        pattern = re.compile(r'^.*$')
        assert validate_regex_safety(pattern, '') is True

    def test_special_characters_safe(self):
        """âœ… åŒ…å«ç‰¹æ®Šå­—ç¬¦çš„å®‰å…¨æ¨¡å¼åº”è¯¥é€šè¿‡"""
        pattern = re.compile(r'^[a-z0-9._-]+$')
        assert validate_regex_safety(pattern, 'test-123.txt') is True

    def test_unicode_input(self):
        """âœ… Unicode è¾“å…¥åº”è¯¥å®‰å…¨å¤„ç†"""
        pattern = re.compile(r'[\u4e00-\u9fff]+')
        assert validate_regex_safety(pattern, 'ä½ å¥½ä¸–ç•Œ') is True

    def test_multiline_regex(self):
        """âœ… å¤šè¡Œæ­£åˆ™åº”è¯¥å®‰å…¨å¤„ç†"""
        pattern = re.compile(r'^Line: .+$', re.MULTILINE)
        text = "Line: test\nLine: æµ‹è¯•\nLine: Ñ‚ĞµÑÑ‚"
        assert validate_regex_safety(pattern, text) is True

    def test_case_insensitive_regex(self):
        """âœ… ä¸åŒºåˆ†å¤§å°å†™çš„æ­£åˆ™åº”è¯¥é€šè¿‡"""
        pattern = re.compile(r'^[A-Z]+$', re.IGNORECASE)
        assert validate_regex_safety(pattern, 'AbCdEf') is True

    def test_timeout_custom_value(self):
        """âœ… è‡ªå®šä¹‰è¶…æ—¶å€¼åº”è¯¥å·¥ä½œ"""
        pattern = re.compile(r'^\d+$')
        # ä½¿ç”¨è¾ƒé•¿çš„è¶…æ—¶æ—¶é—´
        assert validate_regex_safety(pattern, '12345', timeout=2.0) is True


# ============================================================================
# æµ‹è¯• 2: extract_report_summary() å››å±‚é˜²æŠ¤
# ============================================================================

class TestExtractReportSummaryDefense:
    """æŠ¥å‘Šæ‘˜è¦æå–çš„å››å±‚é˜²æŠ¤æµ‹è¯•"""

    @pytest.fixture
    def temp_file(self):
        """åˆ›å»ºä¸´æ—¶æ–‡ä»¶çš„ fixture"""
        with tempfile.NamedTemporaryFile(mode='w', suffix='.md', delete=False) as f:
            yield Path(f.name)
        # æ¸…ç†
        Path(f.name).unlink(missing_ok=True)

    def test_normal_report_summary(self, temp_file):
        """âœ… ç¬¬ä¸€å±‚: æ­£å¸¸æ–‡ä»¶åº”è¯¥æˆåŠŸæå–"""
        content = """# Task #130.3 æŠ¥å‘Š

## ğŸ“Š æ‰§è¡Œæ‘˜è¦

è¿™æ˜¯ä¸€ä¸ªæ­£å¸¸çš„æ‘˜è¦å†…å®¹ã€‚åŒ…å«äº†ä»»åŠ¡çš„å…³é”®ä¿¡æ¯ã€‚

## è¯¦ç»†ç»“æœ

æ›´å¤šè¯¦ç»†å†…å®¹...
"""
        temp_file.write_text(content, encoding='utf-8')

        summary = extract_report_summary(temp_file)
        assert 'æ‰§è¡Œæ‘˜è¦' not in summary  # æ ‡é¢˜ä¸åº”è¯¥åŒ…å«
        assert 'è¿™æ˜¯ä¸€ä¸ªæ­£å¸¸çš„æ‘˜è¦å†…å®¹' in summary or len(summary) > 0

    def test_small_file_passes_layer_1(self, temp_file):
        """âœ… ç¬¬ä¸€å±‚: å°æ–‡ä»¶ (< 10MB) é€šè¿‡æ£€æŸ¥"""
        content = "x" * 1000  # 1KB
        temp_file.write_text(content, encoding='utf-8')
        file_size = temp_file.stat().st_size

        assert file_size < 10 * 1024 * 1024  # åº”è¯¥å°äº 10MB
        # ä¸ä¼šæŠ›å‡º FileTooLargeError
        result = extract_report_summary(temp_file)
        assert isinstance(result, str)

    def test_file_too_large_layer_1(self, temp_file):
        """âš ï¸ ç¬¬ä¸€å±‚: å¤§äº 10MB çš„æ–‡ä»¶åº”è¯¥è¢«æ‹’ç»"""
        # åˆ›å»ºä¸€ä¸ªå¤§äº 10MB çš„æ–‡ä»¶
        large_content = "x" * (11 * 1024 * 1024)  # 11MB
        temp_file.write_text(large_content, encoding='utf-8')

        with pytest.raises(FileTooLargeError):
            extract_report_summary(temp_file)

    def test_content_truncation_layer_2(self, temp_file):
        """âœ… ç¬¬äºŒå±‚: è¶…è¿‡ 100KB çš„å†…å®¹åº”è¯¥è¢«æˆªæ–­"""
        # åˆ›å»ºä¸€ä¸ªçº¦ 150KB çš„å†…å®¹
        content = """## ğŸ“Š æ‰§è¡Œæ‘˜è¦

""" + ("x" * 150000)  # çº¦ 150KB
        temp_file.write_text(content, encoding='utf-8')

        # ä¸åº”è¯¥æŠ›å‡ºå¼‚å¸¸ï¼Œè€Œæ˜¯æˆªæ–­å†…å®¹
        summary = extract_report_summary(temp_file, max_length=2000)
        assert len(summary) <= 2100  # æœ‰ fallback çš„ 20 å­—ç¬¦ç¼“å†²

    def test_regex_pattern_matching_layer_4(self, temp_file):
        """âœ… ç¬¬å››å±‚: æ­£åˆ™æ¨¡å¼åŒ¹é…åº”è¯¥æå–æ‘˜è¦"""
        content = """# é¡¹ç›®æŠ¥å‘Š

## ğŸ“Š æ‰§è¡Œæ‘˜è¦

ä¸»è¦æˆæœ:
- å®Œæˆäº†ä¸‰é˜¶æ®µä¼˜åŒ–
- æ·»åŠ äº†å®Œæ•´çš„æµ‹è¯•å¥—ä»¶
- é›†æˆäº† CI/CD

## åç»­è®¡åˆ’

ç»§ç»­ä¼˜åŒ–...
"""
        temp_file.write_text(content, encoding='utf-8')

        summary = extract_report_summary(temp_file)
        # æ‘˜è¦åº”è¯¥åŒ…å«æ‰§è¡Œæ‘˜è¦ä¸‹çš„å†…å®¹
        assert len(summary) > 0

    def test_file_not_found(self):
        """âš ï¸ æ–‡ä»¶ä¸å­˜åœ¨åº”è¯¥æŠ›å‡ºå¼‚å¸¸"""
        non_existent = Path('/tmp/non_existent_report_12345.md')

        with pytest.raises(FileException):
            extract_report_summary(non_existent)

    def test_encoding_error(self, temp_file):
        """âš ï¸ ç¼–ç é”™è¯¯åº”è¯¥è¢«æ•è·"""
        # å†™å…¥æ— æ•ˆçš„ UTF-8 å­—èŠ‚
        with open(temp_file, 'wb') as f:
            f.write(b'\xff\xfe invalid utf-8')

        with pytest.raises(EncodingError):
            extract_report_summary(temp_file)

    def test_empty_file(self, temp_file):
        """âœ… ç©ºæ–‡ä»¶åº”è¯¥è¿”å›ç©ºå­—ç¬¦ä¸²"""
        temp_file.write_text("", encoding='utf-8')

        summary = extract_report_summary(temp_file)
        assert summary == "" or len(summary) == 0

    def test_file_with_no_summary_section(self, temp_file):
        """âœ… æ²¡æœ‰æ‰§è¡Œæ‘˜è¦éƒ¨åˆ†çš„æ–‡ä»¶åº”è¯¥è¿”å›å†…å®¹æˆªæ–­"""
        content = "# æŠ¥å‘Š\n\nè¿™æ˜¯ä¸€äº›å†…å®¹ï¼Œä½†æ²¡æœ‰æ‰§è¡Œæ‘˜è¦éƒ¨åˆ†ã€‚"
        temp_file.write_text(content, encoding='utf-8')

        summary = extract_report_summary(temp_file, max_length=2000)
        # åº”è¯¥è¿”å›ä¸€äº›å†…å®¹
        assert isinstance(summary, str)

    def test_multiple_summary_sections(self, temp_file):
        """âœ… å¤šä¸ªæ‰§è¡Œæ‘˜è¦éƒ¨åˆ†åº”è¯¥æå–ç¬¬ä¸€ä¸ª"""
        content = """## ğŸ“Š æ‰§è¡Œæ‘˜è¦

ç¬¬ä¸€ä¸ªæ‘˜è¦å†…å®¹

## å…¶ä»–éƒ¨åˆ†

ä¸­é—´å†…å®¹

## ğŸ“Š æ‰§è¡Œæ‘˜è¦

ç¬¬äºŒä¸ªæ‘˜è¦å†…å®¹ï¼ˆä¸åº”è¯¥è¢«æå–ï¼‰
"""
        temp_file.write_text(content, encoding='utf-8')

        summary = extract_report_summary(temp_file)
        assert 'ç¬¬ä¸€ä¸ªæ‘˜è¦å†…å®¹' in summary


# ============================================================================
# æµ‹è¯• 3: é¢„ç¼–è¯‘æ­£åˆ™æ¨¡å¼éªŒè¯
# ============================================================================

class TestRegexPatterns:
    """é¢„ç¼–è¯‘æ­£åˆ™æ¨¡å¼çš„éªŒè¯å’Œæ€§èƒ½æµ‹è¯•"""

    def test_task_id_pattern_valid(self):
        """âœ… TASK_ID_PATTERN åº”è¯¥åŒ¹é…æœ‰æ•ˆçš„ä»»åŠ¡ ID"""
        valid_ids = [
            '130',
            '130.2',
            '130.2.1',
            '1',
            '999.99',
        ]
        for task_id in valid_ids:
            assert TASK_ID_PATTERN.match(task_id) is not None, f"Failed to match {task_id}"

    def test_task_id_pattern_invalid(self):
        """âš ï¸ TASK_ID_PATTERN åº”è¯¥æ‹’ç»æŸäº›æ— æ•ˆçš„ä»»åŠ¡ ID"""
        # TASK_ID_PATTERN æ˜¯åŸºç¡€æ¨¡å¼ï¼Œå…è®¸ä»»ä½•æ•°å­—å’Œç‚¹çš„ç»„åˆ
        # æ›´ä¸¥æ ¼çš„éªŒè¯åœ¨ TASK_ID_STRICT_PATTERN ä¸­
        invalid_ids = [
            'abc',
            'TASK_130',
            'task-130',
            '../130',
        ]
        for task_id in invalid_ids:
            match = TASK_ID_PATTERN.match(task_id)
            # åŸºç¡€æ¨¡å¼ä¼šæ‹’ç»å¤§å¤šæ•°æ— æ•ˆè¾“å…¥
            if match is not None:
                # å¦‚æœåŒ¹é…ï¼Œåº”è¯¥åªæ˜¯æ•°å­—å’Œç‚¹
                assert task_id.replace('.', '').isdigit() or '.' in task_id

    def test_task_id_strict_pattern_valid(self):
        """âœ… TASK_ID_STRICT_PATTERN åº”è¯¥åŒ¹é…æœ‰æ•ˆçš„ä¸¥æ ¼ä»»åŠ¡ ID"""
        valid_ids = [
            '1',
            '99',
            '999',
            '1.1',
            '999.99',
        ]
        for task_id in valid_ids:
            assert TASK_ID_STRICT_PATTERN.match(task_id) is not None, f"Failed to match {task_id}"

    def test_task_id_strict_pattern_invalid(self):
        """âš ï¸ TASK_ID_STRICT_PATTERN åº”è¯¥æ‹’ç»ä¸ç¬¦åˆä¸¥æ ¼æ ¼å¼çš„ ID"""
        invalid_ids = [
            '',
            '0000',  # è¶…è¿‡ 3 ä½
            '1.2.3',  # è¶…è¿‡ 2 ä½å­ç‰ˆæœ¬å·
            '1.',
            '.1',
        ]
        for task_id in invalid_ids:
            assert TASK_ID_STRICT_PATTERN.match(task_id) is None, f"Unexpectedly matched {task_id}"

    def test_dangerous_chars_pattern_detection(self):
        """âš ï¸ DANGEROUS_CHARS_PATTERN åº”è¯¥æ£€æµ‹å±é™©å­—ç¬¦"""
        dangerous_inputs = [
            'test\x00null',  # ç©ºå­—ç¬¦
            'test\x1bescape',  # è½¬ä¹‰å­—ç¬¦
            'test`backtick',  # åå¼•å·
            'test$dollar',  # ç¾å…ƒç¬¦å·
            'test(paren)',  # åœ†æ‹¬å·
            'test{brace}',  # èŠ±æ‹¬å·
            'test[bracket]',  # æ–¹æ‹¬å·
            'test;semicolon',  # åˆ†å·
            'test&ampersand',  # å’Œç¬¦å·
            'test#hash',  # å“ˆå¸Œ
            'test|pipe',  # ç®¡é“
            'test<less',  # å°äº
            'test>greater',  # å¤§äº
        ]
        for text in dangerous_inputs:
            assert DANGEROUS_CHARS_PATTERN.search(text) is not None, f"Failed to detect in {repr(text)}"

    def test_dangerous_chars_pattern_safe(self):
        """âœ… å®‰å…¨å­—ç¬¦åº”è¯¥ä¸è¢«æ£€æµ‹ä¸ºå±é™©"""
        safe_inputs = [
            'normal_text',
            'test-123.txt',
            'CamelCaseText',
            'ä»»åŠ¡ID-130',
            'file_name_2024',
        ]
        for text in safe_inputs:
            assert DANGEROUS_CHARS_PATTERN.search(text) is None, f"False positive for {repr(text)}"

    def test_summary_pattern_extraction(self):
        """âœ… SUMMARY_PATTERN åº”è¯¥æ­£ç¡®æå–æ‰§è¡Œæ‘˜è¦"""
        text = """# æŠ¥å‘Š

## ğŸ“Š æ‰§è¡Œæ‘˜è¦

æ‘˜è¦å†…å®¹ç¬¬ä¸€è¡Œ
æ‘˜è¦å†…å®¹ç¬¬äºŒè¡Œ

## å…¶ä»–éƒ¨åˆ†

å…¶ä»–å†…å®¹"""

        match = SUMMARY_PATTERN.search(text)
        assert match is not None, "Failed to match summary pattern"
        summary = match.group(1)
        assert 'æ‘˜è¦å†…å®¹ç¬¬ä¸€è¡Œ' in summary
        assert 'æ‘˜è¦å†…å®¹ç¬¬äºŒè¡Œ' in summary
        assert 'å…¶ä»–éƒ¨åˆ†' not in summary  # ä¸åº”è¯¥åŒ…å«åç»­æ ‡é¢˜

    def test_summary_pattern_multiline(self):
        """âœ… SUMMARY_PATTERN åº”è¯¥å¤„ç†å¤šè¡Œæ‘˜è¦"""
        text = """## ğŸ“Š æ‰§è¡Œæ‘˜è¦

è¡Œ 1
è¡Œ 2
è¡Œ 3

## ä¸‹ä¸€ä¸ªéƒ¨åˆ†"""

        match = SUMMARY_PATTERN.search(text)
        assert match is not None
        summary = match.group(1)
        assert 'è¡Œ 1' in summary
        assert 'è¡Œ 3' in summary

    def test_summary_pattern_no_match(self):
        """âœ… æ²¡æœ‰æ‰§è¡Œæ‘˜è¦éƒ¨åˆ†çš„æ–‡æœ¬åº”è¯¥ä¸åŒ¹é…"""
        text = "# æŠ¥å‘Š\n\næ²¡æœ‰æ‰§è¡Œæ‘˜è¦éƒ¨åˆ†çš„å†…å®¹"

        match = SUMMARY_PATTERN.search(text)
        assert match is None

    def test_patterns_are_compiled(self):
        """âœ… æ‰€æœ‰æ¨¡å¼åº”è¯¥æ˜¯é¢„ç¼–è¯‘çš„ re.Pattern å¯¹è±¡"""
        patterns = [
            TASK_ID_PATTERN,
            TASK_ID_STRICT_PATTERN,
            DANGEROUS_CHARS_PATTERN,
            SUMMARY_PATTERN,
        ]
        for pattern in patterns:
            assert isinstance(pattern, type(re.compile(''))), f"{pattern} is not compiled"

    def test_pattern_performance_precompiled(self):
        """âœ… é¢„ç¼–è¯‘æ¨¡å¼åº”è¯¥æ¯”åŠ¨æ€ç¼–è¯‘å¿«æˆ–è‡³å°‘ç›¸å½“"""
        import time

        test_string = '130.2'
        iterations = 5000

        # é¢„ç¼–è¯‘æ€§èƒ½ (å¤šæ¬¡è¿è¡Œå–æœ€å°å€¼)
        precompiled_times = []
        for _ in range(3):
            start = time.perf_counter()
            for _ in range(iterations):
                TASK_ID_STRICT_PATTERN.match(test_string)
            precompiled_times.append(time.perf_counter() - start)
        precompiled_time = min(precompiled_times)

        # åŠ¨æ€ç¼–è¯‘æ€§èƒ½ (å¤šæ¬¡è¿è¡Œå–æœ€å°å€¼)
        dynamic_times = []
        for _ in range(3):
            start = time.perf_counter()
            for _ in range(iterations):
                re.compile(r'^[0-9]{1,3}(?:\.[0-9]{1,2})?$').match(test_string)
            dynamic_times.append(time.perf_counter() - start)
        dynamic_time = min(dynamic_times)

        # é¢„ç¼–è¯‘åº”è¯¥ä¸æ˜¾è‘—æ…¢äºåŠ¨æ€ç¼–è¯‘ (å…è®¸ 20% è¯¯å·®èŒƒå›´)
        assert precompiled_time < dynamic_time * 1.2, \
            f"Precompiled ({precompiled_time}s) significantly slower than dynamic ({dynamic_time}s)"


# ============================================================================
# é›†æˆæµ‹è¯•
# ============================================================================

class TestReDoSProtectionIntegration:
    """ReDoS é˜²æŠ¤çš„ç«¯åˆ°ç«¯é›†æˆæµ‹è¯•"""

    @pytest.fixture
    def temp_report(self):
        """åˆ›å»ºä¸´æ—¶æŠ¥å‘Šæ–‡ä»¶"""
        with tempfile.NamedTemporaryFile(mode='w', suffix='.md', delete=False) as f:
            content = """# Task #130.3 å®ŒæˆæŠ¥å‘Š

## ğŸ“Š æ‰§è¡Œæ‘˜è¦

ä¸‰é˜¶æ®µä¼˜åŒ–å…¨éƒ¨å®Œæˆï¼š
- ReDoS é˜²æŠ¤å¼ºåŒ–
- å¼‚å¸¸åˆ†ç±»ç»†åŒ–
- å¾®ä¼˜åŒ–æ•´åˆ

## æŠ€æœ¯ç»†èŠ‚

è¯¦ç»†çš„å®æ–½å†…å®¹...

## éªŒè¯ç»“æœ

æ‰€æœ‰æµ‹è¯•é€šè¿‡ã€‚
"""
            f.write(content)
            yield Path(f.name)
        Path(f.name).unlink(missing_ok=True)

    def test_end_to_end_report_processing(self, temp_report):
        """âœ… ç«¯åˆ°ç«¯: æŠ¥å‘ŠæŸ¥æ‰¾ + æ‘˜è¦æå– + å¼‚å¸¸å¤„ç†"""
        # éªŒè¯æ–‡ä»¶å­˜åœ¨ä¸”å¯è¯»
        assert temp_report.exists()

        # æå–æ‘˜è¦ï¼ˆåº”è¯¥é€šè¿‡æ‰€æœ‰å››å±‚é˜²æŠ¤ï¼‰
        summary = extract_report_summary(temp_report)
        assert isinstance(summary, str)
        # æ‘˜è¦å¯èƒ½ä¸ºç©ºï¼ˆå¦‚æœæ²¡æœ‰æ‰¾åˆ°æ‰§è¡Œæ‘˜è¦éƒ¨åˆ†ï¼‰ï¼Œä½†åº”è¯¥æ˜¯å­—ç¬¦ä¸²ç±»å‹
        assert isinstance(summary, str)

    def test_malformed_report_graceful_handling(self):
        """âœ… æ ¼å¼é”™è¯¯çš„æŠ¥å‘Šåº”è¯¥è¢«ä¼˜é›…å¤„ç†"""
        with tempfile.NamedTemporaryFile(mode='w', suffix='.md', delete=False) as f:
            f.write("ä¸å®Œæ•´çš„æŠ¥å‘Šå†…å®¹")
            temp_path = Path(f.name)

        try:
            # åº”è¯¥ä¸æŠ›å‡ºå¼‚å¸¸
            summary = extract_report_summary(temp_path)
            assert isinstance(summary, str)
        finally:
            temp_path.unlink(missing_ok=True)


if __name__ == '__main__':
    pytest.main([__file__, '-v', '--tb=short'])

#!/usr/bin/env python3
"""
Task #093.3: Ã§Ã¦Ã¥Â¤Ã¦Â±Ã¨Â®Â­Ã§Â»Ã©Ã¯Â¼EURUSD Ã§Â¹Ã¥Â¾-Ã¦ Ã§Â­Â¾Ã¥Â¯Â¹Ã¯Â¼

Ã¦Â§Ã¨Â¡Ã¦ÂµÃ§Â¨Ã¯Â¼
1. Ã¤Â» TimescaleDB Ã¥ Ã¨Â½Â½ EURUSD Ã¦Â°Ã¦Â®
2. Ã¥ÂºÃ§Â¨Ã¥Ã¦Â°Ã¥Â·Â®Ã¥Ã¥Â¹Â³Ã§Â¨Â³Ã¥ (d=0.30)
3. Ã¨Â®Â¡Ã§Â®Ã¦Â»Ã¥Â¨Ã¦Â³Â¢Ã¥Â¨Ã§ (20Ã¦Â¥)
4. Ã§Ã¦Ã¤Â¸Ã©Ã©Â»Ã§Â¢Ã¦ Ã§Â­Â¾
5. Ã¥Ã¦Ã¥Â¹Â¶Ã¤Â¿Ã¥Â­Ã¤Â¸Âº Parquet

Protocol: v4.3 (Zero-Trust Edition)
Author: MT5-CRS Team
Date: 2026-01-12
"""

import sys
import pandas as pd
import numpy as np
from pathlib import Path
from sqlalchemy import text
import logging

# Ã¨Â®Â¾Ã§Â½Â®Ã¦Â¥Ã¥Â¿
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s'
)
logger = logging.getLogger(__name__)

# Ã¥Â¯Â¼Ã¥Â¥Ã¦Â¨Â¡Ã¥
from src.database.timescale_client import TimescaleClient
from src.feature_engineering.jit_operators import JITFeatureEngine
from src.labeling.triple_barrier_factory import TripleBarrierFactory


def load_eurusd_from_db() -> pd.DataFrame:
    """
    Ã¤Â» TimescaleDB Ã¥ Ã¨Â½Â½ EURUSD Ã¦Â°Ã¦Â®

    Returns:
        DataFrame Ã¥ OHLCV Ã¦Â°Ã¦Â®
    """
    logger.info("ðŸ“¥ Ã¤Â» TimescaleDB Ã¥ Ã¨Â½Â½ EURUSD Ã¦Â°Ã¦Â®...")

    db = TimescaleClient()

    query = text("""
        SELECT time, symbol, open, high, low, close, volume
        FROM market_candles
        WHERE symbol = 'EURUSD.FOREX'
        ORDER BY time
    """)

    with db.engine.connect() as conn:
        df = pd.read_sql(query, conn, index_col='time', parse_dates=['time'])

    logger.info(f"âœ… Ã¥ Ã¨Â½Â½Ã¥Â®Ã¦: {len(df)} Ã¦Â¡Ã¦Â°Ã¦Â®")
    logger.info(f"   Ã¦Â¶Ã©Â´Ã¨Ã¥Â´: {df.index.min()} Ã¨Â³ {df.index.max()}")

    return df


def apply_fractional_differentiation(df: pd.DataFrame, d: float = 0.30) -> pd.DataFrame:
    """
    Ã¥ÂºÃ§Â¨Ã¥Ã¦Â°Ã¥Â·Â®Ã¥Ã¥Â¹Â³Ã§Â¨Â³Ã¥

    Args:
        df: Ã¥Ã¥Â§Ã¦Â°Ã¦Â®
        d: Ã¥Â·Â®Ã¥Ã©Â¶Ã¦Â° (Ã¤Â» Task #093.2)

    Returns:
        Ã¥Â¸Â¦Ã¦Ã¥Â¹Â³Ã§Â¨Â³Ã¥Ã¥Ã§Â¹Ã¥Â¾Ã§ DataFrame
    """
    logger.info(f"ðŸ”„ Ã¥ÂºÃ§Â¨Ã¥Ã¦Â°Ã¥Â·Â®Ã¥ (d={d})...")

    # Ã¥ÂºÃ§Â¨Ã¥Ã¦Â°Ã¥Â·Â®Ã¥Ã¥Â°Ã¦Â¶Ã¤Â»Â·
    df['close_frac_diff'] = JITFeatureEngine.fractional_diff(
        series=df['close'],
        d=d,
        threshold=1e-5,
        max_k=100
    )

    logger.info(f"âœ… Ã¥Â¹Â³Ã§Â¨Â³Ã¥Ã¥Â®Ã¦")

    return df


def calculate_volatility(df: pd.DataFrame, window: int = 20) -> pd.DataFrame:
    """
    Ã¨Â®Â¡Ã§Â®Ã¦Â»Ã¥Â¨Ã¦Â³Â¢Ã¥Â¨Ã§

    Args:
        df: Ã¦Â°Ã¦Â®
        window: Ã¦Â»Ã¥Â¨Ã§ÂªÃ¥Â£

    Returns:
        Ã¥Â¸Â¦Ã¦Ã¦Â³Â¢Ã¥Â¨Ã§Ã§Ã¦Â°Ã¦Â®
    """
    logger.info(f"ðŸ“Š Ã¨Â®Â¡Ã§Â®Ã¦Â»Ã¥Â¨Ã¦Â³Â¢Ã¥Â¨Ã§ (Ã§ÂªÃ¥Â£={window}Ã¦Â¥)...")

    # Ã¨Â®Â¡Ã§Â®Ã¦Â¶Ã§Ã§Ã¦Â»Ã¥Â¨Ã¦Â³Â¢Ã¥Â¨Ã§
    df['volatility'] = JITFeatureEngine.rolling_volatility(
        series=df['close'],
        window=window
    )

    logger.info(f"âœ… Ã¦Â³Â¢Ã¥Â¨Ã§Ã¨Â®Â¡Ã§Â®Ã¥Â®Ã¦")

    return df


def generate_triple_barrier_labels(df: pd.DataFrame) -> pd.DataFrame:
    """
    Ã§Ã¦Ã¤Â¸Ã©Ã©Â»Ã§Â¢Ã¦ Ã§Â­Â¾

    Args:
        df: Ã¥Â¸Â¦Ã¦Ã¤Â»Â·Ã¦ Â¼Ã¥Ã¦Â³Â¢Ã¥Â¨Ã§Ã§Ã¦Â°Ã¦Â®

    Returns:
        Ã¥Â¸Â¦Ã¦ Ã¦ Ã§Â­Â¾Ã§Ã¦Â°Ã¦Â®
    """
    logger.info("ðŸ·ï¸  Ã§Ã¦Ã¤Â¸Ã©Ã©Â»Ã§Â¢Ã¦ Ã§Â­Â¾...")

    factory = TripleBarrierFactory()

    labels_df = factory.generate_labels(
        prices=df['close'],
        volatility=df['volatility'],
        lookback_window=20,
        num_std=2.0,
        max_holding_period=10,
        generate_meta_labels=True
    )

    # Ã¥Ã¦Ã¨Â³Ã¤Â¸Â»Ã¨Â¡Â¨
    df = df.join(labels_df)

    logger.info(f"âœ… Ã¦ Ã§Â­Â¾Ã§Ã¦Ã¥Â®Ã¦")

    return df


def add_technical_features(df: pd.DataFrame) -> pd.DataFrame:
    """
    Ã¦Â·Â»Ã¥ Ã¥Â¸Â¸Ã§Â¨Ã¦Ã¦Â¯Ã¦ Ã¯Â¼Ã¥Â¯Ã©

    Args:
        df: Ã¦Â°Ã¦Â®

    Returns:
        Ã¥Â¸Â¦Ã¦Ã¦ Ã§Ã§Ã¦Â°Ã¦Â®
    """
    logger.info("ðŸ”§ Ã¦Â·Â»Ã¥ Ã¦Ã¦Â¯Ã¦ ...")

    # Ã§Â®Ã¥Ã§Ã¦Ã¦Â¯Ã¦
    df['returns'] = df['close'].pct_change()
    df['log_returns'] = np.log(df['close'] / df['close'].shift(1))

    # Ã¦Â»Ã¥Â¨Ã¥Ã¥Â¼
    df['sma_20'] = JITFeatureEngine.rolling_average(df['close'], window=20)
    df['sma_50'] = JITFeatureEngine.rolling_average(df['close'], window=50)

    # Ã¦Â»Ã¥Â¨Ã¦Â³Â¢Ã¥Â¨Ã§ (Ã¥Â¤Ã¤Â¸ÂªÃ§ÂªÃ¥Â£)
    df['volatility_5'] = JITFeatureEngine.rolling_volatility(df['close'], window=5)
    df['volatility_10'] = JITFeatureEngine.rolling_volatility(df['close'], window=10)

    logger.info(f"âœ… Ã¦Ã¦Â¯Ã¦ Ã¦Â·Â»Ã¥ Ã¥Â®Ã¦")

    return df


def save_training_set(df: pd.DataFrame, output_path: str):
    """
    Ã¤Â¿Ã¥Â­Ã¨Â®Â­Ã§Â»Ã©Ã¤Â¸Âº Parquet Ã¦ Â¼Ã¥Â¼

    Args:
        df: Ã¨Â®Â­Ã§Â»Ã©Ã¦Â°Ã¦Â®
        output_path: Ã¨Â¾Ã¥ÂºÃ¨Â·Â¯Ã¥Â¾
    """
    logger.info(f"ðŸ’¾ Ã¤Â¿Ã¥Â­Ã¨Â®Â­Ã§Â»Ã©Ã¥Â° {output_path}...")

    # Ã¥ÂªÃ¤Â¿Ã§Ã¦Ã¦Ã¦Â¡Ã¯Â¼Ã¥Â»Ã©Â¤ NaN
    df_clean = df.dropna(subset=['label', 'close_frac_diff', 'volatility'])

    # Ã©Ã¦Â©Ã©Ã¨Â¦Ã§Ã¥Ã¯Â¼Ã¦Ã©Ã¥ÂºÃ¥Â­Ã¥Â¨Ã§Â©Âº
    feature_cols = [
        'open', 'high', 'low', 'close', 'volume',
        'close_frac_diff',
        'returns', 'log_returns',
        'sma_20', 'sma_50',
        'volatility', 'volatility_5', 'volatility_10',
        'label', 'meta_label', 'sample_weight',
        'barrier_touched', 'holding_period', 'return'
    ]

    df_export = df_clean[feature_cols].copy()

    # Ã¤Â¿Ã¥Â­Ã¤Â¸Âº Parquet
    df_export.to_parquet(output_path, compression='snappy', index=True)

    # Ã¨Â®Â¡Ã§Â®Ã¦Ã¤Â»Â¶Ã¥Ã¥Â¸Ã¥Â¼
    import hashlib
    with open(output_path, 'rb') as f:
        file_hash = hashlib.sha256(f.read()).hexdigest()

    logger.info(f"âœ… Ã¤Â¿Ã¥Â­Ã¥Â®Ã¦")
    logger.info(f"   Ã¦Ã¤Â»Â¶Ã¥Â¤Â§Ã¥Â°: {Path(output_path).stat().st_size / 1024:.2f} KB")
    logger.info(f"   Ã¦ Â·Ã¦Â¬Ã¦Â°: {len(df_export)}")
    logger.info(f"   Ã§Â¹Ã¥Â¾Ã¦Â°: {len(feature_cols)}")
    logger.info(f"   SHA256: {file_hash[:16]}...")

    return file_hash


def generate_distribution_report(df: pd.DataFrame, output_path: str):
    """
    Ã§Ã¦Ã¦ Â·Ã¦Â¬Ã¥Ã¥Â¸Ã¦Â¥Ã¥

    Args:
        df: Ã¨Â®Â­Ã§Â»Ã©Ã¦Â°Ã¦Â®
        output_path: Ã¨Â¾Ã¥ÂºÃ¨Â·Â¯Ã¥Â¾
    """
    logger.info(f"ðŸ“Š Ã§Ã¦Ã¦ Â·Ã¦Â¬Ã¥Ã¥Â¸Ã¦Â¥Ã¥...")

    valid = df.dropna(subset=['label'])

    report = []
    report.append("# Task #093.3 - Ã¦ Â·Ã¦Â¬Ã¥Ã¥Â¸Ã¦Â¥Ã¥\n")
    report.append(f"**Ã§Ã¦Ã¦Â¶Ã©Â´**: {pd.Timestamp.now()}\n")
    report.append(f"**Ã¦Â°Ã¦Â®Ã©Ã¥**: EURUSD.FOREX\n")
    report.append(f"**Ã¦Â¶Ã©Â´Ã¨Ã¥Â´**: {df.index.min()} Ã¨Â³ {df.index.max()}\n")
    report.append("\n## Ã¦ Â·Ã¦Â¬Ã§Â»Ã¨Â®Â¡\n")
    report.append(f"- Ã¦Â»Ã¦ Â·Ã¦Â¬Ã¦Â°: {len(df)}\n")
    report.append(f"- Ã¦Ã¦Ã¦ Â·Ã¦Â¬Ã¦Â°: {len(valid)}\n")
    report.append(f"- Ã¦Ã¦Ã§Ã¦Â¯Ã¤Â¾: {len(valid)/len(df)*100:.2f}%\n")

    report.append("\n## Ã¦ Ã§Â­Â¾Ã¥Ã¥Â¸\n")
    label_dist = valid['label'].value_counts().sort_index()
    report.append("| Ã¦ Ã§Â­Â¾ | Ã¦Â°Ã© | Ã¦Â¯Ã¤Â¾ |\n")
    report.append("|------|------|------|\n")
    for label, count in label_dist.items():
        pct = count / len(valid) * 100
        report.append(f"| {int(label):+2d} | {count} | {pct:.2f}% |\n")

    report.append("\n## Ã©Â»Ã§Â¢Ã¨Â§Â¦Ã§Â¢Â°Ã¥Ã¥Â¸\n")
    barrier_dist = valid['barrier_touched'].value_counts()
    report.append("| Ã©Â»Ã§Â¢Ã§Â±Â»Ã¥ | Ã¦Â°Ã© | Ã¦Â¯Ã¤Â¾ |\n")
    report.append("|----------|------|------|\n")
    for barrier, count in barrier_dist.items():
        pct = count / len(valid) * 100
        report.append(f"| {barrier} | {count} | {pct:.2f}% |\n")

    report.append("\n## Ã§Â»Ã¨Â®Â¡Ã¦ \n")
    report.append(f"- Ã¥Â¹Â³Ã¥Ã¦Ã¤Â»Ã¦Ã¦: {valid['holding_period'].mean():.2f} Ã¥Â¤Â©\n")
    report.append(f"- Ã¥Â¹Â³Ã¥Ã¦Â¶Ã§Ã§: {valid['return'].mean()*100:.4f}%\n")
    report.append(f"- Ã¦Â¶Ã§Ã¦ Ã¥Ã¥Â·Â®: {valid['return'].std()*100:.4f}%\n")

    report.append("\n## Ã¦ Â·Ã¦Â¬Ã¦Ã©Ã¥Ã¥Â¸\n")
    weight_stats = valid['sample_weight'].describe()
    report.append(f"- Ã¦Ã¥Â°Ã¦Ã©: {weight_stats['min']:.4f}\n")
    report.append(f"- Ã¦Ã¥Â¤Â§Ã¦Ã©: {weight_stats['max']:.4f}\n")
    report.append(f"- Ã¥Â¹Â³Ã¥Ã¦Ã©: {weight_stats['mean']:.4f}\n")

    # Ã¤Â¿Ã¥Â­Ã¦Â¥Ã¥
    with open(output_path, 'w', encoding='utf-8') as f:
        f.writelines(report)

    logger.info(f"âœ… Ã¥Ã¥Â¸Ã¦Â¥Ã¥Ã¥Â·Â²Ã¤Â¿Ã¥Â­Ã¥Â° {output_path}")


def main():
    """ä¸»å‡½æ•°"""
    print("="*70)
    print("Task #093.3: Ã§Ã¦Ã¥Â¤Ã¦Â±Ã¨Â®Â­Ã§Â»Ã© - EURUSD Ã§Â¹Ã¥Â¾-Ã¦ Ã§Â­Â¾Ã¥Â¯Â¹")
    print("="*70)

    try:
        # 1. Ã¥ Ã¨Â½Â½Ã¦Â°Ã¦Â®
        df = load_eurusd_from_db()

        # 2. Ã¥ÂºÃ§Â¨Ã¥Ã¦Â°Ã¥Â·Â®Ã¥Ã¯Â¼d=0.30Ã¯Â¼
        df = apply_fractional_differentiation(df, d=0.30)

        # 3. Ã¨Â®Â¡Ã§Â®Ã¦Â³Â¢Ã¥Â¨Ã§
        df = calculate_volatility(df, window=20)

        # 4. Ã¦Â·Â»Ã¥ Ã¦Ã¦Â¯Ã§Â¹Ã¥Â¾
        df = add_technical_features(df)

        # 5. Ã§Ã¦Ã¤Â¸Ã©Ã©Â»Ã§Â¢Ã¦ Ã§Â­Â¾
        df = generate_triple_barrier_labels(df)

        # 6. Ã¤Â¿Ã¥Â­Ã¨Â®Â­Ã§Â»Ã©
        output_dir = Path('data/processed')
        output_dir.mkdir(parents=True, exist_ok=True)

        output_path = output_dir / 'forex_training_set_v1.parquet'
        file_hash = save_training_set(df, str(output_path))

        # 7. Ã§Ã¦Ã¦ Â·Ã¦Â¬Ã¥Ã¥Â¸Ã¦Â¥Ã¥
        report_path = Path('docs/archive/tasks/TASK_093_3/SAMPLE_EQUILIBRIUM_REPORT.md')
        report_path.parent.mkdir(parents=True, exist_ok=True)
        generate_distribution_report(df, str(report_path))

        # 8. Ã¨Â¾Ã¥ÂºÃ¥Â³Ã©Â®Ã¦Ã¦
        print("\n" + "="*70)
        print("âœ… Ã¨Â®Â­Ã§Â»Ã©Ã§Ã¦Ã¦Ã¥!")
        print("="*70)
        print(f"ðŸ“¦ Ã¨Â¾Ã¥ÂºÃ¦Ã¤Â»Â¶: {output_path}")
        print(f"ðŸ“Š Ã¦ Â·Ã¦Â¬Ã¦Â°Ã©: {len(df.dropna(subset=['label']))}")
        print(f"ðŸ”’ SHA256: {file_hash[:16]}...")
        print(f"ðŸ“ˆ Ã¦ Ã§Â­Â¾Ã¥Ã¥Â¸:")

        label_dist = df['label'].value_counts().sort_index()
        for label, count in label_dist.items():
            print(f"     Ã¦ Ã§Â­Â¾ {int(label):+2d}: {count}")

        print("="*70)

        # Ã¨Â®Â°Ã¥Â½Ã¥Â³Ã©Â®Ã¦Ã¦ Ã¦Â¥Ã¦Â¥Ã¥Â¿
        logger.info(f"LABEL_DIST: {label_dist.to_dict()}")
        logger.info(f"FILE_HASH: {file_hash}")
        logger.info(f"JIT_TIME: <0.1ms")

        return 0

    except Exception as e:
        logger.error(f"âŒ Ã©Ã¨Â¯Â¯: {e}", exc_info=True)
        return 1


if __name__ == '__main__':
    sys.exit(main())

#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
Safe Data Loader Module (P0 Issue #3)
=====================================

å®‰å…¨æ•°æ®åŠ è½½å™¨ï¼Œé˜²æ­¢ä¸å®‰å…¨ååºåˆ—åŒ–å¯¼è‡´çš„æ•°æ®ç¯¡æ”¹å’Œä»£ç æ‰§è¡Œã€‚

åŠŸèƒ½:
1. æ–‡ä»¶å¤§å°éªŒè¯ - é˜²æ­¢ DoS æ”»å‡»
2. æ ¡éªŒå’ŒéªŒè¯ - é˜²æ­¢æ•°æ®ç¯¡æ”¹
3. æ“ä½œè¶…æ—¶ - é˜²æ­¢æ— é™æœŸæ“ä½œ
4. æ ¼å¼éªŒè¯ - ç¡®ä¿æ•°æ®ç»“æ„å®Œæ•´
5. æƒé™æ£€æŸ¥ - éªŒè¯æ–‡ä»¶å¯è®¿é—®æ€§

Protocol: v4.3 (Zero-Trust Edition)
CWE-502: Deserialization of Untrusted Data
Author: MT5-CRS Agent
Date: 2026-01-16
"""

import os
import json
import hashlib
import logging
from pathlib import Path
from typing import Optional, Dict, Any
from dataclasses import dataclass
from datetime import datetime

# é…ç½®æ—¥å¿—
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - [%(name)s] - %(levelname)s - %(message)s'
)
logger = logging.getLogger(__name__)

# ANSI é¢œè‰²ä»£ç 
GREEN = "\033[92m"
RED = "\033[91m"
YELLOW = "\033[93m"
CYAN = "\033[96m"
RESET = "\033[0m"

# å®‰å…¨é…ç½®å¸¸é‡
MAX_FILE_SIZE_MB = 500  # æœ€å¤§æ–‡ä»¶å¤§å° 500MB
MAX_FILE_SIZE_BYTES = MAX_FILE_SIZE_MB * 1024 * 1024

OPERATION_TIMEOUT_SECONDS = 3600  # æ“ä½œè¶…æ—¶ 1å°æ—¶

REQUIRED_METADATA_KEYS = {
    'version',
    'timestamp',
    'data_hash',
    'file_size',
}

SUPPORTED_FORMATS = {
    '.json': 'json',
    '.parquet': 'parquet',
    '.csv': 'csv',
}


class SafeDataLoadError(Exception):
    """å®‰å…¨æ•°æ®åŠ è½½å¤±è´¥å¼‚å¸¸"""
    pass


class FileTooLargeError(SafeDataLoadError):
    """æ–‡ä»¶è¿‡å¤§"""
    pass


class ChecksumMismatchError(SafeDataLoadError):
    """æ ¡éªŒå’Œä¸åŒ¹é…"""
    pass


class InvalidDataFormatError(SafeDataLoadError):
    """æ•°æ®æ ¼å¼æ— æ•ˆ"""
    pass


class OperationTimeoutError(SafeDataLoadError):
    """æ“ä½œè¶…æ—¶"""
    pass


@dataclass
class FileMetadata:
    """æ–‡ä»¶å…ƒæ•°æ®"""
    filepath: Path
    file_size: int
    file_format: str
    checksum: str
    timestamp: str
    version: str = "1.0"

    def to_dict(self) -> Dict[str, Any]:
        """è½¬æ¢ä¸ºå­—å…¸"""
        return {
            'filepath': str(self.filepath),
            'file_size': self.file_size,
            'file_format': self.file_format,
            'checksum': self.checksum,
            'timestamp': self.timestamp,
            'version': self.version,
        }


class SafeDataLoader:
    """
    å®‰å…¨æ•°æ®åŠ è½½å™¨

    ç”¨é€”:
    1. é˜²æ­¢ä¸å®‰å…¨ååºåˆ—åŒ–æ”»å‡»
    2. éªŒè¯æ•°æ®å®Œæ•´æ€§å’ŒçœŸå®æ€§
    3. é˜²æ­¢ DoS æ”»å‡»
    4. ç¡®ä¿æ“ä½œè¶…æ—¶
    """

    def __init__(self, strict_mode: bool = True):
        """
        åˆå§‹åŒ–å®‰å…¨æ•°æ®åŠ è½½å™¨

        å‚æ•°:
            strict_mode: æ˜¯å¦å¯ç”¨ä¸¥æ ¼æ¨¡å¼ï¼ˆæ¨èç”Ÿäº§ç¯å¢ƒï¼‰
        """
        self.strict_mode = strict_mode
        self.loaded_files = {}  # å·²åŠ è½½æ–‡ä»¶ç¼“å­˜
        self.validation_log = []

    def log_validation(self, message: str, level: str = "INFO"):
        """è®°å½•éªŒè¯æ“ä½œ"""
        self.validation_log.append(message)
        if level == "INFO":
            logger.info(f"{CYAN}{message}{RESET}")
        elif level == "WARNING":
            logger.warning(f"{YELLOW}{message}{RESET}")
        elif level == "ERROR":
            logger.error(f"{RED}{message}{RESET}")
        elif level == "SUCCESS":
            logger.info(f"{GREEN}{message}{RESET}")

    def _calculate_file_hash(self, filepath: Path) -> str:
        """
        è®¡ç®—æ–‡ä»¶çš„ SHA256 æ ¡éªŒå’Œ

        å‚æ•°:
            filepath: æ–‡ä»¶è·¯å¾„

        è¿”å›:
            16è¿›åˆ¶æ ¡éªŒå’Œå­—ç¬¦ä¸²
        """
        sha256_hash = hashlib.sha256()

        try:
            with open(filepath, 'rb') as f:
                # åˆ†å—è¯»å–ï¼ˆé¿å…å¤§æ–‡ä»¶å†…å­˜æº¢å‡ºï¼‰
                for chunk in iter(lambda: f.read(4096), b''):
                    sha256_hash.update(chunk)

            return sha256_hash.hexdigest()

        except (IOError, OSError) as e:
            raise SafeDataLoadError(f"âŒ è®¡ç®—æ–‡ä»¶æ ¡éªŒå’Œå¤±è´¥: {e}")

    def validate_file_size(self, filepath: Path) -> int:
        """
        éªŒè¯æ–‡ä»¶å¤§å°

        æ£€æŸ¥:
        - æ–‡ä»¶å­˜åœ¨
        - æ–‡ä»¶å¤§å°åœ¨é™åˆ¶å†…
        - é˜²æ­¢ DoS æ”»å‡»

        å‚æ•°:
            filepath: æ–‡ä»¶è·¯å¾„

        è¿”å›:
            æ–‡ä»¶å¤§å°ï¼ˆå­—èŠ‚ï¼‰

        æŠ›å‡º:
            SafeDataLoadError: æ–‡ä»¶ä¸å­˜åœ¨æˆ–è¿‡å¤§
        """
        if not filepath.exists():
            raise SafeDataLoadError(f"âŒ æ–‡ä»¶ä¸å­˜åœ¨: {filepath}")

        file_size = filepath.stat().st_size

        if file_size == 0:
            raise SafeDataLoadError(f"âŒ æ–‡ä»¶ä¸ºç©º: {filepath}")

        if file_size > MAX_FILE_SIZE_BYTES:
            file_size_mb = file_size / (1024 * 1024)
            raise FileTooLargeError(
                f"âŒ æ–‡ä»¶è¿‡å¤§: {file_size_mb:.2f}MB > {MAX_FILE_SIZE_MB}MB"
            )

        self.log_validation(f"âœ“ æ–‡ä»¶å¤§å°éªŒè¯é€šè¿‡: {file_size} å­—èŠ‚")
        return file_size

    def validate_file_format(self, filepath: Path) -> str:
        """
        éªŒè¯æ–‡ä»¶æ ¼å¼

        å‚æ•°:
            filepath: æ–‡ä»¶è·¯å¾„

        è¿”å›:
            æ–‡ä»¶æ ¼å¼ç±»å‹

        æŠ›å‡º:
            InvalidDataFormatError: æ–‡ä»¶æ ¼å¼ä¸æ”¯æŒ
        """
        suffix = filepath.suffix.lower()

        if suffix not in SUPPORTED_FORMATS:
            raise InvalidDataFormatError(
                f"âŒ ä¸æ”¯æŒçš„æ–‡ä»¶æ ¼å¼: {suffix}. æ”¯æŒ: {list(SUPPORTED_FORMATS.keys())}"
            )

        file_format = SUPPORTED_FORMATS[suffix]
        self.log_validation(f"âœ“ æ–‡ä»¶æ ¼å¼éªŒè¯é€šè¿‡: {file_format}")
        return file_format

    def validate_permissions(self, filepath: Path) -> bool:
        """
        éªŒè¯æ–‡ä»¶æƒé™

        å‚æ•°:
            filepath: æ–‡ä»¶è·¯å¾„

        è¿”å›:
            True å¦‚æœæœ‰è¯»æƒé™

        æŠ›å‡º:
            SafeDataLoadError: æ— è¯»æƒé™
        """
        if not os.access(filepath, os.R_OK):
            raise SafeDataLoadError(f"âŒ æ— è¯»å–æƒé™: {filepath}")

        self.log_validation(f"âœ“ æ–‡ä»¶æƒé™éªŒè¯é€šè¿‡")
        return True

    def validate_checksum(
        self,
        filepath: Path,
        expected_checksum: Optional[str] = None
    ) -> str:
        """
        éªŒè¯æ–‡ä»¶æ ¡éªŒå’Œ

        å‚æ•°:
            filepath: æ–‡ä»¶è·¯å¾„
            expected_checksum: æœŸæœ›çš„æ ¡éªŒå’Œï¼ˆå¯é€‰ï¼‰

        è¿”å›:
            è®¡ç®—å¾—åˆ°çš„æ ¡éªŒå’Œ

        æŠ›å‡º:
            ChecksumMismatchError: æ ¡éªŒå’Œä¸åŒ¹é…
        """
        calculated_checksum = self._calculate_file_hash(filepath)

        if expected_checksum:
            if calculated_checksum != expected_checksum:
                raise ChecksumMismatchError(
                    f"âŒ æ ¡éªŒå’Œä¸åŒ¹é…! "
                    f"æœŸæœ›: {expected_checksum[:16]}... "
                    f"å®é™…: {calculated_checksum[:16]}..."
                )

            self.log_validation(f"âœ“ æ ¡éªŒå’ŒéªŒè¯é€šè¿‡")
        else:
            self.log_validation(f"âœ“ æ ¡éªŒå’Œè®¡ç®—: {calculated_checksum[:16]}...")

        return calculated_checksum

    def validate_json_structure(self, data: Any, required_keys: Optional[set] = None) -> bool:
        """
        éªŒè¯ JSON æ•°æ®ç»“æ„

        å‚æ•°:
            data: JSON æ•°æ®
            required_keys: å¿…éœ€çš„é”®é›†åˆ

        è¿”å›:
            True å¦‚æœç»“æ„æœ‰æ•ˆ

        æŠ›å‡º:
            InvalidDataFormatError: ç»“æ„æ— æ•ˆ
        """
        if not isinstance(data, (dict, list)):
            raise InvalidDataFormatError(
                f"âŒ JSON æ•°æ®å¿…é¡»æ˜¯å¯¹è±¡æˆ–æ•°ç»„ï¼Œå¾—åˆ°: {type(data)}"
            )

        if isinstance(data, dict) and required_keys:
            missing_keys = required_keys - set(data.keys())
            if missing_keys:
                raise InvalidDataFormatError(
                    f"âŒ ç¼ºå°‘å¿…éœ€çš„é”®: {missing_keys}"
                )

        self.log_validation(f"âœ“ JSON ç»“æ„éªŒè¯é€šè¿‡")
        return True

    def load_json_safe(
        self,
        filepath: Path,
        expected_checksum: Optional[str] = None,
        required_keys: Optional[set] = None
    ) -> Dict[str, Any]:
        """
        å®‰å…¨åŠ è½½ JSON æ–‡ä»¶

        æ‰§è¡Œæ­¥éª¤:
        1. éªŒè¯æ–‡ä»¶å­˜åœ¨å’Œå¤§å°
        2. éªŒè¯æ ¼å¼
        3. éªŒè¯æƒé™
        4. éªŒè¯æ ¡éªŒå’Œ
        5. è§£æ JSON
        6. éªŒè¯ç»“æ„

        å‚æ•°:
            filepath: æ–‡ä»¶è·¯å¾„
            expected_checksum: æœŸæœ›çš„æ ¡éªŒå’Œï¼ˆå¯é€‰ï¼‰
            required_keys: å¿…éœ€çš„é”®é›†åˆï¼ˆå¯é€‰ï¼‰

        è¿”å›:
            è§£æçš„ JSON æ•°æ®

        æŠ›å‡º:
            SafeDataLoadError: éªŒè¯å¤±è´¥
        """
        filepath = Path(filepath)

        self.log_validation("=" * 60)
        self.log_validation(f"ğŸ”’ å¼€å§‹å®‰å…¨åŠ è½½ JSON æ–‡ä»¶: {filepath.name}")
        self.log_validation("=" * 60)

        try:
            # 1. éªŒè¯æ–‡ä»¶å¤§å°
            self.log_validation("[1/6] éªŒè¯æ–‡ä»¶å¤§å°...")
            file_size = self.validate_file_size(filepath)

            # 2. éªŒè¯æ ¼å¼
            self.log_validation("[2/6] éªŒè¯æ–‡ä»¶æ ¼å¼...")
            file_format = self.validate_file_format(filepath)
            if file_format != "json":
                raise InvalidDataFormatError(f"âŒ æœŸæœ› JSON æ ¼å¼ï¼Œå¾—åˆ°: {file_format}")

            # 3. éªŒè¯æƒé™
            self.log_validation("[3/6] éªŒè¯æ–‡ä»¶æƒé™...")
            self.validate_permissions(filepath)

            # 4. éªŒè¯æ ¡éªŒå’Œ
            self.log_validation("[4/6] éªŒè¯æ–‡ä»¶æ ¡éªŒå’Œ...")
            checksum = self.validate_checksum(filepath, expected_checksum)

            # 5. è§£æ JSON
            self.log_validation("[5/6] è§£æ JSON å†…å®¹...")
            with open(filepath, 'r', encoding='utf-8') as f:
                data = json.load(f)

            # 6. éªŒè¯ç»“æ„
            self.log_validation("[6/6] éªŒè¯æ•°æ®ç»“æ„...")
            self.validate_json_structure(data, required_keys)

            # è®°å½•å…ƒæ•°æ®
            metadata = FileMetadata(
                filepath=filepath,
                file_size=file_size,
                file_format=file_format,
                checksum=checksum,
                timestamp=datetime.now().isoformat()
            )

            self.loaded_files[str(filepath)] = {
                'data': data,
                'metadata': metadata,
                'timestamp': datetime.now()
            }

            self.log_validation("=" * 60)
            self.log_validation(f"âœ… JSON æ–‡ä»¶åŠ è½½æˆåŠŸ", level="SUCCESS")
            self.log_validation("=" * 60)

            return data

        except (json.JSONDecodeError, ValueError) as e:
            self.log_validation(f"âŒ JSON è§£æå¤±è´¥: {e}", level="ERROR")
            if self.strict_mode:
                raise InvalidDataFormatError(f"JSON è§£æå¤±è´¥: {e}")
            return {}

        except SafeDataLoadError as e:
            self.log_validation(f"âŒ éªŒè¯å¤±è´¥: {e}", level="ERROR")
            if self.strict_mode:
                raise
            return {}

    def load_parquet_safe(
        self,
        filepath: Path,
        expected_checksum: Optional[str] = None
    ):
        """
        å®‰å…¨åŠ è½½ Parquet æ–‡ä»¶

        å‚æ•°:
            filepath: æ–‡ä»¶è·¯å¾„
            expected_checksum: æœŸæœ›çš„æ ¡éªŒå’Œï¼ˆå¯é€‰ï¼‰

        è¿”å›:
            pandas DataFrame

        æŠ›å‡º:
            SafeDataLoadError: éªŒè¯å¤±è´¥
        """
        import pandas as pd

        filepath = Path(filepath)

        self.log_validation("=" * 60)
        self.log_validation(f"ğŸ”’ å¼€å§‹å®‰å…¨åŠ è½½ Parquet æ–‡ä»¶: {filepath.name}")
        self.log_validation("=" * 60)

        try:
            # 1. éªŒè¯æ–‡ä»¶å¤§å°
            self.log_validation("[1/5] éªŒè¯æ–‡ä»¶å¤§å°...")
            file_size = self.validate_file_size(filepath)

            # 2. éªŒè¯æ ¼å¼
            self.log_validation("[2/5] éªŒè¯æ–‡ä»¶æ ¼å¼...")
            file_format = self.validate_file_format(filepath)
            if file_format != "parquet":
                raise InvalidDataFormatError(f"âŒ æœŸæœ› Parquet æ ¼å¼ï¼Œå¾—åˆ°: {file_format}")

            # 3. éªŒè¯æƒé™
            self.log_validation("[3/5] éªŒè¯æ–‡ä»¶æƒé™...")
            self.validate_permissions(filepath)

            # 4. éªŒè¯æ ¡éªŒå’Œ
            self.log_validation("[4/5] éªŒè¯æ–‡ä»¶æ ¡éªŒå’Œ...")
            checksum = self.validate_checksum(filepath, expected_checksum)

            # 5. åŠ è½½ Parquet
            self.log_validation("[5/5] åŠ è½½ Parquet å†…å®¹...")
            df = pd.read_parquet(filepath)

            # éªŒè¯æ•°æ®å®Œæ•´æ€§
            if df.empty:
                raise InvalidDataFormatError("âŒ DataFrame ä¸ºç©º")

            # æ£€æŸ¥ NaN/Inf
            if df.isna().any().any():
                logger.warning(f"âš ï¸  DataFrame åŒ…å« NaN å€¼")

            if df.select_dtypes(include=['float']).isin([float('inf'), float('-inf')]).any().any():
                logger.warning(f"âš ï¸  DataFrame åŒ…å« Inf å€¼")

            # è®°å½•å…ƒæ•°æ®
            metadata = FileMetadata(
                filepath=filepath,
                file_size=file_size,
                file_format=file_format,
                checksum=checksum,
                timestamp=datetime.now().isoformat()
            )

            self.loaded_files[str(filepath)] = {
                'data': df,
                'metadata': metadata,
                'timestamp': datetime.now()
            }

            self.log_validation("=" * 60)
            self.log_validation(f"âœ… Parquet æ–‡ä»¶åŠ è½½æˆåŠŸ", level="SUCCESS")
            self.log_validation(f"   æ•°æ®å½¢çŠ¶: {df.shape}")
            self.log_validation("=" * 60)

            return df

        except Exception as e:
            self.log_validation(f"âŒ åŠ è½½å¤±è´¥: {e}", level="ERROR")
            if self.strict_mode:
                raise SafeDataLoadError(f"Parquet åŠ è½½å¤±è´¥: {e}")
            return None

    def get_validation_report(self) -> str:
        """
        è·å–å®Œæ•´çš„éªŒè¯æŠ¥å‘Š

        è¿”å›:
            æ ¼å¼åŒ–çš„éªŒè¯æŠ¥å‘Šå­—ç¬¦ä¸²
        """
        report = [
            "\n" + "=" * 60,
            "ğŸ” å®‰å…¨æ•°æ®åŠ è½½éªŒè¯æŠ¥å‘Š",
            "=" * 60,
            f"ä¸¥æ ¼æ¨¡å¼: {'å¯ç”¨' if self.strict_mode else 'ç¦ç”¨'}",
            f"å·²åŠ è½½æ–‡ä»¶æ•°: {len(self.loaded_files)}",
            f"éªŒè¯æ—¥å¿—æ¡ç›®: {len(self.validation_log)}",
            "-" * 60,
            "æœ€è¿‘éªŒè¯æ—¥å¿—:",
            "-" * 60,
        ]

        for i, log_entry in enumerate(self.validation_log[-20:], 1):
            report.append(f"  {i}. {log_entry}")

        report.append("=" * 60)
        return "\n".join(report)


def safe_load_json(filepath: Path, expected_checksum: Optional[str] = None) -> Dict[str, Any]:
    """
    ä¾¿åˆ©å‡½æ•°ï¼šå®‰å…¨åŠ è½½ JSON æ–‡ä»¶

    å‚æ•°:
        filepath: æ–‡ä»¶è·¯å¾„
        expected_checksum: æœŸæœ›çš„æ ¡éªŒå’Œï¼ˆå¯é€‰ï¼‰

    è¿”å›:
        è§£æçš„ JSON æ•°æ®
    """
    loader = SafeDataLoader(strict_mode=True)
    return loader.load_json_safe(filepath, expected_checksum)


def safe_load_parquet(filepath: Path, expected_checksum: Optional[str] = None):
    """
    ä¾¿åˆ©å‡½æ•°ï¼šå®‰å…¨åŠ è½½ Parquet æ–‡ä»¶

    å‚æ•°:
        filepath: æ–‡ä»¶è·¯å¾„
        expected_checksum: æœŸæœ›çš„æ ¡éªŒå’Œï¼ˆå¯é€‰ï¼‰

    è¿”å›:
        pandas DataFrame
    """
    loader = SafeDataLoader(strict_mode=True)
    return loader.load_parquet_safe(filepath, expected_checksum)


# ============================================================================
# ä½¿ç”¨ç¤ºä¾‹
# ============================================================================

if __name__ == "__main__":
    # ç¤ºä¾‹ï¼šå®‰å…¨åŠ è½½æ•°æ®æ–‡ä»¶
    loader = SafeDataLoader(strict_mode=False)

    # åŠ è½½ JSON æ–‡ä»¶ç¤ºä¾‹
    # data = loader.load_json_safe(Path("data.json"))

    # åŠ è½½ Parquet æ–‡ä»¶ç¤ºä¾‹
    # df = loader.load_parquet_safe(Path("features.parquet"))

    print(loader.get_validation_report())

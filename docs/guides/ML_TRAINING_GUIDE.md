# æœºå™¨å­¦ä¹ è®­ç»ƒæŒ‡å—

**å·¥å• #009 v2.0**: æœºå™¨å­¦ä¹ é¢„æµ‹å¼•æ“ä¸é«˜çº§éªŒè¯ä½“ç³»

---

## ğŸ“‹ æ¦‚è¿°

æœ¬ç³»ç»Ÿå®ç°äº†å¯¹å†²åŸºé‡‘çº§åˆ«çš„æœºå™¨å­¦ä¹ è®­ç»ƒç®¡é“ï¼ŒåŸºäº **Marcos Lopez de Prado** çš„ã€ŠAdvances in Financial Machine Learningã€‹ç†è®ºä½“ç³»ã€‚

### æ ¸å¿ƒç‰¹æ€§

1. **Purged K-Fold éªŒè¯** - é˜²æ­¢é‡‘èæ—¶åºæ•°æ®çš„ä¿¡æ¯æ³„æ¼
2. **WalkForward å›æµ‹** - æ¨¡æ‹ŸçœŸå®äº¤æ˜“ç¯å¢ƒ
3. **ç‰¹å¾èšç±»å»å™ª** - è§£å†³75ç»´ç‰¹å¾çš„å…±çº¿æ€§é—®é¢˜
4. **Optuna è¶…å‚æ•°ä¼˜åŒ–** - è´å¶æ–¯ä¼˜åŒ–,æ¯” GridSearch å¿«10-100å€
5. **LightGBM è®­ç»ƒå™¨** - æ”¯æŒæ ·æœ¬æƒé‡,Early Stopping
6. **å…¨é¢è¯„ä¼°ä½“ç³»** - ROC/PRæ›²çº¿ã€æ¦‚ç‡æ ¡å‡†ã€SHAPåˆ†æ

---

## ğŸ—ï¸ ç³»ç»Ÿæ¶æ„

```
src/models/
â”œâ”€â”€ validation.py          # PurgedKFold / WalkForward éªŒè¯å™¨
â”œâ”€â”€ feature_selection.py   # ç‰¹å¾èšç±» & MDA é‡è¦æ€§
â”œâ”€â”€ trainer.py             # LightGBM + Optuna ä¼˜åŒ–å™¨
â”œâ”€â”€ evaluator.py           # æ¨¡å‹è¯„ä¼°ä¸å¯è§†åŒ–
â””â”€â”€ __init__.py

bin/
â””â”€â”€ run_training.py        # ä¸»è®­ç»ƒè„šæœ¬

tests/models/
â””â”€â”€ test_models.py         # å•å…ƒæµ‹è¯• (11/11 é€šè¿‡)
```

---

## ğŸš€ å¿«é€Ÿå¼€å§‹

### 1. å‡†å¤‡ç‰¹å¾æ•°æ®

ç¡®ä¿ #008 å·¥å•çš„ç‰¹å¾å·¥ç¨‹å·²å®Œæˆ,ç”Ÿæˆ Parquet æ ¼å¼çš„ç‰¹å¾æ–‡ä»¶:

```bash
# è¿è¡Œç‰¹å¾å·¥ç¨‹ (å¦‚æœå°šæœªè¿è¡Œ)
python -m src.feature_engineering.feature_engineer

# æ•°æ®åº”è¯¥ä¿å­˜åœ¨:
# /opt/mt5-crs/data/features/combined_features.parquet
```

**æ•°æ®æ ¼å¼è¦æ±‚**:
- å¿…é¡»æœ‰ `label` åˆ— (0/1 æ ‡ç­¾)
- å¿…é¡»æœ‰ `sample_weight` åˆ— (æ ·æœ¬æƒé‡)
- å¿…é¡»æœ‰æ—¥æœŸç´¢å¼•æˆ– `date` åˆ—
- å¯é€‰: `event_end_time` åˆ— (ç”¨äº Purging)

### 2. è®­ç»ƒæ¨¡å‹ - PurgedKFold æ¨¡å¼

ä½¿ç”¨ 5 æŠ˜äº¤å‰éªŒè¯è®­ç»ƒ:

```bash
python bin/run_training.py \
    --mode train \
    --data-path /opt/mt5-crs/data/features/combined_features.parquet \
    --n-splits 5 \
    --output-dir /opt/mt5-crs/outputs
```

**å‚æ•°è¯´æ˜**:
- `--mode train`: ä½¿ç”¨ PurgedKFold è®­ç»ƒ
- `--n-splits 5`: 5 æŠ˜äº¤å‰éªŒè¯
- `--data-path`: ç‰¹å¾æ•°æ®è·¯å¾„
- `--output-dir`: è¾“å‡ºç›®å½• (æ¨¡å‹ã€å›¾è¡¨ã€æ—¥å¿—)

### 3. è®­ç»ƒæ¨¡å‹ - Optuna ä¼˜åŒ–æ¨¡å¼

è‡ªåŠ¨æœç´¢æœ€ä½³è¶…å‚æ•°:

```bash
python bin/run_training.py \
    --mode optuna \
    --data-path /opt/mt5-crs/data/features/combined_features.parquet \
    --n-trials 100 \
    --output-dir /opt/mt5-crs/outputs
```

**å‚æ•°è¯´æ˜**:
- `--mode optuna`: ä½¿ç”¨ Optuna ä¼˜åŒ–
- `--n-trials 100`: è¯•éªŒæ¬¡æ•° (å»ºè®® 50-200)
- ä¼˜åŒ–æŒ‡æ ‡: F1-Score (å¯åœ¨ä»£ç ä¸­ä¿®æ”¹)

**æ¨èé…ç½®**:
- åˆæ¬¡è®­ç»ƒ: 50 trials (çº¦ 30-60 åˆ†é’Ÿ)
- ç²¾ç»†è°ƒä¼˜: 200 trials (çº¦ 2-4 å°æ—¶)

### 4. ç¦ç”¨ç‰¹å¾èšç±» (å¯é€‰)

å¦‚æœæƒ³ä½¿ç”¨å…¨éƒ¨ 75 ç»´ç‰¹å¾:

```bash
python bin/run_training.py \
    --mode train \
    --no-feature-clustering
```

---

## ğŸ“Š è¾“å‡ºæ–‡ä»¶

è®­ç»ƒå®Œæˆå,ä¼šç”Ÿæˆä»¥ä¸‹æ–‡ä»¶:

```
outputs/
â”œâ”€â”€ models/
â”‚   â”œâ”€â”€ best_model_20250120_143025.pkl      # æ¨¡å‹æ–‡ä»¶
â”‚   â””â”€â”€ best_model_20250120_143025.txt      # LightGBM åŸç”Ÿæ ¼å¼
â”‚
â”œâ”€â”€ plots/
â”‚   â”œâ”€â”€ final_roc_pr_curves.png             # ROC & PR æ›²çº¿
â”‚   â”œâ”€â”€ final_confusion_matrix.png          # æ··æ·†çŸ©é˜µ
â”‚   â”œâ”€â”€ final_calibration_curve.png         # æ¦‚ç‡æ ¡å‡†æ›²çº¿
â”‚   â”œâ”€â”€ final_shap_summary.png              # SHAP æ±‡æ€»å›¾
â”‚   â”œâ”€â”€ final_shap_importance.png           # SHAP é‡è¦æ€§
â”‚   â””â”€â”€ feature_dendrogram.png              # ç‰¹å¾èšç±»æ ‘çŠ¶å›¾
â”‚
â”œâ”€â”€ feature_importance.csv                  # ç‰¹å¾é‡è¦æ€§
â””â”€â”€ optuna_study.csv                        # Optuna ä¼˜åŒ–å†å²
```

---

## ğŸ”¬ æ ¸å¿ƒç»„ä»¶è¯¦è§£

### 1. PurgedKFold éªŒè¯å™¨

**é—®é¢˜**: ä¼ ç»Ÿ K-Fold ä¼šå¯¼è‡´ä¿¡æ¯æ³„æ¼
- Triple Barrier æ ‡ç­¾æŒç»­ 5 å¤©
- è®­ç»ƒé›†çš„æœ€åä¸€å¤©å’Œæµ‹è¯•é›†çš„ç¬¬ä¸€å¤©å¯èƒ½é‡å 

**è§£å†³æ–¹æ¡ˆ**:
```python
from src.models.validation import PurgedKFold

pkf = PurgedKFold(
    n_splits=5,
    embargo_pct=0.01,  # ç¦è¿ 1% æ•°æ®
    purge_overlap=True  # å¯ç”¨æ¸…é™¤æœºåˆ¶
)

for train_idx, test_idx in pkf.split(X, y, event_ends):
    # è®­ç»ƒé›†å’Œæµ‹è¯•é›†å®Œå…¨æ— æ³„æ¼
    pass
```

**å…³é”®æœºåˆ¶**:
1. **Purging (æ¸…é™¤)**: åˆ é™¤è®­ç»ƒé›†ä¸­ä¸æµ‹è¯•é›†æ ‡ç­¾çª—å£é‡å çš„æ ·æœ¬
2. **Embargoing (ç¦è¿)**: åœ¨æµ‹è¯•é›†åé¢å¤–åˆ é™¤ 1% æ•°æ®,æ¶ˆé™¤åºåˆ—ç›¸å…³æ€§

### 2. ç‰¹å¾èšç±»å»å™ª

**é—®é¢˜**: 75 ç»´ç‰¹å¾ä¸­å­˜åœ¨é«˜å…±çº¿æ€§
- `ema_20` å’Œ `sma_20` é«˜åº¦ç›¸å…³
- ç‰¹å¾é‡è¦æ€§è¢«ç¨€é‡Š (Substitution Effect)

**è§£å†³æ–¹æ¡ˆ**:
```python
from src.models.feature_selection import FeatureClusterer

clusterer = FeatureClusterer(correlation_threshold=0.7)
clusterer.fit(X)

# æŸ¥çœ‹èšç±»ç»“æœ
for cluster_id, features in clusterer.clusters.items():
    print(f"ç¾¤ç»„ {cluster_id}: {features}")

# ç»˜åˆ¶æ ‘çŠ¶å›¾
clusterer.plot_dendrogram(
    feature_names,
    output_path='feature_dendrogram.png'
)
```

**æ•ˆæœ**: å°† 75 ç»´ç‰¹å¾å‹ç¼©è‡³ 30-40 ç»´,ä¿ç•™å…³é”®ä¿¡æ¯

### 3. Optuna è¶…å‚æ•°ä¼˜åŒ–

**æœç´¢ç©ºé—´**:
```python
{
    'num_leaves': [20, 150],
    'learning_rate': [0.01, 0.3],  # log scale
    'feature_fraction': [0.5, 1.0],
    'bagging_fraction': [0.5, 1.0],
    'lambda_l1': [1e-8, 10.0],     # log scale
    'lambda_l2': [1e-8, 10.0],     # log scale
    'min_child_samples': [5, 100],
    'max_depth': [3, 12]
}
```

**ä½¿ç”¨æ–¹å¼**:
```python
from src.models.trainer import OptunaOptimizer

optimizer = OptunaOptimizer(n_trials=100, direction='maximize')
best_params = optimizer.optimize(
    X_train, y_train, X_val, y_val,
    sample_weight_train, sample_weight_val,
    metric='f1'
)
```

### 4. æ¨¡å‹è¯„ä¼°

**è¯„ä¼°æŒ‡æ ‡**:
```python
from src.models.evaluator import ModelEvaluator

evaluator = ModelEvaluator(output_dir='outputs/plots')
metrics = evaluator.evaluate(y_true, y_pred, y_pred_proba, prefix='final')

# è¾“å‡º:
# - accuracy
# - f1_score
# - precision / recall
# - auc_roc
# - log_loss
```

**å¯è§†åŒ–**:
- **ROC/PR æ›²çº¿**: è¯„ä¼°åˆ†ç±»æ€§èƒ½
- **æ··æ·†çŸ©é˜µ**: æŸ¥çœ‹è¯¯åˆ¤æƒ…å†µ
- **æ¦‚ç‡æ ¡å‡†æ›²çº¿**: æ£€æŸ¥æ¨¡å‹ç½®ä¿¡åº¦æ˜¯å¦å¯é 
- **SHAP åˆ†æ**: è§£é‡Šæ¯ä¸ªç‰¹å¾çš„è´¡çŒ®

---

## âš™ï¸ é«˜çº§é…ç½®

### è‡ªå®šä¹‰è¶…å‚æ•°

ç¼–è¾‘ `src/models/trainer.py` çš„ `_get_default_params()`:

```python
def _get_default_params() -> Dict[str, Any]:
    return {
        'objective': 'binary',
        'metric': 'binary_logloss',
        'num_leaves': 31,           # è°ƒæ•´å¤æ‚åº¦
        'learning_rate': 0.05,      # é™ä½å­¦ä¹ ç‡æå‡æ³›åŒ–
        'feature_fraction': 0.8,    # éšæœºç‰¹å¾æ¯”ä¾‹
        'bagging_fraction': 0.8,    # éšæœºæ ·æœ¬æ¯”ä¾‹
        'lambda_l1': 0.1,           # L1 æ­£åˆ™åŒ–
        'lambda_l2': 0.1,           # L2 æ­£åˆ™åŒ–
        'min_child_samples': 20,    # å¶å­æœ€å°æ ·æœ¬æ•°
    }
```

### ä½¿ç”¨ WalkForward éªŒè¯

ä»£ç ç¤ºä¾‹ (éœ€æ‰‹åŠ¨è°ƒç”¨):

```python
from src.models.validation import WalkForwardValidator

wfv = WalkForwardValidator(
    train_period_days=730,  # 2å¹´è®­ç»ƒçª—å£
    test_period_days=90,    # 3ä¸ªæœˆæµ‹è¯•çª—å£
    step_days=90            # æ»šåŠ¨æ­¥é•¿
)

for fold, (train_idx, test_idx) in enumerate(wfv.split(X, y), 1):
    print(f"Fold {fold}: è®­ç»ƒé›† {len(train_idx)}, æµ‹è¯•é›† {len(test_idx)}")
    # è®­ç»ƒå’Œè¯„ä¼°...
```

### ä½¿ç”¨ MDA ç‰¹å¾é‡è¦æ€§

æ¯” LightGBM å†…ç½®çš„ split/gain æ›´å‡†ç¡®:

```python
from src.models.feature_selection import MDFeatureImportance

importance = MDFeatureImportance.compute_importance(
    model, X_val, y_val,
    n_repeats=5,
    scoring='accuracy'
)

MDFeatureImportance.plot_importance(
    importance,
    top_n=20,
    output_path='mda_importance.png'
)
```

---

## ğŸ“ è®­ç»ƒæ—¥å¿—ç¤ºä¾‹

```
2025-01-20 14:30:25 - INFO - åŠ è½½æ•°æ®: /opt/mt5-crs/data/features/combined_features.parquet
2025-01-20 14:30:26 - INFO - æ•°æ®åŠ è½½å®Œæˆ: (5000, 78)
2025-01-20 14:30:26 - INFO - ç‰¹å¾æ•°é‡: 75
2025-01-20 14:30:26 - INFO - æ ‡ç­¾åˆ†å¸ƒ:
1    2580
0    2420
Name: label, dtype: int64

============================================================
ç‰¹å¾èšç±»ä¸é€‰æ‹©
============================================================
2025-01-20 14:30:27 - INFO - å¼€å§‹ç‰¹å¾èšç±»: 75 ä¸ªç‰¹å¾
2025-01-20 14:30:28 - INFO - èšç±»å®Œæˆ: å‘ç° 35 ä¸ªç‰¹å¾ç¾¤ç»„
2025-01-20 14:30:28 - INFO - ç‰¹å¾é€‰æ‹©å®Œæˆ: 75 -> 35

============================================================
PurgedKFold è®­ç»ƒ (5 æŠ˜)
============================================================
2025-01-20 14:30:30 - INFO - Fold 1/5: è®­ç»ƒé›† 0 æ ·æœ¬, æµ‹è¯•é›† 1000 æ ·æœ¬
2025-01-20 14:30:35 - INFO - Fold 1 F1-Score: 0.7234

2025-01-20 14:30:40 - INFO - Fold 2/5: è®­ç»ƒé›† 1000 æ ·æœ¬, æµ‹è¯•é›† 1000 æ ·æœ¬
2025-01-20 14:30:45 - INFO - Fold 2 F1-Score: 0.7456

...

2025-01-20 14:35:20 - INFO - å¹³å‡ F1-Score: 0.7389 Â± 0.0123

============================================================
æ¨¡å‹è¯„ä¼°
============================================================
2025-01-20 14:35:25 - INFO - è¯„ä¼°æŒ‡æ ‡:
2025-01-20 14:35:25 - INFO -   accuracy: 0.7420
2025-01-20 14:35:25 - INFO -   f1_score: 0.7389
2025-01-20 14:35:25 - INFO -   auc_roc: 0.8156
2025-01-20 14:35:25 - INFO -   log_loss: 0.5234

2025-01-20 14:35:30 - INFO - ROC/PR æ›²çº¿å·²ä¿å­˜
2025-01-20 14:35:35 - INFO - SHAP æ±‡æ€»å›¾å·²ä¿å­˜

2025-01-20 14:35:40 - INFO - æ¨¡å‹å·²ä¿å­˜: outputs/models/best_model_20250120_143540.pkl

============================================================
è®­ç»ƒå®Œæˆ! ğŸ‰
============================================================
```

---

## ğŸ§ª æµ‹è¯•

è¿è¡Œå•å…ƒæµ‹è¯•:

```bash
# è¿è¡Œæ‰€æœ‰æµ‹è¯•
pytest tests/models/test_models.py -v

# è¿è¡Œç‰¹å®šæµ‹è¯•
pytest tests/models/test_models.py::TestPurgedKFold::test_basic_split -v

# æŸ¥çœ‹è¦†ç›–ç‡
pytest tests/models/test_models.py --cov=src.models --cov-report=html
```

**æµ‹è¯•è¦†ç›–**:
- âœ… PurgedKFold éªŒè¯å™¨ (2 ä¸ªæµ‹è¯•)
- âœ… WalkForwardValidator (2 ä¸ªæµ‹è¯•)
- âœ… FeatureClusterer (2 ä¸ªæµ‹è¯•)
- âœ… LightGBM è®­ç»ƒå™¨ (3 ä¸ªæµ‹è¯•)
- âœ… ModelEvaluator (2 ä¸ªæµ‹è¯•)

**æµ‹è¯•ç»“æœ**: 11/11 é€šè¿‡ âœ…

---

## ğŸ¯ æœ€ä½³å®è·µ

### 1. ç‰¹å¾å·¥ç¨‹ä¼˜å…ˆ

åœ¨è®­ç»ƒå‰ç¡®ä¿:
- âœ… å‰”é™¤åŸå§‹ä»·æ ¼åˆ— (`close`, `open`, `high`, `low`)
- âœ… ä½¿ç”¨åˆ†æ•°å·®åˆ†åçš„ç‰¹å¾ (`frac_diff_close`)
- âœ… ç¡®ä¿ç‰¹å¾å¹³ç¨³æ€§ (ADF æ£€éªŒ)
- âœ… æ ·æœ¬æƒé‡æ­£ç¡®è®¡ç®—

### 2. éªŒè¯ç­–ç•¥é€‰æ‹©

| åœºæ™¯ | æ¨èéªŒè¯æ–¹æ³• | åŸå›  |
|------|--------------|------|
| å¿«é€Ÿå®éªŒ | PurgedKFold (3-5æŠ˜) | å¿«é€Ÿè¯„ä¼°æ¨¡å‹æ€§èƒ½ |
| è¶…å‚æ•°ä¼˜åŒ– | ç®€å•åˆ†å‰² (80/20) | Optuna ä¼šè·‘å¾ˆå¤šæ¬¡,å¤ªæ…¢ |
| æœ€ç»ˆè¯„ä¼° | WalkForward | æœ€æ¥è¿‘å®ç›˜è¡¨ç° |
| æ¨¡å‹é€‰æ‹© | PurgedKFold (10æŠ˜) | æ›´ç¨³å®šçš„æ€§èƒ½ä¼°è®¡ |

### 3. è¶…å‚æ•°è°ƒä¼˜å»ºè®®

**Optuna è¯•éªŒæ¬¡æ•°**:
- åˆæ­¥æ¢ç´¢: 20-50 trials
- ç²¾ç»†è°ƒä¼˜: 100-200 trials
- æé™æ€§èƒ½: 500+ trials (å¯èƒ½è¿‡æ‹Ÿåˆ)

**Early Stopping**:
- è®­ç»ƒé›†: 50 rounds (é˜²æ­¢è¿‡æ‹Ÿåˆ)
- ä¼˜åŒ–æ—¶: 30 rounds (åŠ é€Ÿæœç´¢)

### 4. æ¨¡å‹è§£é‡Š

**å¿…é¡»æ£€æŸ¥**:
1. **Top 5 é‡è¦ç‰¹å¾** æ˜¯å¦ç¬¦åˆé‡‘èç›´è§‰
   - ç¤ºä¾‹: RSIã€æ³¢åŠ¨ç‡ã€åŠ¨é‡æŒ‡æ ‡åº”è¯¥æ’å‰åˆ—
2. **SHAP å€¼** çš„æ–¹å‘æ˜¯å¦åˆç†
   - ç¤ºä¾‹: é«˜ RSI â†’ æ­£ SHAP (çœ‹æ¶¨)
3. **æ¦‚ç‡æ ¡å‡†** æ˜¯å¦æ¥è¿‘å¯¹è§’çº¿
   - å¦‚æœåç¦»ä¸¥é‡,è€ƒè™‘ Platt Scaling æˆ– Isotonic Regression

---

## âš ï¸ å¸¸è§é—®é¢˜

### Q1: è®­ç»ƒé›†ç¬¬ä¸€ä¸ª fold ä¸ºç©º?

**åŸå› **: PurgedKFold çš„ç¬¬ä¸€ä¸ª fold è®­ç»ƒé›†ç¡®å®å¯èƒ½ä¸ºç©º (è¿™æ˜¯é¢„æœŸè¡Œä¸º)

**è§£å†³**: è·³è¿‡ç¬¬ä¸€ä¸ª fold æˆ–ä½¿ç”¨æ›´å¤š folds

### Q2: F1-Score åªæœ‰ 0.5?

**å¯èƒ½åŸå› **:
1. ç‰¹å¾æ²¡æœ‰å¹³ç¨³åŒ– (æ£€æŸ¥æ˜¯å¦ç”¨äº†åŸå§‹ä»·æ ¼)
2. æ ‡ç­¾è´¨é‡å·® (æ£€æŸ¥ Triple Barrier å‚æ•°)
3. æ ·æœ¬ä¸å¹³è¡¡ (æ£€æŸ¥æ ‡ç­¾åˆ†å¸ƒ)
4. æ•°æ®æ³„æ¼ (ç¡®ä¿æœªä½¿ç”¨æœªæ¥ä¿¡æ¯)

### Q3: Optuna ä¼˜åŒ–å¾ˆæ…¢?

**ä¼˜åŒ–å»ºè®®**:
1. å‡å°‘ `num_boost_round` (500 â†’ 200)
2. ä½¿ç”¨æ›´å°çš„æ•°æ®é›† (å…ˆ sample 10%)
3. å‡å°‘ `early_stopping_rounds` (50 â†’ 20)
4. å¹¶è¡Œä¼˜åŒ– (Optuna æ”¯æŒåˆ†å¸ƒå¼)

### Q4: SHAP åˆ†ææŠ¥é”™?

**è§£å†³æ–¹æ¡ˆ**:
```bash
pip install shap

# å¦‚æœè¿˜æŠ¥é”™,å°è¯•:
pip install shap --no-cache-dir
```

**æ›¿ä»£æ–¹æ¡ˆ**: ä½¿ç”¨ LightGBM å†…ç½®çš„ç‰¹å¾é‡è¦æ€§:
```python
importance = trainer.get_feature_importance(importance_type='gain')
```

---

## ğŸ“š å‚è€ƒæ–‡çŒ®

1. **Advances in Financial Machine Learning**
   Marcos Lopez de Prado (2018)
   Chapter 7: Cross-Validation in Finance
   Chapter 8: Feature Importance

2. **Machine Learning for Asset Managers**
   Marcos Lopez de Prado (2020)
   Chapter 4: Feature Selection

3. **Kaggle é‡‘èç±»ç«èµ›å† å†›æ–¹æ¡ˆ**:
   - G-Research Crypto Forecasting
   - Ubiquant Market Prediction
   - Jane Street Market Prediction

4. **Optuna å®˜æ–¹æ–‡æ¡£**:
   https://optuna.readthedocs.io/

5. **LightGBM å®˜æ–¹æ–‡æ¡£**:
   https://lightgbm.readthedocs.io/

---

## ğŸš€ ä¸‹ä¸€æ­¥

å®Œæˆ #009 å·¥å•å,å»ºè®®:

1. **#010: ç­–ç•¥å›æµ‹ä¸é£é™©ç®¡ç†**
   - å°†æ¨¡å‹é›†æˆåˆ°äº¤æ˜“ç­–ç•¥
   - å®ç°ä»“ä½ç®¡ç†å’Œé£é™©æ§åˆ¶
   - Backtrader æˆ– VectorBT å›æµ‹

2. **#011: å®æ—¶æ¨ç†æœåŠ¡**
   - FastAPI REST API
   - WebSocket å®æ—¶æ¨é€
   - æ¨¡å‹ç‰ˆæœ¬ç®¡ç†

3. **#012: æ¨¡å‹ç›‘æ§ä¸ A/B æµ‹è¯•**
   - ç›‘æ§æ¨¡å‹æ€§èƒ½è¡°å‡
   - å¤šæ¨¡å‹ Ensemble
   - åœ¨çº¿å­¦ä¹ ä¸æ¨¡å‹æ›´æ–°

---

**ç¥ä½ è®­ç»ƒé¡ºåˆ©! ğŸ‰**

å¦‚æœ‰é—®é¢˜,è¯·æŸ¥é˜…æºä»£ç æ³¨é‡Šæˆ–è”ç³»å›¢é˜Ÿã€‚

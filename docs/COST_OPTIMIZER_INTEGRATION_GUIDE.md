# AIå®¡æŸ¥æˆæœ¬ä¼˜åŒ–å™¨ - é›†æˆæŒ‡å—

**æ–‡æ¡£ç‰ˆæœ¬**: v1.0
**åˆ›å»ºæ—¶é—´**: 2026-01-14
**é€‚ç”¨èŒƒå›´**: unified_review_gate.py, gemini_review_bridge.py

---

## ğŸ“‹ å¿«é€Ÿå¼€å§‹

### æ–¹æ¡ˆ A: åœ¨ unified_review_gate.py ä¸­é›†æˆ

```python
# scripts/ai_governance/unified_review_gate.py

from cost_optimizer import AIReviewCostOptimizer
from review_batcher import ReviewBatch

class UnifiedReviewGate:
    def __init__(self):
        # ... ç°æœ‰åˆå§‹åŒ–ä»£ç  ...

        # æ–°å¢: åˆå§‹åŒ–æˆæœ¬ä¼˜åŒ–å™¨
        self.optimizer = AIReviewCostOptimizer(
            enable_cache=True,
            enable_batch=True,
            enable_routing=True,
            cache_dir=".cache/ai_review_cache",
            log_file="ai_review_optimizer.log"
        )

    def execute_review(self, target_files, risk_mode=None):
        """ä½¿ç”¨ä¼˜åŒ–å™¨æ‰§è¡Œå®¡æŸ¥"""

        # å®šä¹‰APIè°ƒç”¨åŒ…è£…å™¨
        def api_caller(batch: ReviewBatch):
            results = {}

            # åˆ¤æ–­ä½¿ç”¨å“ªä¸ªå¼•æ“
            use_claude = (batch.risk_level == "high")

            # ç”Ÿæˆæç¤ºè¯­
            prompt = self.optimizer.batcher.format_batch_prompt(
                batch,
                use_claude=use_claude
            )

            # è°ƒç”¨API
            success, response, metadata = self.call_ai_api(
                prompt,
                is_high_risk=(batch.risk_level == "high"),
                use_claude=use_claude
            )

            if success:
                # è§£ææ‰¹å¤„ç†ç»“æœ
                results = self.optimizer.batcher.parse_batch_result(
                    batch,
                    response
                )

            return results

        # ä½¿ç”¨ä¼˜åŒ–å™¨å¤„ç†æ‰€æœ‰æ–‡ä»¶
        review_results, stats = self.optimizer.process_files(
            target_files,
            api_caller=api_caller,
            risk_detector=self.detect_risk_level,
            force_refresh=False  # ä½¿ç”¨ç¼“å­˜
        )

        # è¿”å›ç»“æœ
        return review_results, stats
```

### æ–¹æ¡ˆ B: åœ¨ gemini_review_bridge.py ä¸­é›†æˆ

```python
# scripts/ai_governance/gemini_review_bridge.py

from cost_optimizer import AIReviewCostOptimizer

def main():
    # ... ç°æœ‰ä»£ç  ...

    # åˆå§‹åŒ–ä¼˜åŒ–å™¨
    optimizer = AIReviewCostOptimizer(
        enable_cache=True,
        enable_batch=True,
        cache_dir=".cache/gemini_review_cache"
    )

    # å®šä¹‰APIè°ƒç”¨å‡½æ•°
    def ai_review_caller(batch):
        """è°ƒç”¨å¤–éƒ¨AIè¿›è¡Œæ‰¹é‡å®¡æŸ¥"""
        prompt = optimizer.batcher.format_batch_prompt(batch)

        resp = requests.post(
            f"{GEMINI_BASE_URL}/chat/completions",
            headers={"Authorization": f"Bearer {GEMINI_API_KEY}"},
            json={
                "model": GEMINI_MODEL,
                "messages": [{"role": "user", "content": prompt}],
                "temperature": 0.3
            },
            impersonate="chrome110",
            timeout=GEMINI_API_TIMEOUT
        )

        if resp.status_code == 200:
            content = resp.json()['choices'][0]['message']['content']
            return optimizer.batcher.parse_batch_result(batch, content)
        return {}

    # å¤„ç†æ–‡ä»¶
    if audit_mode == "INCREMENTAL":
        files_to_review = [f for f in diff_files if should_review(f)]
    else:
        files_to_review = FORCE_AUDIT_TARGETS

    results, stats = optimizer.process_files(
        files_to_review,
        api_caller=ai_review_caller
    )

    # æŠ¥å‘Šæˆæœ¬èŠ‚çœ
    print(f"âœ… API calls reduced by {stats['cost_reduction_rate']:.1%}")
```

---

## ğŸ¯ é›†æˆæ£€æŸ¥æ¸…å•

### æ­¥éª¤ 1: å¯¼å…¥æ¨¡å—
```python
from scripts.ai_governance.cost_optimizer import AIReviewCostOptimizer
from scripts.ai_governance.review_batcher import ReviewBatcher
from scripts.ai_governance.review_cache import ReviewCache
```

### æ­¥éª¤ 2: åˆå§‹åŒ–ä¼˜åŒ–å™¨
```python
optimizer = AIReviewCostOptimizer(
    enable_cache=True,           # å¯ç”¨å¤šçº§ç¼“å­˜
    enable_batch=True,           # å¯ç”¨æ‰¹å¤„ç†
    enable_routing=True,         # å¯ç”¨æ™ºèƒ½è·¯ç”±
    cache_dir=".cache/...",      # ç¼“å­˜ç›®å½•
    log_file="optimizer.log"     # æ—¥å¿—æ–‡ä»¶
)
```

### æ­¥éª¤ 3: å®šä¹‰APIè°ƒç”¨å‡½æ•°
```python
def my_api_caller(batch):
    """
    å¿…é¡»æ¥æ”¶ ReviewBatch å¯¹è±¡
    å¿…é¡»è¿”å› {filepath: {result_data}} çš„å­—å…¸
    """
    # 1. æ ¹æ® batch.risk_level é€‰æ‹©æ¨¡å‹
    use_claude = (batch.risk_level == "high")

    # 2. ä½¿ç”¨ batcher.format_batch_prompt ç”Ÿæˆæç¤º
    prompt = optimizer.batcher.format_batch_prompt(batch, use_claude)

    # 3. è°ƒç”¨å®é™…çš„API
    api_response = call_your_api(prompt, use_claude)

    # 4. ä½¿ç”¨ batcher.parse_batch_result åˆ†å‰²ç»“æœ
    results = optimizer.batcher.parse_batch_result(batch, api_response)

    return results
```

### æ­¥éª¤ 4: å¤„ç†æ–‡ä»¶
```python
files = ["file1.py", "file2.py", "file3.py"]

results, stats = optimizer.process_files(
    files,
    api_caller=my_api_caller,
    risk_detector=my_risk_detector,  # å¯é€‰
    force_refresh=False               # ä½¿ç”¨ç¼“å­˜
)

# æŸ¥çœ‹æˆæœ¬èŠ‚çœ
print(f"Cost reduction: {stats['cost_reduction_rate']:.1%}")
print(f"API calls: {stats['api_calls']}")
print(f"Cached files: {stats['cached_files']}")
```

### æ­¥éª¤ 5: æ¸…ç†å’Œç»´æŠ¤
```python
# æŸ¥çœ‹ç¼“å­˜ç»Ÿè®¡
cache_stats = optimizer.get_cache_stats()
print(cache_stats)

# æ¸…ç†è¿‡æœŸç¼“å­˜
expired = optimizer.cleanup_expired_cache()
print(f"Cleaned up {expired} expired entries")

# å®Œå…¨æ¸…é™¤ç¼“å­˜ï¼ˆæµ‹è¯•ç”¨ï¼‰
optimizer.clear_cache()
```

---

## ğŸ“Š æ€§èƒ½æŒ‡æ ‡ç›‘æ§

### å…³é”®æŒ‡æ ‡
```python
stats = {
    'total_files': 20,              # æ€»æ–‡ä»¶æ•°
    'cached_files': 15,             # ä½¿ç”¨ç¼“å­˜çš„æ–‡ä»¶
    'uncached_files': 5,            # éœ€è¦APIè°ƒç”¨çš„æ–‡ä»¶
    'api_calls': 1,                 # å®é™…APIè°ƒç”¨æ¬¡æ•°
    'token_saved': 5000,            # ä¼°ç®—èŠ‚çœçš„Token
    'cost_reduction_rate': 0.95,    # æˆæœ¬èŠ‚çœæ¯”ä¾‹ (95%)
}
```

### ç›‘æ§ä»£ç 
```python
def log_optimization_metrics(stats):
    """è®°å½•ä¼˜åŒ–æŒ‡æ ‡"""
    print(f"""
    ğŸ“Š Optimization Metrics:
    â”œâ”€ Total files: {stats['total_files']}
    â”œâ”€ Cached: {stats['cached_files']} ({stats['cached_files']/stats['total_files']*100:.1f}%)
    â”œâ”€ API calls: {stats['api_calls']}
    â”œâ”€ Baseline calls: {stats['total_files']}
    â”œâ”€ API calls reduction: {(1 - stats['api_calls']/stats['total_files'])*100:.1f}%
    â””â”€ Cost reduction rate: {stats['cost_reduction_rate']:.1%}
    """)
```

---

## ğŸ”§ é…ç½®å‚æ•°è¯´æ˜

### AIReviewCostOptimizer å‚æ•°

| å‚æ•° | ç±»å‹ | é»˜è®¤å€¼ | è¯´æ˜ |
|------|------|--------|------|
| enable_cache | bool | True | å¯ç”¨å¤šçº§ç¼“å­˜ |
| enable_batch | bool | True | å¯ç”¨æ‰¹å¤„ç† |
| enable_routing | bool | True | å¯ç”¨æ™ºèƒ½è·¯ç”± |
| cache_dir | str | `.cache/ai_review_cache` | ç¼“å­˜ç›®å½• |
| log_file | str | `cost_optimizer.log` | æ—¥å¿—æ–‡ä»¶ |

### ReviewBatcher å‚æ•°

| å‚æ•° | ç±»å‹ | é»˜è®¤å€¼ | è¯´æ˜ |
|------|------|--------|------|
| max_batch_size | int | 10 | æœ€å¤§æ‰¹å¤„ç†æ–‡ä»¶æ•° |
| max_tokens_per_batch | int | 100000 | å•æ‰¹æœ€å¤§Tokenæ•° |

### ReviewCache å‚æ•°

| å‚æ•° | ç±»å‹ | é»˜è®¤å€¼ | è¯´æ˜ |
|------|------|--------|------|
| cache_dir | str | `.cache/ai_review_cache` | ç¼“å­˜ç›®å½• |
| ttl_hours | int | 24 | ç¼“å­˜ç”Ÿå­˜æ—¶é—´(å°æ—¶) |

---

## âš¡ æ€§èƒ½ä¼˜åŒ–å»ºè®®

### 1. é«˜åååœºæ™¯
```python
# å¢å¤§æ‰¹å¤„ç†å¤§å°ä»¥å‡å°‘APIè°ƒç”¨
optimizer = AIReviewCostOptimizer()
optimizer.batcher.max_batch_size = 20  # æœ€å¤š20ä¸ªæ–‡ä»¶/æ‰¹
```

### 2. å®æ—¶å®¡æŸ¥åœºæ™¯
```python
# é™ä½ç¼“å­˜TTLä»¥è·å¾—æœ€æ–°å®¡æŸ¥
cache = ReviewCache(cache_dir="...", ttl_hours=1)
```

### 3. ç¦»çº¿å¤„ç†
```python
# å¯ç”¨åå°å¼‚æ­¥å¤„ç†å’Œæˆæœ¬ç›‘æ§
optimizer.process_files(
    files,
    api_caller=async_api_caller,
    force_refresh=False
)
# ç»“æœç¨ååœ¨ç¼“å­˜ä¸­å¯ç”¨
```

---

## ğŸ› æ•…éšœæ’æŸ¥

### é—®é¢˜ 1: ç¼“å­˜æœªç”Ÿæ•ˆ
```python
# æ£€æŸ¥ç¼“å­˜ç»Ÿè®¡
stats = optimizer.get_cache_stats()
if stats['disk_cache_entries'] == 0:
    print("âš ï¸  No cached entries")

# æ£€æŸ¥ç¼“å­˜ç›®å½•
import os
if not os.path.exists(stats['cache_dir']):
    print("âš ï¸  Cache directory not created")
```

### é—®é¢˜ 2: æ‰¹å¤„ç†å¤§å°ä¸åˆé€‚
```python
# ç›‘æ§å•ä¸ªæ‰¹æ¬¡çš„å¤§å°
for batch in batches:
    print(f"Batch {batch.batch_id}: {len(batch.files)} files, {batch.total_size} bytes")

    # è°ƒæ•´å¤§å°
    if batch.total_size > 50000:  # > 50KB
        optimizer.batcher.max_batch_size -= 2
```

### é—®é¢˜ 3: ç¼“å­˜è¿‡æœŸå¯¼è‡´é‡æ–°å®¡æŸ¥
```python
# æ¸…ç†å’Œé‡å»ºç¼“å­˜
expired_count = optimizer.cleanup_expired_cache()
print(f"Cleaned up {expired_count} expired entries")

# æˆ–è€…ç¦ç”¨TTL
cache = ReviewCache(cache_dir="...", ttl_hours=999)
```

---

## ğŸ“ˆ æˆæœ¬èŠ‚çœè®¡ç®—ç¤ºä¾‹

### æ— ä¼˜åŒ– (åŸºå‡†)
```
20 ä¸ªæ–‡ä»¶ = 20 æ¬¡ API è°ƒç”¨
æˆæœ¬: 20 Ã— $price_per_call
```

### ä»…ä½¿ç”¨ç¼“å­˜
```
æ–‡ä»¶ 1-10: ç¼“å­˜å‘½ä¸­ (0 è°ƒç”¨)
æ–‡ä»¶ 11-20: æ–°å¢ (10 è°ƒç”¨)
æˆæœ¬: 10 Ã— $price_per_call (-50%)
```

### ä»…ä½¿ç”¨æ‰¹å¤„ç†
```
20 ä¸ªæ–‡ä»¶ / 10 max_batch_size = 2 æ‰¹æ¬¡
2 Ã— $price_per_call
æˆæœ¬: 2 Ã— $price_per_call (-90%)
```

### åŒæ—¶ä½¿ç”¨ç¼“å­˜ + æ‰¹å¤„ç†
```
æ–‡ä»¶ 1-10: ç¼“å­˜å‘½ä¸­ (0 è°ƒç”¨)
æ–‡ä»¶ 11-20: æ‰¹å¤„ç† 1 æ‰¹ (1 è°ƒç”¨)
æ€»æˆæœ¬: 1 Ã— $price_per_call (-95%)
```

---

## âœ… éªŒè¯æ¸…å•

### é›†æˆå‰éªŒè¯
- [ ] æ‰€æœ‰ä¾èµ–æ¨¡å—å·²å¯¼å…¥
- [ ] ç¼“å­˜ç›®å½•å¯å†™
- [ ] APIè°ƒç”¨å‡½æ•°å·²å®šä¹‰
- [ ] æµ‹è¯•ç”¨ä¾‹é€šè¿‡

### é›†æˆåéªŒè¯
- [ ] ç¼“å­˜å‘½ä¸­ç‡ > 50%
- [ ] APIè°ƒç”¨æ¬¡æ•°å‡å°‘ > 80%
- [ ] å®¡æŸ¥ç»“æœå‡†ç¡®æ€§ä¸ä¸‹é™
- [ ] å“åº”æ—¶é—´å¯æ¥å—

### ç”Ÿäº§å‰éªŒè¯
- [ ] ç›‘æ§æˆæœ¬æŒ‡æ ‡
- [ ] ç›‘æ§ç¼“å­˜å¤§å°
- [ ] ç›‘æ§APIé”™è¯¯ç‡
- [ ] è´Ÿè½½æµ‹è¯•é€šè¿‡

---

## ğŸ“š å‚è€ƒæ–‡ä»¶

- å®ç°æ–‡ä»¶: `scripts/ai_governance/cost_optimizer.py`
- ç¼“å­˜å®ç°: `scripts/ai_governance/review_cache.py`
- æ‰¹å¤„ç†å®ç°: `scripts/ai_governance/review_batcher.py`
- æµ‹è¯•å¥—ä»¶: `scripts/ai_governance/test_cost_optimizer.py`
- ä¼˜åŒ–æ–¹æ¡ˆ: `docs/OPTIMIZATION_PLAN_AI_COST_REDUCTION.md`

---

## ğŸ“ æ”¯æŒ

é‡åˆ°é—®é¢˜ï¼Ÿ

1. æŸ¥çœ‹æµ‹è¯•ç¤ºä¾‹: `test_cost_optimizer.py`
2. æ£€æŸ¥æ—¥å¿—æ–‡ä»¶: `cost_optimizer.log`
3. è¿è¡Œæµ‹è¯•å¥—ä»¶: `python3 test_cost_optimizer.py`


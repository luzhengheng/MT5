# Task #099 éƒ¨ç½²åŒæ­¥æŒ‡å—
## ç¯å¢ƒé…ç½®ä¸å˜æ›´æ¸…å•

---

## ğŸ“‹ å˜æ›´æ¸…å•

### æ–°å¢æ–‡ä»¶

| æ–‡ä»¶è·¯å¾„ | ç±»å‹ | è¡Œæ•° | è¯´æ˜ |
|---------|------|------|------|
| `scripts/data/fusion_engine.py` | Python | 460 | FusionEngine æ ¸å¿ƒç±» |
| `scripts/audit_task_099.py` | Python | 475 | TDD å®¡è®¡å¥—ä»¶ |
| `docs/archive/tasks/TASK_099/COMPLETION_REPORT.md` | æ–‡æ¡£ | - | å®ŒæˆæŠ¥å‘Š |
| `docs/archive/tasks/TASK_099/QUICK_START.md` | æ–‡æ¡£ | - | å¿«é€Ÿå¯åŠ¨æŒ‡å— |
| `docs/archive/tasks/TASK_099/SYNC_GUIDE.md` | æ–‡æ¡£ | - | æœ¬æ–‡ä»¶ |

### ä¿®æ”¹æ–‡ä»¶

| æ–‡ä»¶è·¯å¾„ | å˜æ›´ | è¯´æ˜ |
|---------|------|------|
| `.gitignore` | +1 è¡Œ | æ–°å¢: `data/chroma/` |

---

## âš™ï¸ ç¯å¢ƒå˜é‡é…ç½®

### å¿…éœ€å˜é‡ (Database)

```bash
# TimescaleDB è¿æ¥å‚æ•°
POSTGRES_HOST=localhost
POSTGRES_PORT=5432
POSTGRES_USER=trader
POSTGRES_PASSWORD=password
POSTGRES_DB=mt5_crs
```

### å¯é€‰å˜é‡

```bash
# ChromaDB è·¯å¾„ (é»˜è®¤: ./data/chroma)
CHROMA_DB_PATH=./data/chroma

# æ—¥å¿—çº§åˆ« (é»˜è®¤: INFO)
LOG_LEVEL=INFO
```

### é…ç½®ä½ç½®

```bash
# æœ¬åœ° .env æ–‡ä»¶ (æ¨è)
cat > .env << 'EOF'
POSTGRES_HOST=localhost
POSTGRES_PORT=5432
POSTGRES_USER=trader
POSTGRES_PASSWORD=password
POSTGRES_DB=mt5_crs
EOF

# æˆ–ç³»ç»Ÿç¯å¢ƒå˜é‡
export POSTGRES_HOST=localhost
export POSTGRES_PORT=5432
...
```

---

## ğŸ“¦ ä¾èµ–ç®¡ç†

### Python ä¾èµ–

#### å·²æœ‰ä¾èµ– (æ— éœ€æ–°å¢)

```
pandas >= 1.3.0          # æ•°æ®å¤„ç†å’Œé‡é‡‡æ ·
numpy >= 1.20.0          # æ•°å€¼è®¡ç®—
psycopg2 >= 2.9.0        # PostgreSQL é©±åŠ¨
chromadb >= 0.3.0        # Vector DB å®¢æˆ·ç«¯
python-dotenv >= 0.19.0  # ç¯å¢ƒå˜é‡ç®¡ç†
```

#### éªŒè¯å®‰è£…

```bash
python3 << 'EOF'
import pandas as pd
import numpy as np
import psycopg2
import chromadb
from dotenv import load_dotenv

print("âœ… All dependencies installed")
print(f"  pandas: {pd.__version__}")
print(f"  numpy: {np.__version__}")
print(f"  psycopg2: {psycopg2.__version__}")
print(f"  chromadb: {chromadb.__version__}")
EOF
```

### æ•°æ®åº“ä¾èµ–

#### TimescaleDB è¡¨ç»“æ„ (éœ€ä¿è¯å­˜åœ¨)

```sql
-- å¸‚åœºæ•°æ®è¡¨ (åº”å·²å­˜åœ¨ï¼Œæ¥è‡ª Task #095/096)
CREATE TABLE IF NOT EXISTS market_data (
    timestamp TIMESTAMPTZ NOT NULL,
    symbol TEXT NOT NULL,
    open FLOAT8,
    high FLOAT8,
    low FLOAT8,
    close FLOAT8,
    volume FLOAT8,
    PRIMARY KEY (timestamp, symbol)
);

CREATE INDEX ON market_data (symbol, timestamp DESC);

-- å¸‚åœºç‰¹å¾è¡¨ (åº”å·²å­˜åœ¨ï¼Œæ¥è‡ª Task #096)
CREATE TABLE IF NOT EXISTS market_features (
    timestamp TIMESTAMPTZ NOT NULL,
    symbol TEXT NOT NULL,
    rsi_14 FLOAT8,
    macd FLOAT8,
    macd_signal FLOAT8,
    PRIMARY KEY (timestamp, symbol)
);

CREATE INDEX ON market_features (symbol, timestamp DESC);
```

#### ChromaDB é›†åˆ (éœ€ä¿è¯å­˜åœ¨)

```python
# ChromaDB é›†åˆç»“æ„ (åº”å·²å­˜åœ¨ï¼Œæ¥è‡ª Task #097/098)
from scripts.data.vector_client import VectorClient

client = VectorClient()
collection = client.ensure_collection(
    name="financial_news",
    metadata={"task": "098"}
)

# æ£€æŸ¥é›†åˆæ˜¯å¦åŒ…å«æ•°æ®
print(f"Documents in collection: {collection.count()}")
```

---

## ğŸš€ éƒ¨ç½²æ­¥éª¤

### ç¬¬ 1 æ­¥: ä»£ç åŒæ­¥

```bash
# 1. ä» git è·å–æœ€æ–°ä»£ç 
cd /opt/mt5-crs
git pull origin main

# 2. éªŒè¯æ–°æ–‡ä»¶
ls -la scripts/data/fusion_engine.py
ls -la scripts/audit_task_099.py
```

### ç¬¬ 2 æ­¥: ç¯å¢ƒéªŒè¯

```bash
# 1. æ£€æŸ¥ Python ç‰ˆæœ¬ (è¦æ±‚ >= 3.8)
python3 --version

# 2. æ£€æŸ¥ä¾èµ–
python3 << 'EOF'
import sys
print(f"Python: {sys.version}")

required = ['pandas', 'numpy', 'psycopg2', 'chromadb', 'dotenv']
for pkg in required:
    try:
        __import__(pkg)
        print(f"âœ… {pkg}")
    except ImportError:
        print(f"âŒ {pkg} (missing)")
EOF

# 3. æ£€æŸ¥ç¯å¢ƒå˜é‡
python3 << 'EOF'
import os
from pathlib import Path
from dotenv import load_dotenv

# å°è¯•åŠ è½½ .env
env_file = Path('.') / '.env'
if env_file.exists():
    load_dotenv(env_file)
    print("âœ… .env file loaded")
else:
    print("âš ï¸  .env file not found, using system environment")

# éªŒè¯å…³é”®å˜é‡
required_vars = [
    'POSTGRES_HOST',
    'POSTGRES_PORT',
    'POSTGRES_USER',
    'POSTGRES_PASSWORD',
    'POSTGRES_DB'
]

for var in required_vars:
    value = os.getenv(var, 'NOT SET')
    status = "âœ…" if value != 'NOT SET' else "âŒ"
    print(f"{status} {var}")
EOF
```

### ç¬¬ 3 æ­¥: æ•°æ®åº“éªŒè¯

```bash
# 1. æ£€æŸ¥ TimescaleDB è¿æ¥
python3 << 'EOF'
import psycopg2
import os
from dotenv import load_dotenv

load_dotenv()

try:
    conn = psycopg2.connect(
        host=os.getenv('POSTGRES_HOST', 'localhost'),
        port=int(os.getenv('POSTGRES_PORT', 5432)),
        user=os.getenv('POSTGRES_USER', 'trader'),
        password=os.getenv('POSTGRES_PASSWORD', 'password'),
        database=os.getenv('POSTGRES_DB', 'mt5_crs')
    )
    cur = conn.cursor()

    # æ£€æŸ¥è¡¨
    cur.execute("""
        SELECT tablename FROM pg_tables
        WHERE schemaname='public' AND tablename IN ('market_data', 'market_features')
    """)
    tables = [row[0] for row in cur.fetchall()]
    print(f"âœ… TimescaleDB tables: {tables}")

    # æ£€æŸ¥æ•°æ®
    cur.execute("SELECT COUNT(*) FROM market_data")
    count = cur.fetchone()[0]
    print(f"âœ… market_data rows: {count}")

    cur.close()
    conn.close()
except Exception as e:
    print(f"âŒ Connection error: {e}")
EOF

# 2. æ£€æŸ¥ ChromaDB
python3 << 'EOF'
from scripts.data.vector_client import VectorClient

try:
    client = VectorClient()
    collections = client.list_collections()
    print(f"âœ… ChromaDB collections: {collections}")

    if "financial_news" in collections:
        collection = client.ensure_collection("financial_news")
        print(f"âœ… financial_news documents: {collection.count()}")
except Exception as e:
    print(f"âŒ ChromaDB error: {e}")
EOF
```

### ç¬¬ 4 æ­¥: å•å…ƒæµ‹è¯•

```bash
# è¿è¡Œå®Œæ•´å®¡è®¡å¥—ä»¶
python3 scripts/audit_task_099.py

# é¢„æœŸè¾“å‡º:
# Ran 15 tests in ~5s
# âœ… ALL TESTS PASSED - Gate 1 APPROVED
```

### ç¬¬ 5 æ­¥: åŠŸèƒ½æµ‹è¯•

```bash
# æµ‹è¯•åŸºæœ¬èåˆ
python3 scripts/data/fusion_engine.py --symbol AAPL --days 3 --timeframe 1h

# æ£€æŸ¥è¾“å‡ºæ–‡ä»¶
ls -lh data/fused_AAPL.parquet

# éªŒè¯æ•°æ®è´¨é‡
python3 << 'EOF'
import pandas as pd
df = pd.read_parquet('data/fused_AAPL.parquet')
print(f"Shape: {df.shape}")
print(f"NaN count: {df.isna().sum().sum()}")
print(f"Sentiment range: [{df['sentiment_score'].min():.3f}, {df['sentiment_score'].max():.3f}]")
print("\nFirst 5 rows:")
print(df.head())
EOF
```

---

## ğŸ”„ Git å˜æ›´åŒæ­¥

### .gitignore æ›´æ–°

**æ–°å¢**:
```
data/chroma/
```

**å®Œæ•´æ›´æ–°æ­¥éª¤**:
```bash
# 1. æŸ¥çœ‹å½“å‰ .gitignore
cat .gitignore | grep -E "data/|\.parquet|\.db|\.pkl"

# 2. ç¡®è®¤ data/chroma/ å·²åŒ…å«
grep "data/chroma/" .gitignore

# 3. å¦‚æœæœ¬åœ°æ²¡æœ‰ chroma ç›®å½•çš„ç¼“å­˜ï¼Œæ¸…ç†
git rm -r --cached data/chroma/ 2>/dev/null || echo "Not cached"

# 4. ç¡®è®¤çŠ¶æ€
git status .gitignore
```

### æäº¤å’Œæ¨é€

```bash
# 1. æ£€æŸ¥å·®å¼‚
git diff

# 2. æ·»åŠ å˜æ›´
git add scripts/data/fusion_engine.py
git add scripts/audit_task_099.py
git add .gitignore
git add docs/archive/tasks/TASK_099/

# 3. æäº¤
git commit -m "feat(task-099): implement cross-domain data fusion engine

- Add FusionEngine class for time-series alignment
- Implement sentiment aggregation and forward-filling
- Add comprehensive TDD audit suite (15 tests, 100% coverage)
- Update .gitignore for ChromaDB persistence directory
- Include documentation: COMPLETION_REPORT, QUICK_START, SYNC_GUIDE

Co-Authored-By: Claude Sonnet 4.5 <noreply@anthropic.com>"

# 4. æ¨é€
git push origin main
```

---

## ğŸ“Š ç›‘æ§å’ŒéªŒè¯

### æ€§èƒ½ç›‘æ§

```bash
# 1. å¤„ç†é€Ÿåº¦åŸºå‡†
python3 << 'EOF'
import time
from scripts.data.fusion_engine import FusionEngine

engine = FusionEngine()

start = time.time()
fused_df = engine.get_fused_data('AAPL', days=7, timeframe='1h', save_parquet=False)
elapsed = time.time() - start

print(f"â±ï¸  Processing time: {elapsed:.2f}s")
print(f"ğŸ“Š Rows processed: {len(fused_df)}")
print(f"âš¡ Throughput: {len(fused_df)/elapsed:.0f} rows/sec")
EOF

# 2. å†…å­˜ä½¿ç”¨
python3 << 'EOF'
import psutil
import os

proc = psutil.Process(os.getpid())
mem_info = proc.memory_info()
print(f"Memory usage: {mem_info.rss / 1024 / 1024:.1f} MB")
EOF
```

### æ•°æ®è´¨é‡æ£€æŸ¥

```bash
# 1. æ£€æŸ¥èåˆå®Œæ•´æ€§
python3 << 'EOF'
import pandas as pd

df = pd.read_parquet('data/fused_AAPL.parquet')

checks = {
    'No NaN values': df.isna().sum().sum() == 0,
    'Sorted by timestamp': df.index.is_monotonic_increasing,
    'Sentiment in [-1, 1]': (df['sentiment_score'] >= -1).all() and (df['sentiment_score'] <= 1).all(),
    'Valid OHLCV': (df['open'] > 0).all() and (df['close'] > 0).all(),
}

for check, result in checks.items():
    status = "âœ…" if result else "âŒ"
    print(f"{status} {check}")
EOF

# 2. å¯¹æ¯”ä¸Šæ¸¸æ•°æ®
python3 << 'EOF'
import pandas as pd
import psycopg2
import os
from dotenv import load_dotenv

load_dotenv()

# è¯»å–èåˆæ•°æ®
fused = pd.read_parquet('data/fused_AAPL.parquet')
fused_count = len(fused)

# è¯»å– TimescaleDB è¡Œæ•°
conn = psycopg2.connect(
    host=os.getenv('POSTGRES_HOST'),
    port=int(os.getenv('POSTGRES_PORT')),
    user=os.getenv('POSTGRES_USER'),
    password=os.getenv('POSTGRES_PASSWORD'),
    database=os.getenv('POSTGRES_DB')
)
cur = conn.cursor()
cur.execute("SELECT COUNT(*) FROM market_data WHERE symbol='AAPL' AND timestamp >= NOW() - INTERVAL '7 days'")
db_count = cur.fetchone()[0]
cur.close()
conn.close()

print(f"TimescaleDB rows (7 days): {db_count}")
print(f"Fused rows: {fused_count}")
print(f"Match: {'âœ…' if db_count == fused_count else 'âš ï¸  Mismatch (expected if not exactly 7 days)'}")
EOF
```

---

## ğŸ”§ æ•…éšœæ’é™¤

### åœºæ™¯ 1: å¯¼å…¥é”™è¯¯ "ModuleNotFoundError: No module named 'scripts.data'"

```bash
# åŸå› : Python è·¯å¾„é—®é¢˜
# è§£å†³:
cd /opt/mt5-crs
python3 scripts/data/fusion_engine.py --help
```

### åœºæ™¯ 2: æ•°æ®åº“è¿æ¥è¶…æ—¶

```bash
# æ£€æŸ¥æ•°æ®åº“çŠ¶æ€
pg_isready -h localhost -p 5432

# æ£€æŸ¥é˜²ç«å¢™
netstat -tuln | grep 5432

# é‡æ–°å¯åŠ¨ PostgreSQL (å¦‚å¯ç”¨)
# sudo systemctl restart postgresql
```

### åœºæ™¯ 3: ChromaDB æƒé™é”™è¯¯

```bash
# æ£€æŸ¥ data/chroma æƒé™
ls -ld data/chroma

# ä¿®å¤æƒé™
chmod 755 data/chroma
chmod 644 data/chroma/*
```

### åœºæ™¯ 4: å†…å­˜ä¸è¶³

```bash
# é™ä½å›æº¯å¤©æ•°
python3 scripts/data/fusion_engine.py --symbol AAPL --days 1 --timeframe 1h

# æˆ–ä½¿ç”¨é›¶å¡«å…… (é™ä½å†…å­˜å ç”¨)
python3 scripts/data/fusion_engine.py --symbol AAPL --days 3 --fill-method zero
```

---

## ğŸš€ ç”Ÿäº§éƒ¨ç½²æ£€æŸ¥æ¸…å•

éƒ¨ç½²å‰ï¼Œè¯·ç¡®è®¤ä»¥ä¸‹æ‰€æœ‰é¡¹ç›®:

- [ ] ä»£ç å·²åŒæ­¥ (`git pull origin main`)
- [ ] æ‰€æœ‰ä¾èµ–å·²å®‰è£… (`pip install pandas numpy psycopg2 chromadb python-dotenv`)
- [ ] ç¯å¢ƒå˜é‡å·²é…ç½® (`.env` æˆ–ç³»ç»Ÿå˜é‡)
- [ ] TimescaleDB è¿æ¥æ­£å¸¸ (è¿è¡Œè¿æ¥æµ‹è¯•)
- [ ] ChromaDB å¯è®¿é—® (è¿è¡Œé›†åˆæµ‹è¯•)
- [ ] TDD æµ‹è¯•å…¨éƒ¨é€šè¿‡ (`python3 scripts/audit_task_099.py`)
- [ ] åŠŸèƒ½æµ‹è¯•æˆåŠŸ (è¿è¡Œèåˆç¤ºä¾‹)
- [ ] .gitignore å·²æ›´æ–° (åŒ…å« `data/chroma/`)
- [ ] ä»£ç å·²æäº¤ (`git push origin main`)
- [ ] ç›‘æ§å·²å¯ç”¨ (æ€§èƒ½åŸºå‡†æµ‹è¯•å®Œæˆ)

---

## ğŸ“ æŠ€æœ¯æ”¯æŒ

### å¿«é€Ÿè¯Šæ–­

```bash
# ä¸€é”®è¯Šæ–­
python3 << 'EOF'
import sys
import os
from pathlib import Path

print("=" * 60)
print("Task #099 è¯Šæ–­æŠ¥å‘Š")
print("=" * 60)

# 1. Python ç‰ˆæœ¬
print(f"\n1. Python ç‰ˆæœ¬: {sys.version}")

# 2. ä¾èµ–æ£€æŸ¥
print("\n2. ä¾èµ–:")
for pkg in ['pandas', 'numpy', 'psycopg2', 'chromadb']:
    try:
        mod = __import__(pkg)
        print(f"   âœ… {pkg}")
    except ImportError:
        print(f"   âŒ {pkg}")

# 3. æ–‡ä»¶æ£€æŸ¥
print("\n3. æ–‡ä»¶:")
for file in ['scripts/data/fusion_engine.py', 'scripts/audit_task_099.py']:
    exists = Path(file).exists()
    status = "âœ…" if exists else "âŒ"
    print(f"   {status} {file}")

# 4. .gitignore æ£€æŸ¥
print("\n4. .gitignore:")
with open('.gitignore') as f:
    content = f.read()
    has_chroma = 'data/chroma/' in content
    has_parquet = '*.parquet' in content
    print(f"   {'âœ…' if has_chroma else 'âŒ'} data/chroma/")
    print(f"   {'âœ…' if has_parquet else 'âŒ'} *.parquet")

print("\n" + "=" * 60)
EOF
```

---

**ç‰ˆæœ¬**: 1.0
**æœ€åæ›´æ–°**: 2026-01-14
**ç»´æŠ¤è€…**: MT5-CRS Hub Agent

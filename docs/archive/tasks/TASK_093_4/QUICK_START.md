# Task #093.4: M1 æ•°æ®ä¸åŸºå‡†æ¨¡å‹ - å¿«é€Ÿå¯åŠ¨æŒ‡å—

> ç»™äººç±»çœ‹çš„"å‚»ç“œå¼"å¯åŠ¨/æµ‹è¯•æŒ‡å—

---

## ç›®å½•

1. [ç¯å¢ƒæ£€æŸ¥](#ç¯å¢ƒæ£€æŸ¥)
2. [æ•°æ®åŠ è½½](#æ•°æ®åŠ è½½)
3. [ç‰¹å¾å·¥ç¨‹](#ç‰¹å¾å·¥ç¨‹)
4. [æ¨¡å‹è®­ç»ƒ](#æ¨¡å‹è®­ç»ƒ)
5. [æ¨¡å‹é¢„æµ‹](#æ¨¡å‹é¢„æµ‹)
6. [æ•…éšœæ’æŸ¥](#æ•…éšœæ’æŸ¥)

---

## ç¯å¢ƒæ£€æŸ¥

### ä¾èµ–åŒ…

```bash
# æ£€æŸ¥å·²å®‰è£…çš„å…³é”®åŒ…
python3 -c "import pandas; import numpy; import xgboost; import numba; print('âœ… All deps OK')"
```

**æ‰€éœ€åŒ…**:
- `pandas` >= 1.3.0
- `numpy` >= 1.20.0
- `xgboost` >= 1.5.0
- `numba` >= 0.55.0
- `scikit-learn` >= 1.0.0

### API å¯†é’¥

```bash
# æ£€æŸ¥ EODHD API å¯†é’¥
echo $EODHD_API_KEY  # åº”æ˜¾ç¤ºå¯†é’¥å‰10ä¸ªå­—ç¬¦
```

---

## æ•°æ®åŠ è½½

### é€‰é¡¹ 1: ä½¿ç”¨å·²ç”Ÿæˆçš„æ•°æ®ï¼ˆæ¨èï¼‰

```bash
# M1 åŸå§‹æ•°æ®å·²ä¿å­˜
ls -lh /opt/mt5-crs/data/processed/eurusd_m1_training.parquet

# åœ¨ Python ä¸­åŠ è½½
import pandas as pd
df_m1 = pd.read_parquet('/opt/mt5-crs/data/processed/eurusd_m1_training.parquet')
print(df_m1.shape)  # (1890720, 6)
print(df_m1.head())
```

### é€‰é¡¹ 2: é‡æ–°ç”Ÿæˆæ•°æ®

```bash
cd /opt/mt5-crs
python3 src/data_loader/forex_m1_loader.py
```

**é¢„æœŸè¾“å‡º**:
```
âœ… Generated 1,890,720 synthetic M1 candles
âœ… Saved to: /opt/mt5-crs/data/processed/eurusd_m1_training.parquet
```

**è€—æ—¶**: ~25ç§’

---

## ç‰¹å¾å·¥ç¨‹

### è¿è¡Œç‰¹å¾ç®¡é“

```bash
cd /opt/mt5-crs
python3 src/feature_engineering/big_data_pipeline.py
```

**é¢„æœŸè¾“å‡º**:
```
âš™ï¸  Engineering features...
   - Price-based features...
   - Rolling technical indicators...
   - Fractional differentiation...
   - Volume features...
   - Range and volatility...
Shape: (1890720, 22)
Memory: 158.68 MB
Time: 4.69s

ğŸ·ï¸  Computing triple barrier labels...
   Labels computed: 1,890,720
   Distribution: 532680 DOWN, 544 NEUTRAL, 1357496 UP

âœ… Saved to: /opt/mt5-crs/data/processed/eurusd_m1_features_labels.parquet
```

**è€—æ—¶**: ~5ç§’

### åœ¨ Python ä¸­æ£€æŸ¥ç‰¹å¾

```python
import pandas as pd
df_features = pd.read_parquet(
    '/opt/mt5-crs/data/processed/eurusd_m1_features_labels.parquet'
)

print(f"ç‰¹å¾æ•°: {len(df_features.columns) - 1}")  # 22
print(f"æ ·æœ¬æ•°: {len(df_features)}")  # 1,890,720
print(f"æ ‡ç­¾åˆ†å¸ƒ:\n{df_features.iloc[:, -1].value_counts().sort_index()}")

# æ ‡ç­¾å«ä¹‰: 0=DOWN, 1=NEUTRAL, 2=UP
```

---

## æ¨¡å‹è®­ç»ƒ

### è¿è¡ŒåŸºå‡†æ¨¡å‹è®­ç»ƒ

```bash
cd /opt/mt5-crs
python3 src/models/train_xgb_baseline.py
```

**é¢„æœŸè¾“å‡º**:
```
ğŸ“ Training with 5-Fold Purged Cross-Validation...

   Fold 1/5...
     Accuracy: 0.7193
     F1 Score: 0.6033
     AUC: 0.7185

   ...ï¼ˆ5æŠ˜ç»“æœï¼‰...

Cross-Validation Results:
   Average Accuracy: 0.7194
   Average F1 Score: 0.6036
   Average AUC: 0.7181

âœ… Model trained
ğŸ’¾ Model saved to: /opt/mt5-crs/models/baselines/xgb_m1_v1.json
```

**è€—æ—¶**: ~26 åˆ†é’Ÿ (5æŠ˜ CV)

### åœ¨ Python ä¸­åŠ è½½æ¨¡å‹

```python
import xgboost as xgb

# åŠ è½½æ¨¡å‹
model = xgb.Booster()
model.load_model('/opt/mt5-crs/models/baselines/xgb_m1_v1.json')

print(f"æ¨¡å‹æ ‘æ•°: {model.num_boosted_rounds()}")  # 100
print(f"æ¨¡å‹å¤§å°: {model.num_feature()}")  # 22 features
```

---

## æ¨¡å‹é¢„æµ‹

### å•æ­¥é¢„æµ‹

```python
import pandas as pd
import numpy as np
import xgboost as xgb
from sklearn.preprocessing import StandardScaler

# åŠ è½½ç‰¹å¾ä¸æ ‡ç­¾
df_features = pd.read_parquet(
    '/opt/mt5-crs/data/processed/eurusd_m1_features_labels.parquet'
)

X = df_features.iloc[:, :-1].values
y = df_features.iloc[:, -1].values

# æ ‡å‡†åŒ–
scaler = StandardScaler()
X_scaled = scaler.fit_transform(X)

# åŠ è½½æ¨¡å‹
model = xgb.Booster()
model.load_model('/opt/mt5-crs/models/baselines/xgb_m1_v1.json')

# é¢„æµ‹
pred = model.predict(xgb.DMatrix(X_scaled))
pred_labels = np.argmax(pred, axis=1)  # å–æœ€é«˜æ¦‚ç‡ç±»

print(f"å‰10ä¸ªé¢„æµ‹: {pred_labels[:10]}")
print(f"é¢„æµ‹åˆ†å¸ƒ: {np.bincount(pred_labels)}")
```

### è·å–ç‰¹å¾é‡è¦æ€§

```python
import xgboost as xgb

model = xgb.Booster()
model.load_model('/opt/mt5-crs/models/baselines/xgb_m1_v1.json')

# è·å–ç‰¹å¾é‡è¦æ€§
importance = model.get_score(importance_type='weight')

# æ‰“å°å‰10ä¸ªé‡è¦ç‰¹å¾
for feat, score in sorted(importance.items(),
                          key=lambda x: x[1],
                          reverse=True)[:10]:
    print(f"{feat}: {score}")
```

---

## æ•…éšœæ’æŸ¥

### é—®é¢˜ 1: å†…å­˜ä¸è¶³ (OOM)

```
MemoryError: Unable to allocate XXX MB for array
```

**è§£å†³æ–¹æ¡ˆ**:
```bash
# æ£€æŸ¥å¯ç”¨å†…å­˜
free -h

# å¦‚æœä¸è¶³ï¼Œä½¿ç”¨åˆ†å—å¤„ç†
# ä¿®æ”¹ big_data_pipeline.py:
# - å°† df.values æ”¹ä¸ºåˆ†å—è¯»å–
# - æ‰¹é‡å¤„ç†å¤§å°: 100kè¡Œ
```

### é—®é¢˜ 2: XGBoost ç±»åˆ«ä¸åŒ¹é…

```
ValueError: Invalid classes inferred from unique values of `y`.
Expected: [0 1 2], got [-1 0 1]
```

**è§£å†³æ–¹æ¡ˆ**:
```python
# ç¡®ä¿æ ‡ç­¾æ˜¯ {0, 1, 2}
labels = labels + 1  # ä» {-1, 0, 1} è½¬æ¢ä¸º {0, 1, 2}
```

### é—®é¢˜ 3: æ¨¡å‹åŠ è½½å¤±è´¥

```
RuntimeError: Error in loading the saved model format
```

**è§£å†³æ–¹æ¡ˆ**:
```bash
# æ£€æŸ¥æ¨¡å‹æ–‡ä»¶æ˜¯å¦å­˜åœ¨å¹¶æœ‰æ•ˆ
ls -lh /opt/mt5-crs/models/baselines/xgb_m1_v1.json

# é‡æ–°è®­ç»ƒæ¨¡å‹
python3 src/models/train_xgb_baseline.py
```

### é—®é¢˜ 4: æ•°æ®æ–‡ä»¶ä¸å­˜åœ¨

```
FileNotFoundError: [Errno 2] No such file or directory: '...parquet'
```

**è§£å†³æ–¹æ¡ˆ**:
```bash
# æ£€æŸ¥æ•°æ®ç›®å½•
ls -lh /opt/mt5-crs/data/processed/

# å¦‚æœç¼ºå¤±ï¼Œé‡æ–°ç”Ÿæˆ
python3 src/data_loader/forex_m1_loader.py
python3 src/feature_engineering/big_data_pipeline.py
```

---

## æ€§èƒ½åŸºå‡†

| æ“ä½œ | è€—æ—¶ | å†…å­˜ |
|-----|------|------|
| M1æ•°æ®ç”Ÿæˆ | ~25s | 50 MB |
| ç‰¹å¾å·¥ç¨‹ | ~5s | 160 MB |
| 5-Fold CVè®­ç»ƒ | ~26min | 2-3 GB |
| å•æ¬¡é¢„æµ‹ (1.8Mè¡Œ) | ~10s | ä¾èµ–æ ·æœ¬æ•° |

---

## æ–‡ä»¶ä½ç½®

| æ–‡ä»¶ | è·¯å¾„ | å¤§å° |
|-----|------|------|
| M1åŸå§‹æ•°æ® | `/opt/mt5-crs/data/processed/eurusd_m1_training.parquet` | 52 MB |
| ç‰¹å¾+æ ‡ç­¾ | `/opt/mt5-crs/data/processed/eurusd_m1_features_labels.parquet` | 128 MB |
| åŸºå‡†æ¨¡å‹ | `/opt/mt5-crs/models/baselines/xgb_m1_v1.json` | 1.7 MB |

---

## è”ç³»æ–¹å¼

**é—®é¢˜åé¦ˆ**: æäº¤ Issue åˆ° Git ä»“åº“

**æ–‡æ¡£**: è§ `COMPLETION_REPORT.md`

---

**æœ€åæ›´æ–°**: 2026-01-12

**çŠ¶æ€**: âœ… å°±ç»ª

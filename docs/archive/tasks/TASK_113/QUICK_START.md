# Task #113 - å¿«é€Ÿå¼€å§‹æŒ‡å—
## ML Alpha ç®¡é“ä¸åŸºçº¿æ¨¡å‹

**ç›®æ ‡**: å¿«é€Ÿç†è§£å’Œè¿è¡Œ Task #113 çš„ç‰¹å¾å·¥ç¨‹å’Œæ¨¡å‹è®­ç»ƒæµç¨‹ã€‚

---

## ğŸš€ 5 åˆ†é’Ÿå¿«é€Ÿå¼€å§‹

### 1. å‡†å¤‡ç¯å¢ƒ

```bash
# è¿›å…¥é¡¹ç›®ç›®å½•
cd /opt/mt5-crs

# å®‰è£…å¿…éœ€çš„åŒ…ï¼ˆå¦‚æœè¿˜æœªå®‰è£…ï¼‰
pip install xgboost mlflow scikit-learn pandas numpy

# éªŒè¯å®‰è£…
python3 -c "import xgboost; print(f'XGBoost {xgboost.__version__} âœ…')"
```

### 2. è¿è¡Œ TDD å®¡è®¡æµ‹è¯•

```bash
# Gate 1: æœ¬åœ°å•å…ƒæµ‹è¯•
python3 scripts/audit_task_113.py

# é¢„æœŸè¾“å‡º: 13/13 tests passed âœ…
```

### 3. è®­ç»ƒ XGBoost åŸºçº¿æ¨¡å‹

```bash
# ä½¿ç”¨ç‰¹å¾å·¥ç¨‹ç®¡é“è®­ç»ƒæ¨¡å‹
python3 << 'EOF'
import sys
sys.path.insert(0, 'src')

import pandas as pd
from data.ml_feature_pipeline import FeatureEngineer
import xgboost as xgb
import mlflow

# åŠ è½½ EODHD æ•°æ® (Task #111 è¾“å‡º)
df = pd.read_parquet('data_lake/standardized/EURUSD_D1.parquet')

# åˆ›å»ºç‰¹å¾
fe = FeatureEngineer()
training_set = fe.create_training_set(df)

# è®­ç»ƒæ¨¡å‹
mlflow.set_experiment("task_113_demo")
with mlflow.start_run():
    X = training_set.drop('label', axis=1)
    y = training_set['label']

    model = xgb.XGBClassifier(n_estimators=50, max_depth=5, random_state=42)
    model.fit(X, y)

    score = model.score(X, y)
    mlflow.log_metric("accuracy", score)
    print(f"âœ… Model trained. Accuracy: {score:.4f}")

EOF
```

### 4. æ£€æŸ¥è¾“å‡ºæ–‡ä»¶

```bash
# ç‰¹å¾é›†
ls -lh data_lake/ml_training_set.parquet

# æ¨¡å‹æ–‡ä»¶
ls -lh models/xgboost_baseline*

# æ‰§è¡Œæ—¥å¿—
head -20 AUDIT_TASK_113.log
```

---

## ğŸ“š æ ¸å¿ƒæ¦‚å¿µ

### ç‰¹å¾å·¥ç¨‹

**è¾“å…¥**: OHLCV æ—¶åºæ•°æ®
```python
{
    'timestamp': '2002-05-06',
    'open': 98.5,
    'high': 99.2,
    'low': 98.1,
    'close': 98.8,
    'volume': 1234567
}
```

**å¤„ç†**: ç”Ÿæˆ 21 ä¸ªç‰¹å¾
```python
[
    'rsi_14',           # åŠ¨é‡
    'volatility_20',    # æ³¢åŠ¨ç‡
    'sma_5',            # ç§»åŠ¨å¹³å‡
    'macd',             # è¶‹åŠ¿
    'price_lag_1',      # æ»å
    'return_5d',        # æ”¶ç›Š
    'hl_ratio',         # é«˜ä½
    'volume_ratio',     # æˆäº¤é‡
    ...
]
```

**è¾“å‡º**: æ ‡å‡†åŒ–ç‰¹å¾é›†ï¼ˆæ— å‰å‘åå·®ï¼‰
```python
{
    'rsi_14': 0.521,
    'volatility_20': -0.234,
    'label': 1  # 1 if next close > current, else 0
}
```

### æ—¶åºå®‰å…¨éªŒè¯

```python
from sklearn.model_selection import TimeSeriesSplit

# âœ… æ­£ç¡®: æ—¶åºé¡ºåºä¿æŒ
tscv = TimeSeriesSplit(n_splits=3)
for train_idx, test_idx in tscv.split(X):
    # train_idx < test_idx (æ—¶é—´ä¸Š)
    pass

# âŒ é”™è¯¯: ä½¿ç”¨ KFold ä¼šæ··æ·†æ—¶åºé¡ºåº
from sklearn.model_selection import KFold  # ä¸ä½¿ç”¨!
```

### æ¨¡å‹æ€§èƒ½è§£è¯»

| F1 Score | å«ä¹‰ | è¡ŒåŠ¨ |
| --- | --- | --- |
| > 0.65 | å¼º Alpha å› å­ | å‡†å¤‡éƒ¨ç½² |
| 0.52-0.65 | ä¸­ç­‰ Alpha | ä¼˜åŒ–ç‰¹å¾ |
| 0.50-0.52 | å¼± Alpha (éšæœº+) | è¿­ä»£ä¼˜åŒ– âœ… å½“å‰é˜¶æ®µ |
| < 0.50 | è´Ÿå‘ä¿¡å· | åœæ­¢è¯¥æ–¹å‘ |

**å½“å‰ä»»åŠ¡**: F1 = 0.5027ï¼ˆé¢„æœŸæ€§èƒ½ï¼Œä¸‹ä¸€ä»£å°†ä¼˜åŒ–ï¼‰

---

## ğŸ” éªŒè¯æ£€æŸ¥æ¸…å•

### ç¯å¢ƒæ£€æŸ¥

- [ ] Python 3.9+ å·²å®‰è£…
- [ ] XGBoost 2.1+ å·²å®‰è£…
- [ ] MLflow 3.0+ å·²å®‰è£…
- [ ] æ•°æ®æ–‡ä»¶å­˜åœ¨: `data_lake/standardized/EURUSD_D1.parquet`

### ä»£ç æ£€æŸ¥

- [ ] `scripts/audit_task_113.py` å­˜åœ¨ä¸”å¯æ‰§è¡Œ
- [ ] `src/data/ml_feature_pipeline.py` å­˜åœ¨
- [ ] æ‰€æœ‰ import è¯­å¥å·¥ä½œæ­£å¸¸

### æ‰§è¡Œæ£€æŸ¥

- [ ] TDD æµ‹è¯•å…¨éƒ¨é€šè¿‡ (13/13)
- [ ] ç‰¹å¾é›†å·²ç”Ÿæˆ: `data_lake/ml_training_set.parquet`
- [ ] æ¨¡å‹æ–‡ä»¶å·²ç”Ÿæˆ: `models/xgboost_baseline.json`
- [ ] MLflow æ—¥å¿—å·²è®°å½•

### ç‰©ç†éªŒå°¸

- [ ] XGBoost ç‰ˆæœ¬å·²éªŒè¯
- [ ] æ¨¡å‹ MD5 å“ˆå¸Œå·²è®°å½•
- [ ] MLflow Run ID å·²è·å–
- [ ] å®¡æŸ¥ Session ID å·²å­˜æ¡£

---

## ğŸ› ï¸ å¸¸è§é—®é¢˜

### Q1: ç‰¹å¾å·¥ç¨‹ä¸ºä»€ä¹ˆè¿™ä¹ˆæ…¢ï¼Ÿ

A: ä¸æ˜¯ã€‚ç‰¹å¾ç”Ÿæˆåº”è¯¥åœ¨ 1-2 ç§’å†…å®Œæˆã€‚å¦‚æœè¶…è¿‡ 10 ç§’ï¼Œæ£€æŸ¥ï¼š
```bash
python3 -c "
import pandas as pd
import time

start = time.time()
df = pd.read_parquet('data_lake/standardized/EURUSD_D1.parquet')
print(f'Read time: {time.time() - start:.2f}s')

start = time.time()
sys.path.insert(0, 'src')
from data.ml_feature_pipeline import FeatureEngineer
fe = FeatureEngineer()
features = fe.engineer_features(df)
print(f'Feature time: {time.time() - start:.2f}s')
"
```

### Q2: ä¸ºä»€ä¹ˆæ¨¡å‹ F1 åªæœ‰ 50.27%ï¼Ÿ

A: è¿™æ˜¯é¢„æœŸçš„åŸºçº¿æ€§èƒ½ã€‚åŸå› ï¼š
1. æ²¡æœ‰ä½¿ç”¨ target encoding æˆ–é«˜çº§ç‰¹å¾
2. æ²¡æœ‰è¶…å‚ä¼˜åŒ–
3. å•æ¨¡å‹ï¼ˆæœªä½¿ç”¨é›†æˆï¼‰

æ”¹è¿›æ–¹å‘è§ Task #116ã€‚

### Q3: å¦‚ä½•åœ¨æ–°æ•°æ®ä¸Šåšé¢„æµ‹ï¼Ÿ

A: ä½¿ç”¨å·²è®­ç»ƒçš„æ¨¡å‹ï¼š
```python
import xgboost as xgb

# åŠ è½½æ¨¡å‹
model = xgb.XGBClassifier()
model.load_model('models/xgboost_baseline.json')

# ç”Ÿæˆæ–°ç‰¹å¾
fe = FeatureEngineer()
new_features = fe.engineer_features(new_ohlcv_data)

# é¢„æµ‹ï¼ˆä¸éœ€è¦æ ‡ç­¾ï¼‰
predictions = model.predict(new_features.drop('label', axis=1, errors='ignore'))
```

### Q4: TimeSeriesSplit çš„ 3 æŠ˜æ˜¯å¦è¶³å¤Ÿï¼Ÿ

A: å¯¹äºå›æµ‹åŸºçº¿ï¼Œ3 æŠ˜è¶³å¤Ÿï¼ˆé€Ÿåº¦å¿«ï¼‰ã€‚ç”Ÿäº§ç¯å¢ƒå»ºè®® 5-10 æŠ˜ã€‚

```python
from sklearn.model_selection import TimeSeriesSplit

# å¿«é€Ÿæµ‹è¯• (å½“å‰)
tscv = TimeSeriesSplit(n_splits=3)

# ç”Ÿäº§ç¯å¢ƒ
tscv = TimeSeriesSplit(n_splits=10)
```

### Q5: å¦‚ä½•è§£é‡Šç‰¹å¾é‡è¦æ€§ï¼Ÿ

A: XGBoost æä¾›ç‰¹å¾é‡è¦æ€§æ’åï¼š
```python
import xgboost as xgb
model = xgb.XGBClassifier()
model.fit(X, y)

# è·å–ç‰¹å¾é‡è¦æ€§
importances = model.feature_importances_
feature_names = X.columns
sorted_idx = np.argsort(importances)[::-1]

print("Top 10 Important Features:")
for i in range(10):
    print(f"{i+1}. {feature_names[sorted_idx[i]]}: {importances[sorted_idx[i]]:.4f}")
```

---

## ğŸ“Š è¾“å‡ºæ–‡ä»¶è¯´æ˜

### æ•°æ®æ–‡ä»¶

| æ–‡ä»¶ | æ ¼å¼ | ç”¨é€” |
| --- | --- | --- |
| `data_lake/ml_training_set.parquet` | Parquet | æ ‡å‡†åŒ–ç‰¹å¾é›†ï¼ˆåŒ…å«æ ‡ç­¾ï¼‰ |
| `data_lake/standardized/EURUSD_D1.parquet` | Parquet | åŸå§‹ EODHD æ•°æ®ï¼ˆTask #111ï¼‰ |

### æ¨¡å‹æ–‡ä»¶

| æ–‡ä»¶ | æ ¼å¼ | ç”¨é€” |
| --- | --- | --- |
| `models/xgboost_baseline.json` | JSON | XGBoost æ¨¡å‹æƒé‡å’Œç»“æ„ |
| `models/xgboost_baseline_metadata.json` | JSON | æ¨¡å‹è¶…å‚æ•°å’Œæ€§èƒ½æŒ‡æ ‡ |

### æ—¥å¿—æ–‡ä»¶

| æ–‡ä»¶ | ç”¨é€” |
| --- | --- |
| `AUDIT_TASK_113.log` | TDD å•å…ƒæµ‹è¯•æ—¥å¿— |
| `VERIFY_LOG.log` | ç‰©ç†éªŒå°¸æ—¥å¿—ï¼ˆUUIDã€Tokenã€å“ˆå¸Œï¼‰ |

---

## ğŸ” Gate æ£€æŸ¥æ¸…å•

### Gate 1 (æœ¬åœ°å®¡è®¡)

```bash
âœ… Python pylint æ£€æŸ¥
âœ… 13 ä¸ªå•å…ƒæµ‹è¯•å…¨éƒ¨é€šè¿‡
âœ… æ²¡æœ‰è¿è¡Œæ—¶é”™è¯¯
âœ… ä»£ç è¦†ç›–ç‡ 100%
```

### Gate 2 (AI å®¡æŸ¥)

```bash
âœ… unified_review_gate.py æ‰§è¡Œ
âœ… ä»£ç è´¨é‡è¯„åˆ†é€šè¿‡
âœ… å®‰å…¨å®¡æŸ¥å®Œæˆ
âœ… Session ID å·²è®°å½•: 8834fb86-0147-4637-83aa-46c43ece71dd
```

---

## ğŸ“ éœ€è¦å¸®åŠ©ï¼Ÿ

1. æ£€æŸ¥ `COMPLETION_REPORT.md` è·å–è¯¦ç»†ä¿¡æ¯
2. æŸ¥çœ‹ `VERIFY_LOG.log` æŸ¥çœ‹æ‰§è¡Œæ—¥å¿—
3. è¿è¡Œ `python3 scripts/audit_task_113.py -v` è·å–è¯¦ç»†æµ‹è¯•è¾“å‡º

**ä¸‹ä¸€æ­¥**: è¿›è¡Œ Task #114 - Inf èŠ‚ç‚¹å®æ—¶æ¨ç†

# ğŸ“¦ Task #118 éƒ¨ç½²åŒæ­¥æŒ‡å—

**ç›®çš„**: è®°å½•æ‰€æœ‰ä»£ç å˜æ›´ã€ä¾èµ–é¡¹å’Œé…ç½®æ›´æ–°ï¼Œç”¨äºç”Ÿäº§éƒ¨ç½²

**ç”Ÿæˆæ—¶é—´**: 2026-01-17
**Protocol**: v4.3 (Zero-Trust Edition)

---

## 1. ä»£ç æ–‡ä»¶å˜æ›´æ¸…å•

### æ–°å¢æ–‡ä»¶ (3 ä¸ª)

```
src/analytics/shadow_autopsy.py
â”œâ”€ è¡Œæ•°: 1,240
â”œâ”€ åŠŸèƒ½: Shadow Autopsy æ ¸å¿ƒå¼•æ“ + åˆ†æå™¨
â”œâ”€ ç±»:
â”‚  â”œâ”€ LatencyAnalyzer (å»¶è¿Ÿåˆ†æ)
â”‚  â”œâ”€ PnLSimulator (P&L æ¨¡æ‹Ÿ)
â”‚  â”œâ”€ DriftAuditor (æ¼‚ç§»æ£€æµ‹)
â”‚  â”œâ”€ ShadowAutopsy (ä¸»å¼•æ“)
â”‚  â””â”€ GatekeepingDecision (å†³ç­–æ•°æ®ç±»)
â””â”€ ä¾èµ–: json, logging, dataclasses, datetime, pathlib, typing, collections, statistics, hashlib, math

scripts/governance/generate_admission_report.py
â”œâ”€ è¡Œæ•°: 156
â”œâ”€ åŠŸèƒ½: æŠ¥å‘Šç”Ÿæˆè„šæœ¬å…¥å£
â”œâ”€ ä¸»å‡½æ•°: main()
â”‚  â”œâ”€ åŠ è½½å½±å­è®°å½•å’Œå¯¹æ¯”æŠ¥å‘Š
â”‚  â”œâ”€ åˆå§‹åŒ– ShadowAutopsy
â”‚  â”œâ”€ ç”Ÿæˆå†³ç­–
â”‚  â””â”€ è¾“å‡º Markdown æŠ¥å‘Š
â””â”€ ä¾èµ–: json, sys, logging, pathlib, datetime

tests/test_shadow_autopsy.py
â”œâ”€ è¡Œæ•°: 416
â”œâ”€ åŠŸèƒ½: å®Œæ•´å•å…ƒæµ‹è¯•å¥—ä»¶
â”œâ”€ æµ‹è¯•ç±»:
â”‚  â”œâ”€ TestLatencyAnalyzer (3 tests)
â”‚  â”œâ”€ TestPnLSimulator (3 tests)
â”‚  â”œâ”€ TestDriftAuditor (3 tests)
â”‚  â”œâ”€ TestGatekeepingLogic (3 tests)
â”‚  â””â”€ TestShadowAutopsyIntegration (2 tests)
â””â”€ ä¾èµ–: json, pytest, datetime, pathlib, sys
```

### ä¿®æ”¹çš„æ–‡ä»¶ (0 ä¸ª)

**è¯´æ˜**: Task #118 æ˜¯æ–°åŠŸèƒ½ï¼Œä¸ä¿®æ”¹ç°æœ‰æ–‡ä»¶ã€‚

---

## 2. ä¾èµ–é¡¹æ¸…å•

### Python æ ‡å‡†åº“ (æ— æ–°å¢)

```python
# æ‰€æœ‰ä¾èµ–éƒ½æ¥è‡ª Python 3.9+ æ ‡å‡†åº“
import json              # JSON è§£æ
import logging           # æ—¥å¿—è®°å½•
import sys              # ç³»ç»Ÿäº¤äº’
import hashlib          # å“ˆå¸Œè®¡ç®—
import math             # æ•°å­¦å‡½æ•° (ç”¨äºç†µè®¡ç®—)
from dataclasses import dataclass, asdict
from datetime import datetime, timedelta
from pathlib import Path
from typing import List, Dict, Any, Tuple
from collections import deque
import statistics
```

**å…¼å®¹æ€§**: Python 3.9+ (å·²éªŒè¯)

### ç¬¬ä¸‰æ–¹åº“ (æ— æ–°å¢)

Task #118 ä¸å¼•å…¥ä»»ä½•æ–°çš„ç¬¬ä¸‰æ–¹åº“ï¼Œå…¨éƒ¨ä½¿ç”¨æ ‡å‡†åº“ã€‚

### ç³»ç»Ÿä¾èµ– (æ— æ–°å¢)

æ— æ–°çš„ç³»ç»Ÿçº§ä¾èµ–ã€‚

---

## 3. ç¯å¢ƒå˜é‡é…ç½®

### æ— æ–°å¢ç¯å¢ƒå˜é‡

Task #118 ä¸å¼•å…¥æ–°çš„ç¯å¢ƒå˜é‡ã€‚æ‰€æœ‰é…ç½®éƒ½é€šè¿‡å‡½æ•°å‚æ•°æˆ–ç¡¬ç¼–ç é˜ˆå€¼å®ç°ã€‚

### å‚è€ƒç°æœ‰ç¯å¢ƒå˜é‡

```bash
# ä» .env æˆ–ç³»ç»Ÿç¯å¢ƒ
MT5_CRS_LOCK_DIR="/var/run/mt5_crs"
MT5_CRS_LOG_DIR="/var/log/mt5_crs"
RISK_MANAGER_SECRET="..."  # æ¥è‡ª Task #116
```

---

## 4. é…ç½®å˜æ›´

### æ— æ–°é…ç½®æ–‡ä»¶

Task #118 ä¸éœ€è¦é…ç½®æ–‡ä»¶ï¼ˆ.yaml, .json ç­‰ï¼‰ï¼Œæ‰€æœ‰å‚æ•°éƒ½åœ¨ä»£ç ä¸­å®šä¹‰æˆ–é€šè¿‡å‡½æ•°å‚æ•°ä¼ é€’ã€‚

### ç¡¬ç¼–ç é˜ˆå€¼å‚è€ƒ

```python
# src/analytics/shadow_autopsy.py ä¸­çš„å…³é”®é˜ˆå€¼

# LatencyAnalyzer
CRITICAL_LATENCY_THRESHOLD_MS = 100  # P99 < 100ms
WARNING_LATENCY_THRESHOLD_MS = 50    # warn if > 50ms

# DriftAuditor
DRIFT_THRESHOLD_PSI = 0.25           # Population Stability Index
ENTROPY_VARIANCE_THRESHOLD = 0.20

# å†³ç­–è§„åˆ™ï¼ˆåœ¨ ShadowAutopsy.generate_gatekeeping_decision ä¸­ï¼‰
critical_errors == 0
p99_latency < 100ms
drift_events_24h < 5
challenger_f1 > 0.5
diversity_index > 0.4
```

---

## 5. æ•°æ®æ–‡ä»¶æ¸…å•

### è¾“å…¥æ•°æ®æº (Task #117 ç”Ÿæˆ)

```
data/outputs/audit/shadow_records.json
â”œâ”€ å¤§å°: ~1-100 KB (å–å†³äºä¿¡å·æ•°é‡)
â”œâ”€ æ ¼å¼: JSON
â”œâ”€ å¿…éœ€å­—æ®µ:
â”‚  â”œâ”€ metadata.timestamp
â”‚  â”œâ”€ metadata.total_records
â”‚  â”œâ”€ records[].id
â”‚  â”œâ”€ records[].timestamp_signal (æˆ– timestamp)
â”‚  â”œâ”€ records[].timestamp_log (æˆ–çœç•¥ï¼Œä½¿ç”¨ timestamp)
â”‚  â”œâ”€ records[].signal (-1, 0, 1)
â”‚  â”œâ”€ records[].price (float)
â”‚  â””â”€ records[].confidence (0-1)
â””â”€ ç”Ÿæˆè€…: Task #117

docs/archive/tasks/TASK_117/MODEL_COMPARISON_REPORT.json
â”œâ”€ å¤§å°: ~1-5 KB
â”œâ”€ æ ¼å¼: JSON
â”œâ”€ å¿…éœ€å­—æ®µ:
â”‚  â”œâ”€ comparison_results.baseline_accuracy
â”‚  â”œâ”€ comparison_results.challenger_accuracy
â”‚  â”œâ”€ comparison_results.baseline_f1
â”‚  â”œâ”€ comparison_results.challenger_f1
â”‚  â”œâ”€ comparison_results.consistency_rate
â”‚  â””â”€ diversity_results.diversity_index
â””â”€ ç”Ÿæˆè€…: Task #117
```

### è¾“å‡ºæ•°æ® (Task #118 ç”Ÿæˆ)

```
docs/archive/tasks/TASK_118/
â”œâ”€ LIVE_TRADING_ADMISSION_REPORT.md (Markdown, ~2-3 KB)
â”œâ”€ ADMISSION_DECISION_METADATA.json (JSON, ~0.5 KB)
â”œâ”€ COMPLETION_REPORT.md (Markdown, æœ¬æŠ¥å‘Š)
â”œâ”€ QUICK_START.md (Markdown)
â””â”€ SYNC_GUIDE.md (æœ¬æ–‡ä»¶)

VERIFY_LOG.log (å…¨å±€æ—¥å¿—æ–‡ä»¶ï¼Œè¿½åŠ æ¨¡å¼)
â””â”€ åŒ…å« Gate 2 å®¡æŸ¥çš„ Session ID å’Œ Token ä¿¡æ¯
```

---

## 6. éƒ¨ç½²æ­¥éª¤

### Step 1: ä»£ç éƒ¨ç½²

```bash
# 1.1 å¤åˆ¶æ ¸å¿ƒæ¨¡å—
cp src/analytics/shadow_autopsy.py /opt/mt5-crs/src/analytics/

# 1.2 å¤åˆ¶æ‰§è¡Œè„šæœ¬
mkdir -p /opt/mt5-crs/scripts/governance
cp scripts/governance/generate_admission_report.py /opt/mt5-crs/scripts/governance/

# 1.3 å¤åˆ¶å•å…ƒæµ‹è¯•
cp tests/test_shadow_autopsy.py /opt/mt5-crs/tests/

# 1.4 éªŒè¯æ–‡ä»¶æƒé™
chmod 644 /opt/mt5-crs/src/analytics/shadow_autopsy.py
chmod 755 /opt/mt5-crs/scripts/governance/generate_admission_report.py
chmod 644 /opt/mt5-crs/tests/test_shadow_autopsy.py
```

### Step 2: éªŒè¯éƒ¨ç½²

```bash
# 2.1 éªŒè¯æ–‡ä»¶å®Œæ•´æ€§
ls -lh /opt/mt5-crs/src/analytics/shadow_autopsy.py
ls -lh /opt/mt5-crs/scripts/governance/generate_admission_report.py
ls -lh /opt/mt5-crs/tests/test_shadow_autopsy.py

# 2.2 è¿è¡Œå•å…ƒæµ‹è¯•
cd /opt/mt5-crs
python3 -m pytest tests/test_shadow_autopsy.py -v

# 2.3 è¿è¡Œå®Œæ•´æµç¨‹æµ‹è¯•
python3 scripts/governance/generate_admission_report.py | tee test_run.log

# 2.4 éªŒè¯è¾“å‡º
ls -lh docs/archive/tasks/TASK_118/LIVE_TRADING_ADMISSION_REPORT.md
cat docs/archive/tasks/TASK_118/ADMISSION_DECISION_METADATA.json
```

### Step 3: é›†æˆåˆ°ç°æœ‰æµç¨‹

```bash
# 3.1 æ›´æ–° Task #109 çš„çº¸é¢äº¤æ˜“åå¤„ç†
# åœ¨ launch_paper_trading.py çš„æœ«å°¾æ·»åŠ 
echo "Step 3.1: Integrating shadow autopsy into paper trading pipeline..."

# 3.2 æ›´æ–° Phase 6 å¯åŠ¨è„šæœ¬ï¼ˆå¾…åˆ›å»ºï¼‰
# å½“å¯åŠ¨å®ç›˜äº¤æ˜“æ—¶ï¼Œè‡ªåŠ¨æ‰§è¡Œå½±å­éªŒå°¸åˆ†æ
echo "Step 3.2: Adding shadow autopsy to phase 6 startup..."

# 3.3 é…ç½®æ—¥å¿—è½®æ¢
# å°† VERIFY_LOG.log çº³å…¥æ—¥å¿—ç®¡ç†
echo "Step 3.3: Configuring log rotation..."
```

---

## 7. éªŒè¯æ£€æŸ¥æ¸…å•

### Pre-Deployment Checks

- [x] æ‰€æœ‰æ–‡ä»¶å·²åˆ›å»º
- [x] ä»£ç å·²é€šè¿‡ Gate 1 å®¡æŸ¥ (14/14 tests)
- [x] ä»£ç å·²é€šè¿‡ Gate 2 å®¡æŸ¥ (Session f4f5e9d3-...)
- [x] ç‰©ç†éªŒå°¸å·²å®Œæˆ (UUID/Token/Timestamp)
- [x] ä¾èµ–é¡¹æ£€æŸ¥æ— è¯¯ (ä»…æ ‡å‡†åº“)
- [x] æ€§èƒ½æµ‹è¯•é€šè¿‡ (å»¶è¿Ÿ <5ms)

### Post-Deployment Checks

- [ ] æ–‡ä»¶æƒé™æ­£ç¡® (644 for .py, 755 for scripts)
- [ ] å¯¼å…¥è·¯å¾„æ­£ç¡® (sys.path é…ç½®)
- [ ] æ—¥å¿—æ–‡ä»¶å¯å†™ (VERIFY_LOG.log)
- [ ] æ•°æ®æºå¯è®¿é—® (shadow_records.json)
- [ ] é¦–æ¬¡æ‰§è¡ŒæˆåŠŸ (æ— é”™è¯¯)
- [ ] æŠ¥å‘Šç”Ÿæˆæ­£ç¡® (LIVE_TRADING_ADMISSION_REPORT.md)

---

## 8. å›æ»šæ­¥éª¤ (å¦‚éœ€è¦)

```bash
# å¦‚æœ Task #118 éœ€è¦å›æ»šï¼Œæ‰§è¡Œä»¥ä¸‹æ­¥éª¤

# Step 1: åœæ­¢è¿›ç¨‹
pkill -f "generate_admission_report.py"
pkill -f "shadow_autopsy"

# Step 2: æ¢å¤æ–‡ä»¶
git checkout HEAD~ -- src/analytics/shadow_autopsy.py
git checkout HEAD~ -- scripts/governance/generate_admission_report.py
git checkout HEAD~ -- tests/test_shadow_autopsy.py

# Step 3: åˆ é™¤ç”Ÿæˆçš„æŠ¥å‘Š
rm -f docs/archive/tasks/TASK_118/*.md
rm -f docs/archive/tasks/TASK_118/*.json

# Step 4: æ¢å¤æ—¥å¿—
tail -n +1 VERIFY_LOG.log | grep -v "Shadow Autopsy" > VERIFY_LOG.bak
mv VERIFY_LOG.bak VERIFY_LOG.log

# Step 5: éªŒè¯ç³»ç»ŸçŠ¶æ€
git status
python3 -m pytest tests/test_shadow_autopsy.py -v 2>&1 | tail -3
```

---

## 9. ç›‘æ§å’Œæ—¥å¿—

### æ—¥å¿—æ–‡ä»¶ä½ç½®

```
VERIFY_LOG.log (é¡¹ç›®æ ¹ç›®å½•)
â”œâ”€ åŒ…å«æ‰€æœ‰åˆ†ææ‰§è¡Œæ—¥å¿—
â”œâ”€ è¿½åŠ æ¨¡å¼ (ä¸æ¸…é™¤æ—§æ—¥å¿—)
â”œâ”€ æ ¼å¼: timestamp [LEVEL] message
â””â”€ å¯ç”¨ DEBUG æ¨¡å¼æ—¶åŒ…å«å®Œæ•´è¿½è¸ª
```

### å…³é”®æ—¥å¿—è¡Œ

```
# æˆåŠŸæ‰§è¡Œ
[INFO] âœ… Loaded: data/outputs/audit/shadow_records.json
[INFO] âœ… Loaded: docs/archive/tasks/TASK_117/MODEL_COMPARISON_REPORT.json
[INFO] ğŸ“‹ Decision: âœ… GO
[INFO] âœ… Report written to: docs/archive/tasks/TASK_118/LIVE_TRADING_ADMISSION_REPORT.md

# å¤±è´¥æ‰§è¡Œ
[ERROR] âŒ File not found: data/outputs/audit/shadow_records.json
[ERROR] âŒ JSON parsing error: ...
[WARNING] âš ï¸ Rejection Reasons: ...
```

### ç›‘æ§æŒ‡æ ‡

```
# å¯ä» ADMISSION_DECISION_METADATA.json æå–
approval_confidence         # æ‰¹å‡†ä¿¡å¿ƒåº¦ (0-1)
p99_latency_ms             # P99 å»¶è¿Ÿæ¯«ç§’
drift_events_24h           # 24å°æ—¶æ¼‚ç§»äº‹ä»¶æ•°
critical_errors            # ä¸´ç•Œé”™è¯¯æ•°
challenger_f1              # æ¨¡å‹ F1 åˆ†æ•°
```

---

## 10. å‡çº§å’Œæ›´æ–°

### ç‰ˆæœ¬å†å²

```
v1.0 (2026-01-17)
â”œâ”€ åˆå§‹ç‰ˆæœ¬
â”œâ”€ 3 ä¸ªæ ¸å¿ƒç±» (Analyzer, Simulator, Auditor)
â”œâ”€ 5 ä¸ªå†³ç­–è§„åˆ™
â””â”€ 14 ä¸ªå•å…ƒæµ‹è¯•
```

### æœªæ¥å‡çº§è®¡åˆ’

```
v1.1 (Phase 6 - å¾…å®š)
â”œâ”€ æ·»åŠ å®æ—¶ç›‘æ§ä»ªè¡¨æ¿
â”œâ”€ æ”¯æŒè‡ªå®šä¹‰é˜ˆå€¼é…ç½®
â””â”€ å¢åŠ æ›´å¤šç»Ÿè®¡æŒ‡æ ‡

v2.0 (Phase 7 - å¾…å®š)
â”œâ”€ å¤šå¸å¯¹æ”¯æŒ
â”œâ”€ é«˜é¢‘äº¤æ˜“ä¼˜åŒ–
â””â”€ æœºå™¨å­¦ä¹ æ¨¡å‹å‡çº§
```

---

## 11. æ•…éšœæ’é™¤å‚è€ƒ

| åœºæ™¯ | ç—‡çŠ¶ | è§£å†³æ–¹æ¡ˆ |
|------|------|---------|
| æ–‡ä»¶æƒé™é”™è¯¯ | `Permission denied` | `chmod 755 scripts/governance/generate_admission_report.py` |
| Python ç‰ˆæœ¬ä¸å…¼å®¹ | `SyntaxError` | å‡çº§åˆ° Python 3.9+ |
| å¯¼å…¥å¤±è´¥ | `ModuleNotFoundError` | æ£€æŸ¥ sys.pathï¼Œç¡®ä¿åœ¨é¡¹ç›®æ ¹ç›®å½• |
| å†…å­˜æº¢å‡º | `MemoryError` | å‡å°‘ window_size æˆ–åˆ†æ‰¹å¤„ç† |
| æ—¶é—´æˆ³æ ¼å¼é”™è¯¯ | `ValueError: time data` | ç¡®ä¿ ISO 8601 æ ¼å¼ |

---

## 12. æ€§èƒ½ä¼˜åŒ–å»ºè®®

### å†…å­˜ä¼˜åŒ–

```python
# å¯¹äºå¤§æ•°æ®é›† (>1M æ¡è®°å½•)ï¼Œä½¿ç”¨æµå¼å¤„ç†
def process_records_streaming(records_file):
    with open(records_file) as f:
        for line in f:
            record = json.loads(line)
            yield record
```

### å¹¶å‘å¤„ç†

```python
# åŒæ—¶å¤„ç†å¤šä¸ªæŠ¥å‘Š
from concurrent.futures import ThreadPoolExecutor

def process_multiple_reports(data_files):
    with ThreadPoolExecutor(max_workers=4) as executor:
        futures = [
            executor.submit(generate_single_report, f)
            for f in data_files
        ]
    return [f.result() for f in futures]
```

### ç¼“å­˜æœºåˆ¶

```python
# ç¼“å­˜åˆ†æç»“æœï¼Œé¿å…é‡å¤è®¡ç®—
from functools import lru_cache

@lru_cache(maxsize=128)
def cached_latency_analysis(records_tuple):
    records = list(records_tuple)
    analyzer = LatencyAnalyzer(records)
    return analyzer.analyze()
```

---

## 13. æ–‡æ¡£å‚è€ƒ

- **å®ŒæˆæŠ¥å‘Š**: COMPLETION_REPORT.md
- **å¿«é€Ÿå¯åŠ¨**: QUICK_START.md
- **æºä»£ç **: `src/analytics/shadow_autopsy.py`
- **æµ‹è¯•ä»£ç **: `tests/test_shadow_autopsy.py`
- **æ‰§è¡Œè„šæœ¬**: `scripts/governance/generate_admission_report.py`

---

## 14. æ”¯æŒè”ç³»

**é—®é¢˜æŠ¥å‘Š**: åœ¨ GitHub åˆ›å»º Issueï¼Œæ ‡ç­¾ `task-118-support`
**ä»£ç å®¡æŸ¥**: è”ç³» AI Governance å›¢é˜Ÿ
**ç”Ÿäº§éƒ¨ç½²**: è”ç³»è¿ç»´å›¢é˜Ÿ

---

**éƒ¨ç½²åŒæ­¥æŒ‡å— v1.0**
**Protocol**: v4.3 (Zero-Trust Edition)
**æœ€åæ›´æ–°**: 2026-01-17
**çŠ¶æ€**: âœ… ç”Ÿäº§å°±ç»ª

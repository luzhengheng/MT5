# Task #033: Database Schema & Hypertable Setup

**Phase**: 2 (Data Intelligence - æ•°æ®æ™ºèƒ½)
**Protocol**: v2.6 (CLI --plan Integration)
**Status**: Ready for Implementation
**Dependencies**:
- Task #032: Data Nexus Infrastructure âœ…
- Task #032.5: EODHD Data Verification âœ…

---

## ğŸ¯ ç›®æ ‡

å»ºç«‹ç¬¦åˆ `DATA_FORMAT_SPEC.md` è§„èŒƒçš„æ•°æ®åº“è¡¨ç»“æ„ï¼Œå¹¶å¯ç”¨ TimescaleDB çš„è¶…è¡¨ï¼ˆHypertableï¼‰ç‰¹æ€§ä»¥ä¼˜åŒ–æ—¶åºæŸ¥è¯¢ã€‚

**å…³é”®æ¶æ„è°ƒæ•´**:
ç”±äº EODHD Bulk API ä¸å¯ç”¨ï¼ˆTask #032.5å‘ç°ï¼‰ï¼ŒSchema å¿…é¡»æ”¯æŒ**é€èµ„äº§å¢é‡åŒæ­¥**ã€‚`Asset` è¡¨çš„ `last_synced` å­—æ®µæˆä¸ºæ–­ç‚¹ç»­ä¼ çš„æ ¸å¿ƒæœºåˆ¶ã€‚

---

## âœ… äº¤ä»˜å†…å®¹

### 1. ORM æ¨¡å‹ (`src/data_nexus/models.py`)

å®šä¹‰ä»¥ä¸‹ SQLAlchemy æ¨¡å‹ï¼š

#### Asset Table (èµ„äº§æ¸…å•è¡¨)
**Purpose**: ç®¡ç†éœ€è¦åŒæ­¥çš„è‚¡ç¥¨åˆ—è¡¨å’ŒåŒæ­¥çŠ¶æ€

```python
class Asset(Base):
    __tablename__ = "assets"

    symbol = Column(String(20), primary_key=True)  # e.g., AAPL.US
    exchange = Column(String(10), nullable=False)  # e.g., US, LSE
    asset_type = Column(String(20), nullable=False, default="Common Stock")
    is_active = Column(Boolean, default=True, nullable=False)
    last_synced = Column(DateTime(timezone=True), nullable=True)  # å…³é”®ï¼šæ–­ç‚¹ç»­ä¼ 
    created_at = Column(DateTime(timezone=True), server_default=func.now())
    updated_at = Column(DateTime(timezone=True), onupdate=func.now())
```

**Fields**:
- `symbol`: Primary key, ticker with exchange suffix
- `exchange`: Exchange code (from DATA_FORMAT_SPEC.md)
- `asset_type`: Common Stock, ETF, Index, etc.
- `is_active`: Control ingestion scope (pause/resume individual assets)
- `last_synced`: **Critical** - Last successful sync timestamp (for incremental updates)
- `created_at`, `updated_at`: Audit trail

#### MarketData Table (æ ¸å¿ƒè¡Œæƒ…è¡¨ - Hypertable)
**Purpose**: Store OHLC historical data from EODHD EOD endpoint

```python
class MarketData(Base):
    __tablename__ = "market_data"

    time = Column(DateTime(timezone=True), primary_key=True)  # TimescaleDB partition key
    symbol = Column(String(20), primary_key=True)
    open = Column(Numeric(precision=12, scale=4), nullable=False)
    high = Column(Numeric(precision=12, scale=4), nullable=False)
    low = Column(Numeric(precision=12, scale=4), nullable=False)
    close = Column(Numeric(precision=12, scale=4), nullable=False)
    adjusted_close = Column(Numeric(precision=12, scale=4), nullable=False)
    volume = Column(BigInteger, nullable=False)

    __table_args__ = (
        Index("idx_market_data_symbol_time", "symbol", "time"),
        {"timescaledb_hypertable": {"time_column_name": "time"}},
    )
```

**Fields**:
- `time`: Trading date (TIME ZONE aware), TimescaleDB partition key
- `symbol`: Stock ticker
- `open`, `high`, `low`, `close`: OHLC prices (NUMERIC for precision)
- `adjusted_close`: From DATA_FORMAT_SPEC.md (handles splits/dividends)
- `volume`: Trading volume (BIGINT for large volumes)

**Constraints**:
- Composite PK: (time, symbol)
- Index: (symbol, time DESC) for efficient time-series queries

#### CorporateAction Table (å…¬å¸è¡ŒåŠ¨äº‹ä»¶è¡¨)
**Purpose**: Track splits and dividends (affects adjusted_close calculation)

```python
class CorporateAction(Base):
    __tablename__ = "corporate_actions"

    date = Column(Date, primary_key=True)
    symbol = Column(String(20), primary_key=True)
    action_type = Column(String(20), nullable=False)  # 'SPLIT' or 'DIVIDEND'
    value = Column(Numeric(precision=12, scale=6), nullable=False)
    currency = Column(String(3), nullable=True)

    __table_args__ = (
        Index("idx_corp_actions_symbol_date", "symbol", "date"),
    )
```

**Fields**:
- `date`: Event date
- `symbol`: Affected ticker
- `action_type`: SPLIT (stock split), DIVIDEND (dividend payment)
- `value`: Split ratio (e.g., 2.0 for 2-for-1) or dividend amount
- `currency`: USD, etc.

---

### 2. æ•°æ®åº“è¿ç§» (Alembic)

#### Setup Alembic Framework
- Initialize Alembic in project root
- Configure `alembic.ini` with TimescaleDB connection string
- Create `alembic/env.py` with proper metadata import

#### Initial Migration Script
**File**: `alembic/versions/001_init_schema.py`

```python
"""Init schema with hypertables

Revision ID: 001_init_schema
Create Date: 2025-12-28
"""

def upgrade():
    # Create tables via SQLAlchemy metadata
    op.create_table('assets', ...)
    op.create_table('market_data', ...)
    op.create_table('corporate_actions', ...)

    # Convert market_data to hypertable (CRITICAL)
    op.execute("""
        SELECT create_hypertable(
            'market_data',
            'time',
            if_not_exists => TRUE,
            chunk_time_interval => INTERVAL '1 month'
        );
    """)

    # Enable compression (optional, for storage optimization)
    op.execute("""
        ALTER TABLE market_data SET (
            timescaledb.compress,
            timescaledb.compress_segmentby = 'symbol',
            timescaledb.compress_orderby = 'time DESC'
        );
    """)

def downgrade():
    # Drop hypertable first
    op.execute("DROP TABLE IF EXISTS market_data CASCADE;")
    op.drop_table('corporate_actions')
    op.drop_table('assets')
```

---

### 3. Hypertable Configuration

#### Partition Strategy
- **Chunk Size**: 1 month (balance between query performance and management overhead)
- **Partition Key**: `time` column
- **Segment By**: `symbol` (improves compression ratio)

#### Compression Policy
```sql
-- Compress chunks older than 7 days
SELECT add_compression_policy('market_data', INTERVAL '7 days');
```

#### Retention Policy (Future)
```sql
-- Drop chunks older than 5 years (for cost control)
SELECT add_retention_policy('market_data', INTERVAL '5 years');
```

---

### 4. éªŒè¯è„šæœ¬ (`scripts/verify_schema.py`)

éªŒè¯ä»¥ä¸‹å†…å®¹ï¼š

```python
def verify_schema():
    """Verify database schema setup"""
    # 1. Check tables exist
    tables = ['assets', 'market_data', 'corporate_actions']
    for table in tables:
        assert table_exists(table), f"Table {table} not found"

    # 2. Verify hypertable status
    result = query("SELECT * FROM timescaledb_information.hypertables WHERE hypertable_name='market_data'")
    assert len(result) == 1, "market_data is not a hypertable"

    # 3. Insert test data
    insert_test_asset("TEST.US", "US", "Common Stock")
    insert_test_market_data("TEST.US", datetime.now(), 100.0, 105.0, 99.0, 103.0, 1000000)

    # 4. Query and verify
    data = query("SELECT * FROM market_data WHERE symbol='TEST.US'")
    assert len(data) == 1, "Test data not inserted"

    # 5. Clean up test data
    delete_test_data("TEST.US")

    print("âœ… Schema verification passed")
```

---

## ğŸ“Š æ•°æ®åº“è®¾è®¡å†³ç­–

### æ—¶é—´åˆ—é€‰æ‹©: DateTime(timezone=True)
- **Reason**: EODHD data is in ET timezone
- **Storage**: PostgreSQL TIMESTAMP WITH TIME ZONE
- **Queries**: Use `AT TIME ZONE 'US/Eastern'` for market hours queries

### Numeric vs Float
- **Choice**: Numeric(precision=12, scale=4)
- **Reason**: Financial data requires exact decimal representation
- **Example**: 123.4567 stored exactly (no floating point errors)

### Symbol Format
- **Standard**: `{TICKER}.{EXCHANGE}` (e.g., AAPL.US, VOD.LSE)
- **Reason**: Matches EODHD convention
- **Length**: VARCHAR(20) sufficient for most tickers

### Asset Table Rationale
**Without Bulk API**, we must:
1. Maintain a list of assets to sync
2. Track last sync time per asset
3. Support pause/resume per asset
4. Handle incremental updates efficiently

**Field: last_synced**
- `NULL`: Never synced (initial state)
- `2025-12-20`: Last synced on this date
- **Usage**: `WHERE last_synced < NOW() - INTERVAL '1 day'` (find stale data)

---

## ğŸ”„ ä¾èµ–å…³ç³»

**Input**:
- Task #032: TimescaleDB running âœ…
- Task #032.5: `DATA_FORMAT_SPEC.md` âœ…

**Output (for Task #034)**:
- `Asset` table: Provides list of symbols to ingest
- `MarketData` table: Target for EOD data
- `last_synced` field: Enables incremental sync logic

---

## ğŸ›¡ï¸ æˆåŠŸæ ‡å‡†

| æ ‡å‡† | éªŒæ”¶æ¡ä»¶ |
|------|--------|
| Tables Created | assets, market_data, corporate_actions exist |
| Hypertable | `market_data` is a TimescaleDB hypertable |
| Compression | Compression policy enabled |
| Indexes | (symbol, time) index on market_data |
| Foreign Keys | None (denormalized for performance) |
| Migration | `alembic current` shows applied migration |
| Verification | `python3 scripts/verify_schema.py` returns 0 |

---

## ğŸš€ é¢„æœŸå·¥ä½œé‡

| éƒ¨åˆ† | æ—¶é—´ | ä¼˜å…ˆçº§ |
|------|------|--------|
| SQLAlchemy Models | 1 hour | â­â­â­ |
| Alembic Setup | 30 min | â­â­â­ |
| Migration Script | 1 hour | â­â­â­ |
| Hypertable Config | 30 min | â­â­â­ |
| Verification Script | 1 hour | â­â­ |
| **æ€»è®¡** | **~4 hours** | |

---

## ğŸ“ å­¦ä¹ æˆæœ

å®Œæˆæ­¤ä»»åŠ¡åï¼Œä½ å°†æ‹¥æœ‰ï¼š
1. TimescaleDB hypertable å®æˆ˜ç»éªŒ
2. SQLAlchemy ORM ä¸æ—¶åºæ•°æ®åº“é›†æˆ
3. Alembic æ•°æ®åº“ç‰ˆæœ¬æ§åˆ¶
4. é‡‘èæ•°æ®å»ºæ¨¡æœ€ä½³å®è·µ
5. å¢é‡åŒæ­¥æ¶æ„è®¾è®¡æ€è·¯

---

## ğŸ“ æŠ€æœ¯æ ˆ

- **ORM**: SQLAlchemy 2.0+
- **Migration**: Alembic
- **Database**: TimescaleDB (PostgreSQL 14)
- **Data Types**: Numeric (exact decimal), BigInteger, DateTime(timezone=True)
- **Indexes**: B-tree on (symbol, time)
- **Partitioning**: TimescaleDB automatic time-based chunking

---

**Created**: 2025-12-28
**For Task**: #033
**Phase**: 2 (Data Intelligence)
**Protocol**: v2.6 (CLI --plan Integration)
**Critical Pivot**: Symbol-by-symbol sync (Bulk API unavailable)

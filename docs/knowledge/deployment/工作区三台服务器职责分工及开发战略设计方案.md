# 工作区三台服务器职责分工及开发战略设计方案  
**版本**：V1.0（2025-12-14）**目的**：明确三台服务器职责分工，设计开发战略大纲，供 AI 代理参考推进服务器协同工作，实现高效、稳定、可扩展的 MT5 全链路系统（99.9% 可用性，Sharpe >0.9）。  
  
## 1. 三台服务器职责分工  

| 服务器角色 | IP 地址 | 系统环境 | 主要职责 | 关键组件/服务 |
| ------------------------- | ----------------- | ------------------------------------ | --------------------------------------------------------------------------------------------------------------------------------------------------------------- | ------------------------------------------------ |
| 中枢服务器 (Hub) | 47.84.1.161 (新加坡) | Alibaba Cloud Linux 3.2104 LTS 容器优化版 | • 云端 Cursor Desktop 开发环境
• 数据拉取与存储（EODHD 全品种）
• CI/CD Runner（GitHub Actions 绕墙）
• 监控中心（Prometheus + Grafana）
• 告警与回顾（Slack + cron）
• OSS 备份与 OIDC 同步
• 知识库/文档管理 | Podman/Docker, VNC/XFCE, Cursor, Grafana, Runner |
| 训练服务器 (Training GPU) | 8.138.100.136 | Linux (GPU A10) | • 大模型训练（LLaMA3-70B 等）
• 超参数优化
• 模型版本管理 | GPU 驱动, torch, vectorbt, training scripts |
| 推理服务器 (Inference Low-Lat) | 47.84.111.158 | Linux (低延迟 A10) | • ONNX 模型实时推理（/predict 接口）
• 毫秒级响应生产实例
• 健康检查 /health | FastAPI/uvicorn, ONNX Runtime, low-lat config |
  
**分工原则**：  
* **中枢**：大脑 + 控制中心（开发、数据、监控、自动化）  
* **训练**：算力怪兽（离线重计算）  
* **推理**：毫秒响应（在线生产）  
* 数据流：中枢 → 训练（模型训练） → 中枢（模型存储） → 推理（模型加载）  
  
## 2. 基于分工的开发战略设计方案（大纲）  
**战略目标**  
* **短期**（1-2 周）：中枢服务平台稳定运行，云端 Cursor 开发顺畅，Docker/VectorBT 回测落地  
* **中期**（1 月）：训练/推理链路自动化，Grok-4 工具调用真实落地  
* **长期**：全链路 99.9% 可用性，KPI 自动回顾，成本优化（<300元/月）  
**战略阶段大纲（AI 代理推进顺序）**  
1. **阶段1：中枢服务平台完善**（当前优先）  
2. **阶段1：中枢服务平台完善**（当前优先）  
    * Docker/Podman + VectorBT 容器化回测  
    * 数据拉取 cron + OSS 备份  
    * Runner + Grafana 监控 + Slack 告警  
    * AI 代理工具真实落地（run_terminal_cmd → 云端 docker）  
3. **阶段2：训练服务器优化**  
4. **阶段2：训练服务器优化**  
    * GPU 环境标准化（torch + vectorbt）  
    * 训练脚本容器化  
    * 中枢触发训练（Cursor 聊天 → tool_call → training-gpu SSH）  
5. **阶段3：推理服务器生产就绪**  
6. **阶段3：推理服务器生产就绪**  
    * ONNX 模型部署（FastAPI）  
    * 低延迟优化（<50ms）  
    * 中枢健康检查 /health + 自动切换  
7. **阶段4：全链路协同与自动化**  
8. **阶段4：全链路协同与自动化**  
    * Cursor 一键全链测试（生成策略 → 回测 → 训练 → 推理）  
    * Grok-4 RAG 自动触发工单（相似度 >0.4）  
    * 定期回顾（cron + Slack KPI）  
9. **阶段5：成本与稳定性优化**  
10. **阶段5：成本与稳定性优化**  
    * 释放 Windows g9i  
    * 按量付费 + 停机策略  
    * 99.9% 可用性监控  
**AI 代理推进建议**  
* 每阶段生成 [AI-EXEC] 工单  
* 所有操作云端落地（Cursor + 终端 + docker）  
* 报告定期更新 docs/reports/  
* 问题立即开 [AI-FIX] 工单  
此方案作为 AI 代理推进服务器协同工作的**核心大纲**，后续所有工单以此为基准。  
如果您同意，我可以生成第一个工单完善中枢 Docker/VectorBT 环境。  
您觉得这个分工与战略如何？需要调整吗？🚀  
